id,number,title,body,state,created_at,updated_at,closed_at,labels,comments_count,author,assignees,milestone,category,tech_context,error_patterns,has_solution,is_recent,engagement_score
3207534948,62237,lightning: integration test was broken due to permission lacking,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

Run `release-7.5` integration test.

### 2. What did you expect to see? (Required)

It should success.

### 3. What did you see instead (Required)

```
+ check_lightning_log_contains 'Experiencing a wait timeout while writing to tikv'

/home/jenkins/agent/workspace/pingcap/tidb/release-7.5/periodics_br_integration_test/tidb/br/tests/lightning_write_timeout/run.sh: line 48: /home/jenkins/agent/workspace/pingcap/tidb/release-7.5/periodics_br_integration_test/tidb/br/tests/_utils/check_lightning_log_contains: Permission denied

script returned exit code 1
```

### 4. What is your TiDB version? (Required)

release-7.5
",open,2025-07-07T04:50:07Z,2025-07-07T04:50:07Z,,"['type/bug', 'component/lightning']",0,YuJuncen,[],,bug,"['backup', 'tikv']",['permission denied'],False,True,2
3205887413,62230,an error when run test  ./run-tests.sh: line 332: kill: (86298) - No such process,"## Enhancement

we can drop this

# github.com/pingcap/tidb/cmd/tidb-server
building mysql-tester binary: ./mysql_tester
start tidb-server, log file: ./integration-test.out
tidb-server(PID: 95300) started
record result for case: ""executor/issues""
./t/executor/issues.test: ok! 465 test cases passed, take time 5.830736958 s

Great, All tests passed
",closed,2025-07-06T01:25:42Z,2025-07-07T04:00:28Z,2025-07-07T04:00:28Z,['type/enhancement'],0,yihong0618,[],,enhancement,['mysql'],[],False,True,1
3207432068,62236,Call `Close` of child executor in a way similiar `defer`,"## Enhancement

In the `Close` function of the executor, once somewhere there is panic. The `Close` of the child executor may not be called. So we need a way to ensure that `Close` of the child executor must be called no matter if there is a panic.",open,2025-07-07T03:33:46Z,2025-07-07T03:33:46Z,,['type/enhancement'],0,xzhangxian1008,[],,enhancement,[],[],False,True,1
2754475392,58447,"Multiple digests being generated based on variation in number of elements in ""IN"" clause on binary column for semantically similar query","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

``` 
MySQL [(none)]> use test;
Database changed
MySQL [test]> select version();
+---------------------+
| version()           |
+---------------------+
| 5.7.25-TiDB-v6.5.11 |
+---------------------+
1 row in set (0.00 sec)

MySQL [test]> CREATE TABLE test_binary(a binary(4));
Query OK, 0 rows affected (0.12 sec)

MySQL [test]> select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd');
Empty set (0.01 sec)

MySQL [test]> select s.DIGEST ,s.DIGEST_TEXT , s.QUERY_SAMPLE_TEXT , s.EXEC_COUNT , s.PLAN_DIGEST from information_schema.statements_summary s where s.DIGEST_TEXT like '%select%test_binary%'; 
+------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+------------+------------------------------------------------------------------+
| DIGEST                                                           | DIGEST_TEXT                                               | QUERY_SAMPLE_TEXT                                                     | EXEC_COUNT | PLAN_DIGEST                                                      |
+------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+------------+------------------------------------------------------------------+
| cf7c329dfd3568dd8c79aeb783471fbef8204996f9ef5287ecfa81234d5ce8a6 | select * from `test_binary` where `a` in ( (_charset) ? ) | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd') |          1 | b71103cdbdd6de5ddfabb01a15604a9888fb246c09a1cf26f3e7d98a74fd14ac |
+------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+------------+------------------------------------------------------------------+
1 row in set (0.00 sec)

MySQL [test]> select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd', _binary 'A\ufffd\ufffd\uffed');
Empty set (0.00 sec)

MySQL [test]> select s.DIGEST ,s.DIGEST_TEXT , s.QUERY_SAMPLE_TEXT , s.EXEC_COUNT , s.PLAN_DIGEST from information_schema.statements_summary s where s.DIGEST_TEXT like '%select%test_binary%'; 
+------------------------------------------------------------------+--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
| DIGEST                                                           | DIGEST_TEXT                                                              | QUERY_SAMPLE_TEXT                                                                                    | EXEC_COUNT | PLAN_DIGEST                                                      |
+------------------------------------------------------------------+--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
| 14bfc516695c75c3345651e76ba3ce7a60fe9af5b5b4e0ae4f61fc59172c6fa3 | select * from `test_binary` where `a` in ( (_charset) ? , (_charset) ? ) | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd', _binary 'A\ufffd\ufffd\uffed') |          1 | 4b0635a4915a1572a3ea0fd7b82ac442b8ec0298d39f71332a39758d569c3ea8 |
| cf7c329dfd3568dd8c79aeb783471fbef8204996f9ef5287ecfa81234d5ce8a6 | select * from `test_binary` where `a` in ( (_charset) ? )                | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd')                                |          1 | b71103cdbdd6de5ddfabb01a15604a9888fb246c09a1cf26f3e7d98a74fd14ac |
+------------------------------------------------------------------+--------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
2 rows in set (0.00 sec)

MySQL [test]> select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd', _binary 'A\ufffd\ufffd\uffed', _binary 'A\ufffd\ufffd\uffdd');
Empty set (0.00 sec)

MySQL [test]> select s.DIGEST ,s.DIGEST_TEXT , s.QUERY_SAMPLE_TEXT , s.EXEC_COUNT , s.PLAN_DIGEST from information_schema.statements_summary s where s.DIGEST_TEXT like '%select%test_binary%'; 
+------------------------------------------------------------------+-----------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
| DIGEST                                                           | DIGEST_TEXT                                                                             | QUERY_SAMPLE_TEXT                                                                                                                   | EXEC_COUNT | PLAN_DIGEST                                                      |
+------------------------------------------------------------------+-----------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
| a2c06a5975b929045cf215cf07cfc2fb3b5dfc5ee0d05163f815d4a252a61e6a | select * from `test_binary` where `a` in ( (_charset) ? , (_charset) ? , (_charset) ? ) | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd', _binary 'A\ufffd\ufffd\uffed', _binary 'A\ufffd\ufffd\uffdd') |          1 | aaf7bf0e11c5df1598811243030ab9e72b3476928807d8d0638b963692147733 |
| 14bfc516695c75c3345651e76ba3ce7a60fe9af5b5b4e0ae4f61fc59172c6fa3 | select * from `test_binary` where `a` in ( (_charset) ? , (_charset) ? )                | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd', _binary 'A\ufffd\ufffd\uffed')                                |          1 | 4b0635a4915a1572a3ea0fd7b82ac442b8ec0298d39f71332a39758d569c3ea8 |
| cf7c329dfd3568dd8c79aeb783471fbef8204996f9ef5287ecfa81234d5ce8a6 | select * from `test_binary` where `a` in ( (_charset) ? )                               | select * from test_binary where a in ( _binary 'A\ufffd\ufffd\ufffd')                                                               |          1 | b71103cdbdd6de5ddfabb01a15604a9888fb246c09a1cf26f3e7d98a74fd14ac |
+------------------------------------------------------------------+-----------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------------------------------+
3 rows in set (0.00 sec)

MySQL [test]> 
```

### 2. What did you expect to see? (Required)

A single digest should have been generated as the query is semantically same.

### 3. What did you see instead (Required)

Different digests have been generated for above 3 queries, based on variation in number of elements in ""IN"" clause.

### 4. What is your TiDB version? (Required)

tested on both v6.5 and v7.1, other versions should be the same.

",closed,2024-12-22T04:01:46Z,2025-07-07T02:32:56Z,2025-07-03T03:55:46Z,"['type/bug', 'sig/sql-infra', 'compatibility-breaker', 'severity/minor', 'affects-6.5', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'report/customer', 'affects-8.5']",1,lawrence1223freenew,['xhebox'],,bug,['mysql'],[],True,False,15
2782920864,58871,PD error is not checked in `waitVersionSyncedWithoutMDL`,"## Bug Report

here error is not checked https://github.com/pingcap/tidb/blob/b74eb0f906a73215548c1cf2352c41a802ea37f9/pkg/ddl/schema_version.go#L408

If PD goes wrong here, the error is ignored and continue with `ver=0`. Then It uses `0` to create a snapshot and `latestSchemaVersion` will be `0` too and `updateGlobalVersionAndWaitSynced` will not work.

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

master

",open,2025-01-13T03:19:39Z,2025-07-07T02:21:38Z,,"['type/bug', 'type/regression', 'affects-6.5', 'affects-7.1', 'component/ddl', 'affects-7.5', 'affects-8.1', 'report/customer', 'affects-8.5']",3,disksing,[],,bug,"['replication', 'pd']",[],False,False,15
3200100495,62200,involvedSchemaInfo is invalid for AlterTableMode and RefreshMeta,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
there are no explicit set or schema/table name set
https://github.com/pingcap/tidb/blob/339f07ae8f2ba406abc7f4757ffcce918cc86a56/pkg/ddl/executor.go#L7076-L7084
https://github.com/pingcap/tidb/blob/339f07ae8f2ba406abc7f4757ffcce918cc86a56/pkg/ddl/executor.go#L5769-L5777
```
[2025/07/03 16:44:33.813 +00:00] [ERROR] [wait_group_wrapper.go:178] [""panic in the wait group""] [recover=""assert failed, InvolvingSchemaInfo should be like an enumerate type: model.InvolvingSchemaInfo{Database:\""\"", Table:\""\"", Policy:\""\"", ResourceGroup:\""\"", Mode:0}""] [stack=""github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithLog.func1.1
  pkg/util/wait_group_wrapper.go:178
runtime.gopanic
  GOROOT/src/runtime/panic.go:791
github.com/pingcap/tidb/pkg/util/intest.doPanic
  pkg/util/intest/assert_common.go:58
github.com/pingcap/tidb/pkg/util/intest.doAssert
  pkg/util/intest/assert_common.go:30
github.com/pingcap/tidb/pkg/util/intest.Assert
  pkg/util/intest/assert.go:25
github.com/pingcap/tidb/pkg/ddl.(*runningJobs).checkRunnable
  pkg/ddl/ddl_running_jobs.go:166
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).loadAndDeliverJobs
  pkg/ddl/job_scheduler.go:423
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).schedule
  pkg/ddl/job_scheduler.go:333
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).scheduleLoop
  pkg/ddl/job_scheduler.go:268
github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithLog.func1
  pkg/util/wait_group_wrapper.go:181""] [stack=""github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithLog.func1.1
  pkg/util/wait_group_wrapper.go:178
runtime.gopanic
  GOROOT/src/runtime/panic.go:791
github.com/pingcap/tidb/pkg/util/intest.doPanic
  pkg/util/intest/assert_common.go:58
github.com/pingcap/tidb/pkg/util/intest.doAssert
  pkg/util/intest/assert_common.go:30
github.com/pingcap/tidb/pkg/util/intest.Assert
  pkg/util/intest/assert.go:25
github.com/pingcap/tidb/pkg/ddl.(*runningJobs).checkRunnable
  pkg/ddl/ddl_running_jobs.go:166
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).loadAndDeliverJobs
  pkg/ddl/job_scheduler.go:423
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).schedule
  pkg/ddl/job_scheduler.go:333
github.com/pingcap/tidb/pkg/ddl.(*jobScheduler).scheduleLoop
  pkg/ddl/job_scheduler.go:268
github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithLog.func1
  pkg/util/wait_group_wrapper.go:181""]
```

### 2. What did you expect to see? (Required)
success
### 3. What did you see instead (Required)
assert fail
### 4. What is your TiDB version? (Required)
master
<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-03T17:25:03Z,2025-07-06T13:00:02Z,,"['type/bug', 'severity/major', 'component/ddl']",6,D3Hunter,[],,bug,['pd'],[],False,True,15
3168877397,61946,SELECT reports error in TiDB but not in MySQL,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```sql
CREATE TABLE t0(c0 DECIMAL UNSIGNED ZEROFILL , c1 NUMERIC , c2 TEXT(310) );
INSERT IGNORE  INTO t0(c2, c0, c1) VALUES (-837020673, 2111813582, 2111813582);


CREATE TABLE t1(c0 decimal(10,0) unsigned zerofill,c1 text COLLATE ""utf8mb4_bin"",c2 text COLLATE ""utf8mb4_bin"");
INSERT INTO t1 SELECT * FROM t0;
SELECT t1.c2, t1.c0, t1.c1 FROM t1 WHERE (CASE 1339410646 WHEN CAST(EXPORT_SET(CEILING((- (t1.c2))), (~ (false)), t1.c0, 0.4071873864608775, t1.c2) AS DATETIME) THEN (CASE 0.8171327018587662 WHEN t1.c0 THEN 'e' ELSE t1.c1 END ) ELSE (('.)')OR('(')) END );
```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

SELECT executed successfully

### 3. What did you see instead (Required)

```sql
ERROR 1105 (HY000): strconv.Atoi: parsing ""184467440737095516150"": value out of range
```

### 4. What is your TiDB version? (Required)
```sql
Release Version: v9.0.0-beta.1.pre-640-g24903d6b24
Edition: Community
Git Commit Hash: 24903d6b24674b9a43625ac2d05bf1b033b04407
Git Branch: master
UTC Build Time: 2025-04-27 01:17:32
GoVersion: go1.23.8
Race Enabled: false
Check Table Before Drop: false
Store: tikv 
```



",open,2025-06-23T17:12:12Z,2025-07-06T07:02:41Z,,"['type/bug', 'sig/execution', 'severity/moderate']",2,FullDuplexFish,[],,bug,"['mysql', 'backup', 'tikv']",[],False,True,7
2681482566,57613,br: add table filter for Pitr restore,"## Feature Request

Right now only snapshot backup/restore supports filter, users are asking for PiTR to support it. We only need to add filter for log restore and not log backup.

Need to consider table rename corner cases
1. table renamed into the filter during log replay should be kept after restore
2. table renamed out of filter range during log replay should be dropped after restore
3. Should naturally works with insertGCRow, repairIndex and TiFlash
4. Partitions exchanged across the filter boundary should not be supported and will error out

This issue now becomes a covering issue for multiple other functionalities including:
1. Online filtered restore: need to refresh schema change by tables and not full load otherwise can freeze DDL op for the entire cluster.
2. Parallel restore: to allow multiple restore tasks with disjoint filters to proceed at the same time
3. Log backup compatibility: allow log backup turned on while doing PiTR
4. Better scheduler control: only set on tables that are going to restore instead of all.

### Tasks:
  - [x] https://github.com/pingcap/tidb/pull/58112 
  - [x] https://github.com/pingcap/kvproto/pull/1294
  - [x] https://github.com/pingcap/tidb/pull/57394
  - [x] https://github.com/pingcap/tidb/pull/59683
  - [x] https://github.com/pingcap/tidb/pull/59678
  - [x] https://github.com/pingcap/tidb/pull/59109
  - [x] https://github.com/pingcap/tidb/pull/59359
  - [x] https://github.com/pingcap/tidb/pull/59281 (depends on https://github.com/pingcap/tidb/pull/59009 and https://github.com/pingcap/tidb/pull/60837)
  - [x] ddl support to drop tables in restore mode https://github.com/pingcap/tidb/pull/61451
  - [x] https://github.com/pingcap/tidb/pull/61238
  - [x] https://github.com/pingcap/tidb/pull/61278
  - [x] https://github.com/pingcap/tidb/pull/58724
  - [x] https://github.com/pingcap/tidb/pull/61108
  - [x] https://github.com/pingcap/tidb/pull/61819
  - [x] https://github.com/pingcap/tidb/pull/61977
### Bugfixes
  - [x] https://github.com/pingcap/tidb/pull/60023
  - [x] https://github.com/pingcap/tidb/pull/60202
  - [x] https://github.com/pingcap/tidb/pull/61225
  - [x] https://github.com/pingcap/tidb/pull/61366
  - [x] https://github.com/pingcap/tidb/pull/61631
  - [x] https://github.com/pingcap/tidb/pull/61734
  - [x] https://github.com/pingcap/tidb/pull/61610
  - [x] https://github.com/pingcap/tidb/pull/61941
  - [x] https://github.com/pingcap/tidb-operator/pull/6267

",open,2024-11-22T01:24:10Z,2025-07-06T06:04:45Z,,"['type/feature-request', 'component/br', 'affects-8.5']",0,Tristan1900,[],,other,"['mysql', 'backup', 'tiflash', 'pd']",[],False,False,3
3205776267,62229,allow ALTER TABLE COMPRESSION=NONE,"## Enhancement

Currently COPMRESSION clause in create table is parsed bug ignored.
https://docs.pingcap.com/tidb/stable/sql-statement-create-table/

> The following table_options are supported. Other options such as AVG_ROW_LENGTH, CHECKSUM, COMPRESSION, CONNECTION, DELAY_KEY_WRITE, ENGINE, KEY_BLOCK_SIZE, MAX_ROWS, MIN_ROWS, ROW_FORMAT and STATS_PERSISTENT are parsed but ignored.

but we restricted ALTER table clause.
https://docs.pingcap.com/tidb/stable/sql-statement-alter-table/

```
: TiDB 8.1.2
mysql> CREATE TABLE t1 (id int) COMPRESSION=""NONE"";
Query OK, 0 rows affected (0.13 sec)

mysql> ALTER TABLE t1 COMPRESSION=""None"";
ERROR 8200 (HY000): This type of ALTER TABLE is currently unsupported
```

I'd like to allow only ALTER TABLE COMPRESSION=""NONE""
",open,2025-07-05T23:14:46Z,2025-07-05T23:15:09Z,,['type/enhancement'],0,takaidohigasi,[],,enhancement,['mysql'],[],False,True,1
2477521480,55568,"Use ""Tencent Cloud Object Storage"" for Restore Data from S3-Compatible Storage Fail","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
Use ""Tencent Cloud Object Storage"" for Restore Data from S3-Compatible Storage Using BR

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
It will be Normal

### 3. What did you see instead (Required)
<Code>PathStyleDomainForbidden</Code>
<Message>The bucket you are attempting to access must be addressed using COS virtual-styled domain.</Message>

### 4. What is your TiDB version? (Required)
8.1.0

### 5.How to fix
br/pkg/storage/s3.go #L175
Need add if options.Provider == ""tencent"" use options.ForcePathStyle = false
",open,2024-08-21T09:17:03Z,2025-07-05T21:30:13Z,,"['type/bug', 'help wanted', 'severity/major', 'component/br', 'affects-8.1', 'affects-8.5']",2,shezhangjun,[],,bug,"['cloud', 'backup', 'tikv']",[],False,False,10
3128949658,61575,dumpling integration test failed,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)
need to use the old version mc
```
mc: <ERROR> `config` is not a recognized command. Get help using `--help` flag.
```
### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-06-09T02:26:49Z,2025-07-05T14:35:41Z,,"['type/bug', 'severity/minor', 'component/dumpling']",1,Leavrth,[],,bug,['backup'],[],False,True,5
1879296351,46609,Support AWS profile for S3 configuration,"## Enhancement

Support AWS profile configuration to set aws config values (for example to limit bandwidth to upload / download)

> Sessions options from Shared Config
> https://docs.aws.amazon.com/sdk-for-go/api/aws/session/


## Pull Request
https://github.com/pingcap/tidb/pull/62199",open,2023-09-04T00:29:09Z,2025-07-05T14:22:46Z,,['type/enhancement'],3,takaidohigasi,['takaidohigasi'],,enhancement,['cloud'],[],False,False,10
3174609207,61999,dumpling: Parallel processing implementation for string-type,"## Enhancement

Currently, parallelization supports only numeric types for dumpling. so support string value.


## related implementation

* pickupPossibleField
    https://github.com/pingcap/tidb/blob/master/dumpling/export/sql.go#L1286-L1299
* estimateCount
    https://github.com/pingcap/tidb/blob/master/dumpling/export/sql.go#L1301
    https://github.com/pingcap/tidb/blob/master/dumpling/export/sql.go#L1306
* detectEstimateRows
    https://github.com/pingcap/tidb/blob/master/dumpling/export/sql.go#L1343

## Pull Request

https://github.com/pingcap/tidb/pull/62172",open,2025-06-25T07:55:26Z,2025-07-05T14:22:11Z,,['type/enhancement'],1,takaidohigasi,['takaidohigasi'],,enhancement,['backup'],[],False,True,6
3124109881,61553,Limit the concurrent number of sst files that call ingest sst API during the `add index` period,"## Enhancement
related to https://github.com/pingcap/tidb/issues/58807 

currently, we already have https://docs.pingcap.com/tidb/stable/system-variables/#tidb_ddl_reorg_max_write_speed-new-in-v6512-v755-and-v850 
while we can not control the concurrent number of sst files, and TiKV will take the number of level0 files as the standard for rate limiting",closed,2025-06-06T08:50:45Z,2025-07-05T09:30:11Z,2025-07-05T09:30:11Z,"['type/enhancement', 'component/ddl', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,AndreMouche,[],,enhancement,['tikv'],[],False,True,5
3153435544,61782,dead chanel in UpdateNewAndDoneWatch,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

It started here

https://github.com/pingcap/tidb/blob/e601725d7fd0389107e9848a5f3182e05e0b9d98/pkg/domain/runaway.go#L75-L80

will insert record into channels here

https://github.com/pingcap/tidb/blob/6a12f31171dda2ef20ad4f81f6b2cd95bf13feab/pkg/resourcegroup/runaway/manager.go#L424-L426
The receive loop however is started later than the first call of `UpdateNewAndDoneWatch(RunawayRecordFlushLoop)`

https://github.com/pingcap/tidb/blob/6a12f31171dda2ef20ad4f81f6b2cd95bf13feab/pkg/resourcegroup/runaway/manager.go#L211

If the channel exceeds the maximum(1024), it blocks.

introduced by #52283

### 2. What did you expect to see? (Required)

non blocking.

### 3. What did you see instead (Required)

`runawayStartLoop` blocks forever

### 4. What is your TiDB version? (Required)

v8.1.0 and later",closed,2025-06-17T13:03:04Z,2025-07-05T06:00:55Z,2025-07-05T06:00:55Z,"['type/bug', 'severity/major', 'component/pd', 'affects-8.1', 'affects-8.5', 'affects-9.0']",0,xhebox,[],,bug,['pd'],[],False,True,6
3186172748,62069,Deadlock encountered during statistics collection,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

Start the cluster and run ANALYZE STATISTICS commands immediately after the cluster has started.

### 2. What did you expect to see? (Required)
No deadlock encountered during statistics collection.

### 3. What did you see instead (Required)
```log
2025-06-26 18:15:01 (UTC+02:00)TiKV master-tikv-0.master-tikv-peer.schrddl-sql-tps-7893364-1-595.svc.cluster.local:20160[future.rs:148] [""starting working thread""] [worker=deadlock-detector] [thread_id=1]
2025-06-26 18:15:01 (UTC+02:00)TiKV master-tikv-0.master-tikv-peer.schrddl-sql-tps-7893364-1-595.svc.cluster.local:20160[deadlock.rs:761] [""became the leader of deadlock detector!""] [self_id=1] [thread_id=131]
2025-06-26 19:48:56 (UTC+02:00)TiKV master-tikv-0.master-tikv-peer.schrddl-sql-tps-7893364-1-595.svc.cluster.local:20160[errors.rs:480] [""txn deadlocks""] [err=""Error(Txn(Error(Mvcc(Error(Deadlock { start_ts: TimeStamp(459003693925662747), lock_ts: TimeStamp(459003693820543001), lock_key: [116, 128, 0, 0, 0, 0, 0, 0, 22, 95, 114, 128, 0, 0, 0, 0, 0, 187, 197], deadlock_key_hash: 15664380848627473828, wait_chain: [txn: 459003693820543001 wait_for_txn: 459003693925662747 key_hash: 15664380848627473828 key: 7480000000000000165F69800000000000000203800000000000DE38 resource_group_tag: 0A20A8523C35A52AE0C52FA7CDAEFF7E6E816566D35C6DDD2E5E9ABD2250C0AB79DE12201A5D2F6A6290E7649C84FA3EB304291CBFC0588A0EA5629664144CCD2FE56C5518022016, txn: 459003693925662747 wait_for_txn: 459003693820543001 key_hash: 4813705967226304026 key: 7480000000000000165F72800000000000BBC5 resource_group_tag: 0A201C168B5476C4736D7F171FFBE75D3F630EBEA1D81AD7FAD14395EA47AA1AF1BF12206CD45B796EF12E7CD136A40CF561D46CB98182D75F27497674CF7ED44881A21F18012016] })))))""] [thread_id=129]
```

```sql
mysql> SELECT * FROM information_schema.deadlocks;
+-------------+----------------------------+-----------+--------------------+------------------------------------------------------------------+-------------------------+----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------+
| DEADLOCK_ID | OCCUR_TIME                 | RETRYABLE | TRY_LOCK_TRX_ID    | CURRENT_SQL_DIGEST                                               | CURRENT_SQL_DIGEST_TEXT | KEY                                                      | KEY_INFO                                                                                                                       | TRX_HOLDING_LOCK   |
+-------------+----------------------------+-----------+--------------------+------------------------------------------------------------------+-------------------------+----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------+
|           1 | 2025-06-27 01:48:56.258590 |         0 | 459003693820543001 | a8523c35a52ae0c52fa7cdaeff7e6e816566d35c6ddd2e5e9abd2250c0ab79de | NULL                    | 7480000000000000165F69800000000000000203800000000000DE38 | {""db_name"":""mysql"",""table_name"":""stats_meta"",""index_name"":""tbl"",""index_values"":[""56888""],""db_id"":1,""table_id"":22,""index_id"":2} | 459003693925662747 |
|           1 | 2025-06-27 01:48:56.258590 |         0 | 459003693925662747 | 1c168b5476c4736d7f171ffbe75d3f630ebea1d81ad7fad14395ea47aa1af1bf | NULL                    | 7480000000000000165F72800000000000BBC5                   | {""db_name"":""mysql"",""table_name"":""stats_meta"",""handle_type"":""int"",""handle_value"":""48069"",""db_id"":1,""table_id"":22}               | 459003693820543001 |
+-------------+----------------------------+-----------+--------------------+------------------------------------------------------------------+-------------------------+----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------+
2 rows in set (0.28 sec)
```

### 4. What is your TiDB version? (Required)

master
release-8.5

",open,2025-06-29T13:34:58Z,2025-07-04T14:46:24Z,,"['type/bug', 'sig/planner', 'component/statistics', 'fuzz/schrddl']",1,0xPoe,['0xPoe'],,bug,"['mysql', 'tikv']",['deadlock'],False,True,9
2521298236,56034,Able to set AUTO_INCREMENT to a value larger than maximum value of int,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
1. create a table with auto increment, and set AUTO_INCREMENT=2147483648, while max value for int is 2147483647 (https://docs.pingcap.com/tidb/stable/data-type-numeric#integer-type)
2. insert into the value using auto increment
```
mysql> create table t1 (a int auto_increment) AUTO_INCREMENT=2147483648;
Query OK, 0 rows affected (0.07 sec)

mysql> insert into t1 values ();
ERROR 1690 (22003): constant 2147483648 overflows int

```

### 2. What did you expect to see? (Required)
Create table should fail or user should be notified/warned in this case.

### 3. What did you see instead (Required)
Create table is OK, but later insert fails.

### 4. What is your TiDB version? (Required)
v8.4.0-alpha
Edition: Community
Git Commit Hash: f9c4773ba34854cec93dec3c5cae8a625925f9e9
Git Branch: heads/refs/tags/v8.4.0-alpha

",open,2024-09-12T04:14:30Z,2025-07-04T14:30:14Z,,"['type/bug', 'good first issue', 'severity/moderate', 'component/ddl']",9,fubinzh,"['takaidohigasi', 'adi-kmt']",,bug,"['mysql', 'backup']",[],False,False,28
3171446223,61967,Cleaning up unused code by enabling golangci-lint unused,"## Enhancement

The unused code can be obtained through the following instructions:
` golangci-lint run --no-config --disable-all --enable=unused --timeout=30m --skip-files="".*_test\.go"" ./pkg/...`

- [x] #61959 Rows Changed: +0 −53
- [x] #61924 Rows Changed: +7 −15
- [x] #62000 Rows Changed: +0 −73
- [x] #61936 Rows Changed: +0 −23
- [x] #62004 Rows Changed: +0 −139
- [x] #62056 Rows Changed: +0 −132


Rest:

```
pkg/resourcemanager/poolmanager/task_manager.go:52:16: func `(*Meta).getOriginConcurrency` is unused (unused)
func (m *Meta) getOriginConcurrency() int32 {
               ^
pkg/resourcemanager/poolmanager/task_manager.go:124:23: func `(*TaskManager).hasTask` is unused (unused)
func (t *TaskManager) hasTask(taskID uint64) bool {
                      ^
pkg/util/cgroup/cgroup_cpu.go:24:5: var `errNoCPUControllerDetected` is unused (unused)
var errNoCPUControllerDetected = errors.New(""no cpu controller detected"")
    ^
pkg/sessionctx/vardef/tidb_vars.go:1804:6: func `mustParseDuration` is unused (unused)
func mustParseDuration(str string) time.Duration {
     ^
pkg/util/tiflashcompute/topo_fetcher.go:161:27: func `(*MockTopoFetcher).assureTopo` is unused (unused)
func (f *MockTopoFetcher) assureTopo(nodeNum int) error {
                          ^
pkg/store/mockstore/unistore/tikv/mvcc/tikv.go:131:5: var `errInvalidLockCFValue` is unused (unused)
var errInvalidLockCFValue = errors.New(""invalid lock CF value"")
    ^
pkg/sessionctx/stmtctx/stmtctx.go:71:6: type `jsonSQLWarn` is unused (unused)
type jsonSQLWarn struct {
     ^
pkg/kv/kv.go:792:2: field `accessKey` is unused (unused)
	accessKey    []byte
	^
pkg/timer/api/store.go:50:26: func `(*OptionalVal[T]).internalPresent` is unused (unused)
func (o *OptionalVal[T]) internalPresent() bool {
                         ^
pkg/table/tables/tables.go:1469:23: func `(*TableCommon).canSkipUpdateBinlog` is unused (unused)
func (t *TableCommon) canSkipUpdateBinlog(col *table.Column) bool {
                      ^
pkg/owner/mock.go:45:2: field `retireHook` is unused (unused)
	retireHook   func()
	^
pkg/distsql/select_result.go:52:2: var `errQueryInterrupted` is unused (unused)
	errQueryInterrupted = dbterror.ClassExecutor.NewStd(errno.ErrQueryInterrupted)
	^
pkg/store/mockstore/mockstore.go:272:6: func `copyImage` is unused (unused)
func copyImage() (string, error) {
     ^
pkg/workloadlearning/handle.go:115:16: func `(*Handle).analyzeBasedOnStatementSummary` is unused (unused)
func (*Handle) analyzeBasedOnStatementSummary() []*TableReadCostMetrics {
               ^
pkg/workloadlearning/handle.go:338:6: func `checkCrossDB` is unused (unused)
func checkCrossDB(sql string) (bool, error) {
     ^
pkg/ttl/ttlworker/job.go:123:2: field `statusMutex` is unused (unused)
	statusMutex sync.Mutex
	^
pkg/ttl/ttlworker/session.go:60:5: var `allIsolationReadEngines` is unused (unused)
var allIsolationReadEngines = map[kv.StoreType]struct{}{
    ^
pkg/executor/join/hash_join_test_util.go:147:6: func `buildDataSource` is unused (unused)
func buildDataSource(sortCase *testutil.SortCase, schema *expression.Schema) *testutil.MockDataSource {
......
```",open,2025-06-24T10:41:56Z,2025-07-04T14:17:38Z,,"['type/enhancement', 'good first issue', 'first-time-contributor']",2,zimulala,['kachida'],,enhancement,"['docker', 'monitoring', 'replication', 'tiflash', 'tikv', 'pd']",[],False,True,10
3198790110,62188,resource group: some interfaces are not correctly using keyspace,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-07-03T09:55:01Z,2025-07-04T10:27:08Z,2025-07-04T10:27:08Z,"['type/bug', 'severity/minor', 'component/pd']",2,lhy1024,[],,bug,[],[],True,True,7
3174835729,62001,resource_control: support collecting and reporting cross AZ network traffic,"## Feature Request

**Is your feature request related to a problem? Please describe:**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->

As the cross AZ traffic in the cloud environment takes a significant portion of the overall cost, we want to collect the cross AZ traffic involved in user statements so it can help us optimize our pricing strategy.

**Describe the feature you'd like:**
<!-- A clear and concise description of what you want to happen. -->

**Describe alternatives you've considered:**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Teachability, Documentation, Adoption, Migration Strategy:**
<!-- If you can, explain some scenarios how users might use this, situations it would be helpful in. Any API designs, mockups, or diagrams are also helpful. -->
",closed,2025-06-25T09:02:05Z,2025-07-04T10:27:01Z,2025-07-04T10:27:01Z,['type/feature-request'],0,glorv,[],,other,"['mysql', 'cloud']",[],False,True,1
3201398973,62210,tiflash path can be seen as a kind of logical-prop to guide upper operator to generate mpp task or not,"## Enhancement

![Image](https://github.com/user-attachments/assets/e6842f97-0a9e-4738-96d1-2bbccde10bd2)

when we are planning mpp join, we use allowMPP switch and p.canPushToCop(tiflash) to judge whether we can generate shuffleJoin or boardCast join directly, and if it is and hint is preferred, we just return them directly, while since p.canPushToCop(tiflash) may not that correct as we expected. We should postpone this kind of hint handling into attachment phase.

That means we want to lift the canPushToCop check here, while for most of the case, always generating a mpp join here and fail in the child building like ds can't find any tiflash path is quite a common and simple case which can be avoided by maintain a kind of logical property bottom-up to simply guide upper join to avoid generate mpp join if any side of its child lost the tiflash-path-prop maintained. 

",open,2025-07-04T05:26:24Z,2025-07-04T09:26:40Z,,"['type/enhancement', 'sig/planner', 'planner/cascades']",0,AilinKid,[],,enhancement,"['docker', 'tiflash']",[],False,True,3
3201891363,62218,Backoff_types field in slow_query system table may not work,"## Bug Report

For a long time, we found our slow logs are inaccurate or has important information missing.
This commit: https://github.com/pingcap/tidb/commit/8c79898896455555b401cf1c093b625765cd6312 , splitted the `Backoff_types` field of the slow log files into `Prewrite_Backoff_types` and `Commit_Backoff_types`, and we expect it can give us some more fine-grained information.

However, the `information_schema.slow_query` system table still has only the `Backoff_types` column. This might cause when querying the table by SQL and it tries to parse the slow log fiels, it might always return empty result for the `Backoff_types` column, as there's no field with matching name. And further, this affects the information shown on TiDB dashboard.

\* Note: this problem was found in code, and haven't been verified by test for now.

By the way, the other backoff related columns in the table looks have inconsistent semantics to each other. E.g., while `Backoff_types` looks only including backoffs happend during write, `Backoff_time` and `Backoff_total` looks different. There might be more problems here.

### What is your TiDB version? (Required)

master. But it should affects all LTS versions from v6.5.x.


",open,2025-07-04T09:02:56Z,2025-07-04T09:02:56Z,,['type/bug'],0,MyonKeminta,[],,bug,['performance'],[],False,True,1
3199721449,62197,Goroutine may leak in test,"## Enhancement

```
PASS
[2025/07/03 03:26:49.368 +00:00] [ERROR] [subscribe.go:170] [""Error processing events""] [category=ddl-notifier] [error=""session pool closed""] [errorVerbose=""session pool closed\ngithub.com/pingcap/errors.Trace\n\texternal/com_github_pingcap_errors/juju_adaptor.go:15\ngithub.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).processEvents\n\tpkg/ddl/notifier/subscribe.go:183\ngithub.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start\n\tpkg/ddl/notifier/subscribe.go:163\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1\n\tpkg/util/wait_group_wrapper.go:189\nruntime.goexit\n\tsrc/runtime/asm_amd64.s:1700""] [stack=""github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start\n\tpkg/ddl/notifier/subscribe.go:170\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1\n\tpkg/util/wait_group_wrapper.go:189""]
coverage: 9.3% of statements
[2025/07/03 03:26:50.368 +00:00] [ERROR] [subscribe.go:170] [""Error processing events""] [category=ddl-notifier] [error=""session pool closed""] [errorVerbose=""session pool closed\ngithub.com/pingcap/errors.Trace\n\texternal/com_github_pingcap_errors/juju_adaptor.go:15\ngithub.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).processEvents\n\tpkg/ddl/notifier/subscribe.go:183\ngithub.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start\n\tpkg/ddl/notifier/subscribe.go:163\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1\n\tpkg/util/wait_group_wrapper.go:189\nruntime.goexit\n\tsrc/runtime/asm_amd64.s:1700""] [stack=""github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start\n\tpkg/ddl/notifier/subscribe.go:170\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1\n\tpkg/util/wait_group_wrapper.go:189""]
goleak: Errors on successful test run: found unexpected goroutines:
[Goroutine 28119 in state select, with github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start on top of the stack:
github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start(0xc00964ecc0)
	pkg/ddl/notifier/subscribe.go:159 +0x1e5
github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1()
	pkg/util/wait_group_wrapper.go:189 +0x6b
created by github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover in goroutine 28460
	pkg/util/wait_group_wrapper.go:181 +0x99
 Goroutine 28460 in state select, with github.com/pingcap/tidb/pkg/util/timeutil.Sleep on top of the stack:
github.com/pingcap/tidb/pkg/util/timeutil.Sleep({0x73c7c78, 0xc009e686e0}, 0xc0068f9ee0?)
	pkg/util/timeutil/time.go:28 +0xcb
github.com/pingcap/tidb/pkg/owner.(*mockManager).CampaignOwner.func1()
	pkg/owner/mock.go:159 +0x345
created by github.com/pingcap/tidb/pkg/owner.(*mockManager).CampaignOwner in goroutine 131
	pkg/owner/mock.go:138 +0x6c
]
```

Sometimes the stats owner manager is not closed when the test is complete. It may fail the leak detection.",closed,2025-07-03T15:05:54Z,2025-07-04T09:01:49Z,2025-07-04T09:01:49Z,['type/enhancement'],0,tangenta,[],,enhancement,[],[],False,True,1
3201776312,62216,"stats: analyze panic with error ""index out of range [10] with length 10"" include virtual column","## Bug Report

If the first column of index is a **virtual column** , when analyze table, it will throw """"index out of range [10] with length 10"" panic error.

### 1. Minimal reproduce step (Required)

1. create table with virtual column as index first column

```
CREATE TABLE `job` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `uuid` char(36) GENERATED ALWAYS AS (json_unquote(json_extract(`job_parameter`, _utf8mb4'$.jobUuid'))) VIRTUAL COMMENT 'uuid',
  `agent_uuid` char(36) GENERATED ALWAYS AS (json_unquote(json_extract(`job_parameter`, _utf8mb4'$.agentUuid'))) VIRTUAL COMMENT 'agent uuid',
  `status` varchar(16) GENERATED ALWAYS AS (json_unquote(json_extract(`job_output`, _utf8mb4'$.status'))) VIRTUAL COMMENT 'xxx',
  `start_time` datetime DEFAULT NULL COMMENT 'xxx',
  `end_time` datetime DEFAULT NULL COMMENT 'xxx',
  `job_parameter` json DEFAULT NULL COMMENT 'xxx',
  `job_output` json DEFAULT NULL COMMENT 'xxx',
  `job_callback` json DEFAULT NULL COMMENT 'xxx',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'xxx',
  `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'xxx',
  PRIMARY KEY (`id`) /*T![clustered_index] NONCLUSTERED */,
  UNIQUE KEY `uk_uuid` (`uuid`),
  KEY `idx_agent_uuid` (`agent_uuid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin AUTO_INCREMENT=8001 /*T![auto_id_cache] AUTO_ID_CACHE=1 */ COMMENT='xxx';
```

2. insert into some data

3. analyze table
```
analyze table job;
```

### 2. What did you expect to see? (Required)

without any error

### 3. What did you see instead (Required)

```
mysql> analyze table job;
ERROR 1105 (HY000): runtime error: index out of range [10] with length 10
```

panic log
```
[2025/07/04 15:59:46.782 +08:00] [ERROR] [analyze.go:520] [""analyze worker panicked""] [recover=""runtime error: index out of r
ange [10] with length 10""] [stack=""github.com/pingcap/tidb/pkg/executor.(*AnalyzeExec).analyzeWorker.func1\n\t/Users/pingcap/
workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/executor/analyze.go:520\nruntime.gopanic\n\t/usr/
local/go1.21/src/runtime/panic.go:914\nruntime.goPanicIndex\n\t/usr/local/go1.21/src/runtime/panic.go:114\ngithub.com/pingcap
/tidb/pkg/util/chunk.Row.IsNull\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg
/util/chunk/row.go:218\ngithub.com/pingcap/tidb/pkg/expression.(*Column).EvalJSON\n\t/Users/pingcap/workspace/bp-tidb-release
-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/column.go:502\ngithub.com/pingcap/tidb/pkg/expression.(*builtin
JSONExtractSig).evalJSON\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expres
sion/builtin_json.go:174\ngithub.com/pingcap/tidb/pkg/expression.(*ScalarFunction).EvalJSON\n\t/Users/pingcap/workspace/bp-ti
db-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/scalar_function.go:487\ngithub.com/pingcap/tidb/pkg/e
xpression.(*builtinCastJSONAsStringSig).evalString\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binar
ies/source/tidb/pkg/expression/builtin_cast.go:1908\ngithub.com/pingcap/tidb/pkg/expression.(*ScalarFunction).EvalString\n\t/
Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/scalar_function.go:472\n
github.com/pingcap/tidb/pkg/expression.(*builtinJSONUnquoteSig).evalString\n\t/Users/pingcap/workspace/bp-tidb-release-darwin
-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/builtin_json.go:239\ngithub.com/pingcap/tidb/pkg/expression.(*ScalarFu
nction).EvalString\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/s
calar_function.go:472\ngithub.com/pingcap/tidb/pkg/expression.(*ScalarFunction).Eval\n\t/Users/pingcap/workspace/bp-tidb-rele
ase-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/expression/scalar_function.go:431\ngithub.com/pingcap/tidb/pkg/expressi
on.(*Column).EvalVirtualColumn\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/
expression/column.go:701\ngithub.com/pingcap/tidb/pkg/table.FillVirtualColumnValue\n\t/Users/pingcap/workspace/bp-tidb-releas
e-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/table/column.go:746\ngithub.com/pingcap/tidb/pkg/executor.(*AnalyzeColumn
sExecV2).decodeSampleDataWithVirtualColumn\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/sour
ce/tidb/pkg/executor/analyze_col_v2.go:171\ngithub.com/pingcap/tidb/pkg/executor.(*AnalyzeColumnsExecV2).buildSamplingStats\n
\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/executor/analyze_col_v2.go:309\n
github.com/pingcap/tidb/pkg/executor.(*AnalyzeColumnsExecV2).analyzeColumnsPushDownV2\n\t/Users/pingcap/workspace/bp-tidb-rel
ease-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/executor/analyze_col_v2.go:107\ngithub.com/pingcap/tidb/pkg/executor.a
nalyzeColumnsPushDownEntry\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/exec
utor/analyze_col.go:69\ngithub.com/pingcap/tidb/pkg/executor.(*AnalyzeExec).analyzeWorker\n\t/Users/pingcap/workspace/bp-tidb
-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/executor/analyze.go:547\ngithub.com/pingcap/tidb/pkg/executor.(*An
alyzeExec).Next.func1\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-k5m6z-build-binaries/source/tidb/pkg/executor/
analyze.go:118\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).Run.func1\n\t/Users/pingcap/workspace/bp-tidb-release-da
rwin-arm64-k5m6z-build-binaries/source/tidb/pkg/util/wait_group_wrapper.go:156""]
```

### 4. What is your TiDB version? (Required)

v7.5.6

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-04T08:18:50Z,2025-07-04T08:58:47Z,,"['type/bug', 'sig/planner', 'severity/major', 'may-affects-6.5', 'may-affects-7.1', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5']",0,elsa0520,[],,bug,"['mysql', 'pd']",['error:'],False,True,8
3201730145,62215,br: cross-version restore throws unexpected error,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
use v8.1 to restore to v7.5 cluster from a backup against v6.5 cluster

### 2. What did you expect to see? (Required)
restore succeed

### 3. What did you see instead (Required)

<img width=""1363"" alt=""Image"" src=""https://github.com/user-attachments/assets/620283d3-2841-440a-9333-c98744726176"" />

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-04T07:58:53Z,2025-07-04T08:00:04Z,,"['type/bug', 'severity/moderate', 'component/br']",0,BornChanger,[],,bug,"['docker', 'backup']",[],False,True,3
3201518609,62212,SQL with join failed to build executor,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

Found from instance plan cache test

```SQL
drop table t1, t2 if exists;

create table t1 (c0 int, c1 int);

create table t2 (c0 int, c1 int);

select * from t1 join t2 on t1.c0 = t2.c0
	where t2.c1 = null or t2.c1 > 0 and t1.c1 > 0;
```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

succeed

### 3. What did you see instead (Required)

```sql
ERROR 8118 (HY000): Failed to build executor   
```

### 4. What is your TiDB version? (Required)

 15fe8f1be9789b9d21e9ba6ac8bc7e20b338c2fa

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-04T06:30:52Z,2025-07-04T07:39:52Z,,"['type/bug', 'sig/planner', 'severity/major']",0,joechenrh,[],,bug,[],[],False,True,3
3187229891,62080,OOM record will increase the non-GC STW latency,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

1. Submit big queries to TiDB, and the memory grows to near `tidb_memory_usage_alarm_ratio`.

### 2. What did you expect to see? (Required)

The query latency / TSO Wait duration is not affected.

### 3. What did you see instead (Required)

1. The P999 TSO wait duration increased to 1~2 seconds, while the metrics of PD looks fine.
2. The log keep printing `[memoryusagealarm.go:215] [""tidb-server has the risk of OOM because of memory usage exceeds alarm ratio. Running SQLs and heap profile will be recorded in record path""] [""is tidb_server_memory_limit set""=true]`, which means it's collecting record at a high frequency.
3. The P999 non-GC STW latency is always high in runtime grafana panel.

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-06-30T05:46:31Z,2025-07-04T06:54:41Z,,"['type/bug', 'sig/sql-infra', 'severity/minor']",4,YangKeao,['YangKeao'],,bug,"['monitoring', 'performance', 'pd']",[],False,True,14
3198962009,62192,cannot remove the selection with the table dual,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```
CREATE TABLE t43fc4f8a (
  col_48 date NOT NULL DEFAULT '1991-09-25',
  col_49 smallint unsigned NOT NULL DEFAULT '14803',
  col_50 char(87) COLLATE utf8mb4_unicode_ci DEFAULT 'GhnCJw~(RZ!i#ZxgC',
  col_51 date DEFAULT NULL,
  UNIQUE KEY idx_7 (col_51)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
PARTITION BY LIST COLUMNS(col_51)
(PARTITION p0 VALUES IN ('1970-09-10','1982-04-21','1990-08-27','1990-10-22','1996-02-27','2018-06-05','2027-05-18'),
 PARTITION p1 VALUES IN ('1972-01-21','1974-11-21','1994-02-23','1996-11-08','2000-04-05','2000-09-01','2005-12-17','2014-09-24','2016-12-01','2024-07-27','2025-02-14','2029-06-22','2036-04-30'));


 CREATE TABLE tlcf30036b (
  col_71 varbinary(257) NOT NULL,
  col_72 timestamp NULL DEFAULT NULL,
  col_73 time NOT NULL,
  PRIMARY KEY (col_71(2)) /*T![clustered_index] CLUSTERED */,
  UNIQUE KEY idx_14 (col_72,col_71) /*!80000 INVISIBLE */
) ENGINE=InnoDB DEFAULT CHARSET=gbk COLLATE=gbk_chinese_ci;


select   /*+   */ /*+ NO_HASH_JOIN( t43fc4f8a , st_57 */ avg( distinct  st_57.r1 ) as r0 from t43fc4f8a , ( select  /*+ use_index( tlcf30036b ) */ /*+ agg_to_cop()  */  elt(2, tlcf30036b.col_72 , tlcf30036b.col_72 ) as r0 , bit_or( tlcf30036b.col_71 ) as r1 from tlcf30036b where IsNull( tlcf30036b.col_71 ) and not( tlcf30036b.col_72 in ( '1980-08-05' ,'2033-10-20' ,'2030-06-22' ,'1972-04-20' ) ) group by tlcf30036b.col_72  having tlcf30036b.col_72 in ( '2004-03-24' ,'2006-02-04' ,'1993-06-20' ,null ) and not( tlcf30036b.col_72 < '2026-03-29' ) order by r0,r1 ) st_57 where st_57.r1 in ( 13307631398032338238 ,10696905560280898882 ,5314440087685082217 ,17229250596274672311 ) group by t43fc4f8a.col_51,t43fc4f8a.col_49  having t43fc4f8a.col_49 <=> 11261 order by r0 limit 562300838
```
<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

```
""TopN_23 8.00 root  Column#13, offset:0, count:562300838"",
""└─HashAgg_28 8.00 root  group by:Column#18, Column#19, funcs:avg(distinct Column#17)->Column#13"",
""  └─Projection_55 8.00 root  cast(Column#9, decimal(20,0) UNSIGNED BINARY)->Column#17, test.t43fc4f8a.col_51->Column#18, test.t43fc4f8a.col_49->Column#19"",
""    └─Projection_29 8.00 root  test.t43fc4f8a.col_49, test.t43fc4f8a.col_51, Column#9"",
""      └─HashJoin_43 8.00 root  CARTESIAN inner join"",
""        ├─Selection_44(Build) 0.80 root  in(Column#9, 13307631398032338238, 10696905560280898882, 5314440087685082217, 17229250596274672311)"",
""        │ └─HashAgg_45 1.00 root  group by:Column#16, funcs:bit_or(Column#15)->Column#9"",
""        │   └─Projection_54 0.00 root  cast(test.tlcf30036b.col_71, bigint(257) BINARY)->Column#15, test.tlcf30036b.col_72->Column#16"",
""        │     └─TableDual_46 0.00 root  rows:0"",
""        └─TableReader_53(Probe) 10.00 root partition:all data:Selection_52"",
""          └─Selection_52 10.00 cop[tikv]  nulleq(test.t43fc4f8a.col_49, 11261)"",
""            └─TableFullScan_51 10000.00 cop[tikv] table:t43fc4f8a keep order:false, stats:pseudo"",
```
### 3. What did you see instead (Required)

```
+---------------------------------+----------+-----------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| id                              | estRows  | task      | access object   | operator info                                                                                                                                                                                                                                      |
+---------------------------------+----------+-----------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| TopN_24                         | 8.00     | root      |                 | Column#13, offset:0, count:562300838                                                                                                                                                                                                               |
| └─HashAgg_29                    | 8.00     | root      |                 | group by:Column#18, Column#19, funcs:avg(distinct Column#17)->Column#13                                                                                                                                                                            |
|   └─Projection_59               | 8.00     | root      |                 | cast(Column#9, decimal(20,0) UNSIGNED BINARY)->Column#17, test.t43fc4f8a.col_51->Column#18, test.t43fc4f8a.col_49->Column#19                                                                                                                       |
|     └─Projection_30             | 8.00     | root      |                 | test.t43fc4f8a.col_49, test.t43fc4f8a.col_51, Column#9                                                                                                                                                                                             |
|       └─HashJoin_44             | 8.00     | root      |                 | CARTESIAN inner join                                                                                                                                                                                                                               |
|         ├─Selection_45(Build)   | 0.80     | root      |                 | in(Column#9, 13307631398032338238, 10696905560280898882, 5314440087685082217, 17229250596274672311)                                                                                                                                                |
|         │ └─HashAgg_46          | 1.00     | root      |                 | group by:Column#16, funcs:bit_or(Column#15)->Column#9                                                                                                                                                                                              |
|         │   └─Projection_58     | 0.00     | root      |                 | cast(test.tlcf30036b.col_71, bigint BINARY)->Column#15, test.tlcf30036b.col_72->Column#16                                                                                                                                                          |
|         │     └─Selection_47    | 0.00     | root      |                 | not(lt(test.tlcf30036b.col_72, 2026-03-29 00:00:00.000000)), or(or(eq(test.tlcf30036b.col_72, 2004-03-24 00:00:00.000000), eq(test.tlcf30036b.col_72, 2006-02-04 00:00:00.000000)), or(eq(test.tlcf30036b.col_72, 1993-06-20 00:00:00.000000), 0)) |
|         │       └─TableDual_48  | 0.00     | root      |                 | rows:0                                                                                                                                                                                                                                             |
|         └─TableReader_57(Probe) | 10.00    | root      | partition:all   | data:Selection_56                                                                                                                                                                                                                                  |
|           └─Selection_56        | 10.00    | cop[tikv] |                 | nulleq(test.t43fc4f8a.col_49, 11261)                                                                                                                                                                                                               |
|             └─TableFullScan_55  | 10000.00 | cop[tikv] | table:t43fc4f8a | keep order:false, stats:pseudo                                                                                                                                                                                                                     |
+---------------------------------+----------+-----------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```
### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-07-03T10:56:06Z,2025-07-04T06:13:07Z,2025-07-04T06:13:07Z,"['type/bug', 'sig/planner', 'severity/moderate', 'fuzz/randomtest']",0,hawkingrei,[],,bug,['tikv'],[],False,True,4
3151903020,61766,Restore telemetry functionality using logging instead of network reporting,"## Enhancement
In version 7.5, we removed the telemetry-related code by https://github.com/pingcap/tidb/pull/51202. It's due to concerns that network transmission of usage data might cause confusion or misunderstanding for users. This was a proactive decision to prioritize user trust and transparency.

However, we still have a legitimate need to analyze feature usage in our cloud environment for the purposes of improving product quality and user experience. Therefore, we propose to restore the telemetry functionality, with the following important changes:

No network reporting: Telemetry data will no longer be transmitted over the public network.

Logging-based only: Usage data will be recorded locally via logs.

Cloud default: The telemetry feature will be enabled by default in cloud deployments. Users will be able to manually disable telemetry logging if they choose to.",closed,2025-06-17T03:18:46Z,2025-07-04T05:25:35Z,2025-07-04T05:19:58Z,"['type/bug', 'type/enhancement', 'sig/sql-infra', 'affects-8.1', 'affects-8.5']",0,Defined2014,[],,bug,"['cloud', 'backup']",[],False,True,5
3195739191,62153,instanceplancache‘s test takes too much time.,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

![Image](https://github.com/user-attachments/assets/93c9e21e-b564-446d-a898-32d9ec70e114)

```
    testkit.go:246: 
        	Error Trace:	/Users/weizhenwang/devel/opensource/tidb/pkg/testkit/testkit.go:246
        	            				/Users/weizhenwang/devel/opensource/tidb/pkg/testkit/testkit.go:181
        	            				/Users/weizhenwang/devel/opensource/tidb/pkg/planner/core/casetest/instanceplancache/main_test.go:220
        	            				/opt/homebrew/Cellar/go/1.24.4/libexec/src/runtime/asm_arm64.s:1223
        	Error:      	Received unexpected error:
        	            	[executor:8118]Failed to build executor
        	            	join's inner condition should be empty
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildHashJoinV2FromChildExecs
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:1647
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildHashJoinV2
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:1594
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildHashJoin
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:1761
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).build
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:263
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildProjection
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:2095
        	            	github.com/pingcap/tidb/pkg/executor.(*executorBuilder).build
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/builder.go:279
        	            	github.com/pingcap/tidb/pkg/executor.(*ExecStmt).buildExecutor
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/adapter.go:1240
        	            	github.com/pingcap/tidb/pkg/executor.(*ExecStmt).Exec
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/executor/adapter.go:581
        	            	github.com/pingcap/tidb/pkg/session.runStmt
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/session/session.go:2337
        	            	github.com/pingcap/tidb/pkg/session.(*session).ExecuteStmt
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/session/session.go:2199
        	            	github.com/pingcap/tidb/pkg/testkit.(*TestKit).ExecWithContext
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/testkit/testkit.go:414
        	            	github.com/pingcap/tidb/pkg/testkit.(*TestKit).MustQueryWithContext
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/testkit/testkit.go:245
        	            	github.com/pingcap/tidb/pkg/testkit.(*TestKit).MustQuery
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/testkit/testkit.go:181
        	            	github.com/pingcap/tidb/pkg/planner/core/casetest/instanceplancache.executeWorker
        	            		/Users/weizhenwang/devel/opensource/tidb/pkg/planner/core/casetest/instanceplancache/main_test.go:220
        	            	runtime.goexit
        	            		/opt/homebrew/Cellar/go/1.24.4/libexec/src/runtime/asm_arm64.s:1223
        	Test:       	TestInstancePlanCache
```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-02T12:26:30Z,2025-07-04T03:26:06Z,,"['type/bug', 'sig/planner', 'component/test', 'severity/moderate']",1,hawkingrei,[],,bug,"['docker', 'backup']",['error:'],False,True,6
2995458813,60576,release: v8.1.3,"**Disclaimer**
The dates published in this issue are for planning purposes only. It is intended solely to help you plan your projects. A date that exists in the future should not be considered a firm release date as the release and timing of releases are subject to change at any time and are at PingCAP's sole discretion.

**Candidate SHA:**
TBD

Working Tags: TBD

**Check the diff in the current version:**
See the difference from the commit perspective:
TBD


**Release process checklist**

- [ ] 0. Announce the release plan.
 
- [ ] 1. Code freeze and RC build: TBD

- [ ] 2. Qualifying the release.

- [ ] 3. Docs preparing for release.

- [ ] 4. The release qualified.

- [ ] 5. Docs are ready for release.

**Release date: TBD**

Do not proceed below until the release date.

- [ ] 6. Publish TiDB Release

> - [ ] fill in Candidate SHA above
> 
> - [ ] fill in the release tag

- [ ] 7. Update docs

- [ ] 8. Update the official website",open,2025-04-15T07:34:07Z,2025-07-04T01:23:58Z,,[],1,EmmaDuDu,[],,other,['pd'],[],False,True,2
3026851012,60924,tablemode need RefreshMeta interface to reload tidb schema diff when BR log restore occur exchange partition,"## Enhancement
When BR uses Tablemode, which is expected to be set to RestoreMode when full restore batch crate tables, including tables created during log backup. However, if an exchange partition occurs during log backup, the table will still be a partition during full restore. In log restoring, the table ID will exchange with partition ID, which exchange by `meta kv` directly instead of infoschema, so the table mode cannot be modified for the table(since the new table ID is not store in infoschema).",closed,2025-04-29T02:56:50Z,2025-07-03T17:28:50Z,2025-05-15T13:59:10Z,['type/enhancement'],1,River2000i,[],,enhancement,['backup'],[],True,True,3
3141298933,61715,Failed to build executor,"## Bug Report

### 1. Minimal reproduce step (Required)

```sql
create table t0(vkey integer, c3 varchar(0));
create table t1(vkey integer, c10 integer);
create table t2(c12 integer, c13 integer, c14 varchar(0), c15 double);
create table t3(vkey varchar(0), c20 integer);
select 0 from t2 join(t3 join t0 a on 0) left join(t1 b left join t1 c on 0) on(c20 = b.vkey) on(c13 = a.vkey) join(select c14 d from(t2 join t3 on c12 = vkey)) e on(c3 = d) where nullif(c15, case when(c.c10) then 0 end); -- ERROR 8118 (HY000) at line 1: Failed to build executor
```


### 2. What did you expect to see? (Required)
No error

### 3. What did you see instead (Required)


### 4. What is your TiDB version? (Required)

`tiup playground nightly --host 0.0.0.0 --kv 3 --tiflash 3`
```bash
8.0.11-TiDB-v9.0.0-beta.1.pre-554-gb1a5536a64-dirty
```


",open,2025-06-12T19:07:42Z,2025-07-03T16:30:20Z,,"['type/bug', 'sig/planner', 'severity/major', 'fuzz/sqlancer', 'may-affects-6.5', 'may-affects-7.1', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5']",1,bajinsheng,['hawkingrei'],,bug,['tiflash'],[],False,True,14
3198258982,62180,Accelerate TTL through the index on TTL column,"## Enhancement

## Background

For the current implementation, if the TTL choose to use the index on TTL column, the performance will even be worse. It's because TTL using the index will scan much more rows than scanning the table directly:

### Duplicate Scan caused by Split Scan Range

The scan task is split by primary key, then the query SQLs are like:

```sql
SELECT LOW_PRIORITY SQL_NO_CACHE `id` FROM `test`.`t` WHERE `id` >= ? AND `id` < ? AND `created_time` < FROM_UNIXTIME(?) ORDER BY `id` ASC LIMIT ?;
```

If using the index, it'll scan the index but only get the data within id range. If we have 64 tasks, the range of index will at least be scanned 64 times.

### Duplicate Scan caused by Scan Batch


The scan is batched / paged according to the primary key, which makes it much worse:

```sql
SELECT LOW_PRIORITY SQL_NO_CACHE `id` FROM `test`.`t` WHERE `id` >= ? AND `id` < ? AND `created_time` < FROM_UNIXTIME(?) ORDER BY `id` ASC LIMIT ?;
SELECT LOW_PRIORITY SQL_NO_CACHE `id` FROM `test`.`t` WHERE `id` > ? AND `id` < ? AND `created_time` < FROM_UNIXTIME(?) ORDER BY `id` ASC LIMIT ?;
```

Every single scan will only get 500 rows (tidb_ttl_scan_batch_size). When scanning the index, all expired data will be scanned to properly sort according to id. Therefore, the index range will be repeatedly scanned for `EXPIRED_DATA_ROWS_WITHIN_RANGE / 500` times.

In conclusion, the index will be scanned for `EXPIRED_DATA_ROWS / 500` times. Usually, we can estimate the `EXPIRED_DATA_ROWS` by `TTL_JOB_INTERVAL / DATA_LIFE_TIME * TABLE_SIZE`. Then using index will scan totally `(TTL_JOB_INTERVAL / DATA_LIFE_TIME * TABLE_SIZE)^2 / 500` rows, and using table scan will scan TABLE_SIZE rows in total. Therefore, if `(TTL_JOB_INTERVAL / DATA_LIFE_TIME)^2 * TABLE_SIZE` is greater than 1, using index will scan more rows.

## Proposal

TTL should identify the index which contains the TTL column automatically. The index should meet the following condition:

1. The index should contain the TTL column.
2. If the index is a composite index, it must have the TTL column as prefix.

The TTL process has to make the following changes:

1. The scan batch SQL will need to ORDER BY the TTL column, and add a hint to use the index to ensure that the performance is stable.

```sql
SELECT LOW_PRIORITY SQL_NO_CACHE `id` FROM `test`.`t` force index(xxx) WHERE `created_time` < FROM_UNIXTIME(?) ORDER BY `created_time` ASC, `id` ASC LIMIT ?;
SELECT LOW_PRIORITY SQL_NO_CACHE `id` FROM `test`.`t` force index(xxx) WHERE ((created_time, id) > (FROM_UNIXTIME(?), ?)) AND `created_time` < FROM_UNIXTIME(?) ORDER BY `created_time` ASC, `id` ASC LIMIT ?;
```
 
2. Split the subtasks by TTL column, but not primary.  
    1. Add a new column split_by to the mysql.tidb_ttl_task table to represent the secondary index id. If no index is selected, the column should be NULL to represent that this table is split by row id or clustered primary key.  
    2. If the worker / manager finds that the index doesn't exist, they should report an error for the task.

Even only with the first modification, using index can be faster than scanning table if `64 * TTL_JOB_INTERVAL / DATA_LIFE_TIME` is smaller than 1, because the index will only be repeatedly scanned 64 times.
We can also try to make 64 configurable, like adding a `TTL_TASK_CNT` so that the user can configure the task counts by themselves. The current task count is set as `min(tableRegionCount, max(64, tikvStoreCount))`,",open,2025-07-03T06:53:24Z,2025-07-03T16:23:10Z,,['type/enhancement'],1,YangKeao,['YangKeao'],,enhancement,"['mysql', 'performance', 'tikv']",[],False,True,6
3199688574,62196,wrong RegardNULLAsPoint value in the interal sql,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

add assertion like 

<img width=""1093"" alt=""Image"" src=""https://github.com/user-attachments/assets/8d19860d-19e0-4b53-9ee9-11466f7ff1e2"" />

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
success to run.
### 3. What did you see instead (Required)

fail to run 

```
--- FAIL: TestGetOracleTime (35.78s)
panic: assert failed [recovered]
	panic: assert failed [recovered]
	panic: assert failed
goroutine 122 [running]:
testing.tRunner.func1.2({0x8f63d40, 0xc0089bced0})
	GOROOT/src/testing/testing.go:1632 +0x3fc
testing.tRunner.func1()
	GOROOT/src/testing/testing.go:1635 +0x6b6
panic({0x8f63d40?, 0xc0089bced0?})
	GOROOT/src/runtime/panic.go:791 +0x132
github.com/pingcap/tidb/pkg/executor.(*Compiler).Compile.func1()
	pkg/executor/compiler.go:59 +0x5a5
panic({0x8f63d40?, 0xc0089bced0?})
	GOROOT/src/runtime/panic.go:791 +0x132
github.com/pingcap/tidb/pkg/util/intest.doPanic({0x0, 0x0}, {0x0, 0x0, 0x0})
	pkg/util/intest/assert_common.go:58 +0x79
github.com/pingcap/tidb/pkg/util/intest.doAssert(0x0, {0x0, 0x0, 0x0})
	pkg/util/intest/assert_common.go:30 +0x6e
github.com/pingcap/tidb/pkg/util/intest.Assert(0x0, {0x0, 0x0, 0x0})
	pkg/util/intest/assert.go:25 +0x9e
github.com/pingcap/tidb/pkg/util/ranger.getPotentialEqOrInColOffset(0xc00867aee0, {0xa6e1c60, 0xc00867aaf0}, {0xc00b624108, 0x1, 0x1})
	pkg/util/ranger/detacher.go:141 +0x87d
github.com/pingcap/tidb/pkg/util/ranger.ExtractEqAndInCondition(0xc00867aee0, {0xc006bb3580, 0x2, 0x2}, {0xc00b624108, 0x1, 0x1}, {0xc008702038, 0x1, 0x1})
	pkg/util/ranger/detacher.go:735 +0x22a
github.com/pingcap/tidb/pkg/util/ranger.(*rangeDetacher).detachCNFCondAndBuildRangeForIndex(0xc006cd86d0, {0xc006bb3580, 0x2, 0x2}, {0xc00b624118, 0x1, 0x1}, 0x1)
	pkg/util/ranger/detacher.go:401 +0x1ab
github.com/pingcap/tidb/pkg/util/ranger.(*rangeDetacher).detachCondAndBuildRangeForCols(0xc006cd86d0)
	pkg/util/ranger/detacher.go:1097 +0x45b
github.com/pingcap/tidb/pkg/util/ranger.DetachCondAndBuildRangeForIndex(0xc00867aee0, {0xc006bb3580, 0x2, 0x2}, {0xc00b624108, 0x1, 0x1}, {0xc008702038, 0x1, 0x1}, ...)
	pkg/util/ranger/detacher.go:1032 +0x185
github.com/pingcap/tidb/pkg/planner/core.detachCondAndBuildRangeForPath({0xa6a0058, 0xc005f94af0}, 0xc007f60d80, {0xc006bb3580, 0x2, 0x2}, 0xc0091a1920)
	pkg/planner/core/stats.go:397 +0x2a5
github.com/pingcap/tidb/pkg/planner/core.fillIndexPath(0xc00655b508, 0xc007f60d80, {0xc006bb3580, 0x2, 0x2})
	pkg/planner/core/stats.go:205 +0xa25
github.com/pingcap/tidb/pkg/planner/core.deriveStats4DataSource({0xa6de968, 0xc00655b508})
	pkg/planner/core/stats.go:141 +0xaa5
github.com/pingcap/tidb/pkg/planner/core/operator/logicalop.(*DataSource).DeriveStats(0xc00655b508, {0x22c16ac?, 0x22c72f5?, 0x1?}, 0x8?, {0x8?, 0xc006cd8d40?, 0x224ffeb?}, {0xfc31300, 0x0, ...})
	pkg/planner/core/operator/logicalop/logical_datasource.go:308 +0x52
github.com/pingcap/tidb/pkg/planner/core/operator/logicalop.(*BaseLogicalPlan).RecursiveDeriveStats(0xc00655b528, {0x0, 0x0, 0x0})
	pkg/planner/core/operator/logicalop/base_logical_plan.go:235 +0x56f
github.com/pingcap/tidb/pkg/planner/core/operator/logicalop.(*BaseLogicalPlan).RecursiveDeriveStats(0xc006738620, {0x0, 0x0, 0x0})
	pkg/planner/core/operator/logicalop/base_logical_plan.go:226 +0x2b8
github.com/pingcap/tidb/pkg/planner/core/operator/logicalop.(*BaseLogicalPlan).RecursiveDeriveStats(0xc006bace20, {0x0, 0x0, 0x0})
	pkg/planner/core/operator/logicalop/base_logical_plan.go:226 +0x2b8
github.com/pingcap/tidb/pkg/planner/core.physicalOptimize({0xa6de688, 0xc006bace00}, 0xc0087cffa8)
	pkg/planner/core/optimizer.go:1133 +0x1f9
github.com/pingcap/tidb/pkg/planner/core.VolcanoOptimize({0xa642e10, 0xc0098a8e10}, {0xa6a0058, 0xc005f94af0}, 0x61002, {0xa6de688, 0xc006bace00})
	pkg/planner/core/optimizer.go:362 +0x245
github.com/pingcap/tidb/pkg/planner/core.doOptimize({0xa642e10, 0xc0098a8e10}, {0xa6a0058, 0xc005f94af0}, 0x61002, {0xa6de688, 0xc006bace00})
	pkg/planner/core/optimizer.go:286 +0x1b5
github.com/pingcap/tidb/pkg/planner/core.DoOptimize({0xa642e10, 0xc0098a8e10}, {0xa6a0058, 0xc005f94af0}, 0x61002, {0xa6de688, 0xc006bace00})
	pkg/planner/core/optimizer.go:411 +0x1f6
github.com/pingcap/tidb/pkg/planner/core.(*PlanBuilder).buildUpdate(0xc0071d90e0, {0xa642e10, 0xc0098a8e10}, 0xc00bd98210)
	pkg/planner/core/logical_plan_builder.go:5604 +0x1a5b
github.com/pingcap/tidb/pkg/planner/core.(*PlanBuilder).Build(0xc0071d90e0, {0xa642e10, 0xc0098a8e10}, 0xc006cda668)
	pkg/planner/core/planbuilder.go:549 +0xa25
github.com/pingcap/tidb/pkg/planner.buildLogicalPlan({0xa642e10, 0xc0098a8e10}, {0xa6a0058, 0xc005f94af0}, 0xc006cda668, 0xc0071d90e0)
	pkg/planner/optimize.go:571 +0x365
github.com/pingcap/tidb/pkg/planner.optimize({0xa642e10, 0xc0098a8e10}, {0xa6a0058, 0xc005f94af0}, 0xc006cda668, {0xa6a3470, 0xc00919e840})
	pkg/planner/optimize.go:490 +0x7da
github.com/pingcap/tidb/pkg/planner.optimizeNoCache({0xa642e10, 0xc0098a8e10}, {0xa6e6b28, 0xc001b61b88}, 0xc006d5bc50, {0xa6a3470, 0xc00919e840})
	pkg/planner/optimize.go:357 +0x1cd0
github.com/pingcap/tidb/pkg/planner.Optimize({0xa642e10, 0xc0098a8e10}, {0xa6e6b28, 0xc001b61b88}, 0xc006d5bc50, {0xa6a3470, 0xc00919e840})
	pkg/planner/optimize.go:206 +0xc47
github.com/pingcap/tidb/pkg/executor.(*Compiler).Compile(0xc006cdb000, {0xa642e10, 0xc0098a8e10}, {0xa661d88, 0xc00bd98210})
	pkg/executor/compiler.go:102 +0x951
github.com/pingcap/tidb/pkg/session.(*session).ExecuteStmt(0xc001b61b88, {0xa642e10, 0xc0098a8e10}, {0xa661d88, 0xc00bd98210})
	pkg/session/session.go:2146 +0x12e5
github.com/pingcap/tidb/pkg/session.(*session).ExecuteInternal(0xc001b61b88, {0xa642e10, 0xc0098a8e10}, {0x9b2e4ad, 0x51}, {0xc006c025c0, 0x4, 0x4})
	pkg/session/session.go:1571 +0x3f2
github.com/pingcap/tidb/pkg/session.mustExecute({0xa6fbdd0, 0xc001b61b88}, {0x9b2e4ad, 0x51}, {0xc006c025c0, 0x4, 0x4})
	pkg/session/bootstrap.go:1321 +0x143
github.com/pingcap/tidb/pkg/session.writeStmtSummaryVars({0xa6fbdd0, 0xc001b61b88})
	pkg/session/upgrade.go:992 +0x19f
github.com/pingcap/tidb/pkg/session.doDMLWorks({0xa6fbdd0, 0xc001b61b88})
	pkg/session/bootstrap.go:1294 +0xc71
github.com/pingcap/tidb/pkg/session.bootstrap({0xa6fbdd0, 0xc001b61b88})
	pkg/session/bootstrap.go:840 +0x50f
github.com/pingcap/tidb/pkg/session.runInBootstrapSession({0xa694a88, 0xc0021af860}, 0x0)
	pkg/session/session.go:3792 +0x7c8
github.com/pingcap/tidb/pkg/session.bootstrapSessionImpl({0xa642c50, 0xfc31300}, {0xa694a88, 0xc0021af860}, 0x9be9220)
	pkg/session/session.go:3529 +0x634
github.com/pingcap/tidb/pkg/session.BootstrapSession({0xa694a88, 0xc0021af860})
	pkg/session/session.go:3465 +0x5a
github.com/pingcap/tidb/pkg/store/gcworker.bootstrap({0xa690a50, 0xc0012dad00}, {0xa694a88, 0xc0021af860}, 0xa7a358200)
	pkg/store/gcworker/gc_worker_test.go:1690 +0x70
github.com/pingcap/tidb/pkg/store/gcworker.createGCWorkerSuiteWithStoreType(0xc0012dad00, 0x1, 0xa7a358200)
	pkg/store/gcworker/gc_worker_test.go:177 +0x4da
github.com/pingcap/tidb/pkg/store/gcworker.createGCWorkerSuite(0xc0012dad00)
	pkg/store/gcworker/gc_worker_test.go:149 +0x47
github.com/pingcap/tidb/pkg/store/gcworker.TestGetOracleTime(0xc0012dad00)
	pkg/store/gcworker/gc_worker_test.go:303 +0x4a
testing.tRunner(0xc0012dad00, 0x9be84c0)
	GOROOT/src/testing/testing.go:1690 +0x227
created by testing.(*T).Run in goroutine 1
	GOROOT/src/testing/testing.go:1743 +0x826
```

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-07-03T14:56:04Z,2025-07-03T15:35:14Z,,"['type/bug', 'sig/planner', 'severity/major', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,hawkingrei,[],,bug,"['docker', 'pd']",['panic:'],False,True,6
2856518185,59567,Indexed and without indexed queries return inconsistency results after network partition inject and recovery.,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

Deploy 5 tikv nodes, 3 pd nodes and 1 tidb node in K8S.

1. running transaction workload.
2. some online DDL threads randomly add index or drop index.
3. network partition: [basic-tikv-0], [basic-tikv-1, basic-tikv-2, basic-tikv-3, basic-tikv-4]
4. network partition recovery before the transaction workload finish.
5. admin check table but failed.



The admin check failed statements happen after network partition recovery.



more details can get from the following files.

[index_inconsistency.zip](https://github.com/user-attachments/files/18819578/index_inconsistency.zip)

in zip:

> - schema_and_init_data: initial schema, state and data. 
> - transaction_workload: execute concurrently.
> - ddl_sequence: DDL threads execute during transaction workload.
> - fault_injection: inject network partition.
> - tidb_logs: tidb and tikv logs.



table4 schema:

```sql
Mysql > show create table table4;
CREATE TABLE `table4` (
  `pkId` int(11) DEFAULT NULL,
  `pkAttr0` int(11) NOT NULL,
  `commonAttr0_0` double(18,6) DEFAULT NULL,
  `commonAttr1_0` decimal(10,2) DEFAULT NULL,
  `commonAttr2_0` varchar(10) DEFAULT NULL,
  `commonAttr3_0` int(11) DEFAULT NULL,
  `commonAttr4_0` double(14,4) DEFAULT NULL,
  PRIMARY KEY (`pkAttr0`) /*T![clustered_index] NONCLUSTERED */,
  KEY `table4index_pk` (`pkAttr0`),
  KEY `table4index_commAttr4` (`commonAttr4_0`),
  KEY `table4index_commAttr0` (`commonAttr0_0`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin
PARTITION BY HASH (`pkAttr0`) PARTITIONS 2
```



### 2. What did you expect to see? (Required)

After network partition recovery and all transaction workload done:

```sql
mysql> admin check table table4;
-- ok

mysql> admin check index table4 table4index_commAttr4;
-- ok

mysql> select count(*) from table4;
+----------+
| count(*) |
+----------+
|       30 |
+----------+
1 row in set (0.00 sec)

mysql> select count(*) from table4 force index(table4index_commAttr4);
+----------+
| count(*) |
+----------+
|       30 |
+----------+
1 row in set (0.00 sec)
```





### 3. What did you see instead (Required)

After network partition recovery and all transaction workload done:

```sql
mysql> admin check table table4;
ERROR 8003 (HY000): table4 err:[admin:8223]index:<nil> != record:&admin.RecordData{Handle:8, Values:[]types.Datum{types.Datum{k:0x0, decimal:0x0, length:0x0, i:0, collation:"""", b:[]uint8(nil), x:interface {}(nil)}}}

mysql> admin check index table4 table4index_commAttr4;
ERROR 8003 (HY000): table count 30 != index(table4index_commAttr4) count 16

mysql> select count(*) from table4;
+----------+
| count(*) |
+----------+
|       30 |
+----------+
1 row in set (0.00 sec)

mysql> select count(*) from table4 force index(table4index_commAttr4);
+----------+
| count(*) |
+----------+
|       16 |
+----------+
1 row in set (0.00 sec)
```



The number of rows return from indexed and without indexed queries is inconsistent.



### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

TiDB v5.4

Release Version: v5.4.0
Edition: Community
Git Commit Hash: 55f3b24c1c9f506bd652ef1d162283541e428872
Git Branch: heads/refs/tags/v5.4.0
UTC Build Time: 2022-01-25 08:39:26
GoVersion: go1.16.4
Race Enabled: false
TiKV Min Version: v3.0.0-60965b006877ca7234adaced7890d7b029ed1306
Check Table Before Drop: false









",closed,2025-02-17T01:54:15Z,2025-07-03T12:34:18Z,2025-07-03T12:34:18Z,"['type/bug', 'severity/critical', 'affects-5.4', 'may-affects-6.1', 'may-affects-6.5', 'may-affects-7.1', 'component/ddl', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5', 'affects-9.0']",4,yanghy233,[],,bug,"['kubernetes', 'mysql', 'backup', 'tikv', 'pd']",[],True,False,19
3174263101,61989,flaky test TestTiFlashLateMaterialization,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

```
    plan_test.go:40: 
        	Error Trace:	pkg/planner/core/casetest/plan_test.go:40
        	            				pkg/planner/core/casetest/tiflash_predicate_push_down_test.go:81
        	Error:      	Not equal: 
        	            	expected: 3
        	            	actual  : 4
        	Test:       	TestTiFlashLateMaterialization
```
### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",open,2025-06-25T05:34:36Z,2025-07-03T11:44:03Z,,"['type/bug', 'sig/planner', 'component/test', 'severity/moderate']",2,hawkingrei,[],,bug,['tiflash'],['error:'],False,True,8
3076458712,61210,Update self version failure causes DDL to get stuck while MDL is disabled,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

Similar to https://github.com/pingcap/tidb/issues/43755, the difference is that MDL was disabled, and DDL job got stuck when tidb server failed to update schema version:

```
[2025/05/13 08:02:06.117 +08:00] [Info] [domain.go:215] [""diff load InfoSchema success""] [currentSchemaVersion=1217026] [neededSchemaVersion=1217027] [""start time""=14.630741ms] [phyTblIDs=""[1398997,1399737]""] [actionTypes=""[2048,2048]""]
[2025/05/13 08:02:08.118 +08:00] [Warn] [util.go:299] [""[ddl] etcd-cli put kv failed""] [key=/tidb/ddl/all_schema_versions/037a5fde-1b5e-4ad1-a2a0-dfa583e6bd5e] [value=1217027] [error=""context deadline exceeded""] [retryCnt=0]
[2025/05/13 08:02:08.148 +08:00] [Info] [domain.go:517] [""update self version failed""] [oldSchemaVersion=1217026] [neededSchemaVersion=1217027] [error=""context deadline exceeded""]
```
And DDL owner was continuously checking for unsynced versions

```
[2025/05/13 08:02:11.951 +08:00] [Info] [syncer.go:352] [""[ddl] syncer check all versions, someone is not synced, continue checking""] [ddl=/tidb/ddl/all_schema_versions/4e3becf5-9448-4cd6-9208-d845b0679638] [currentVer=1217026] [latestVer=1217027]
...
[2025/05/13 10:47:23.830 +08:00] [Info] [syncer.go:352] [""[ddl] syncer check all versions, someone is not synced, continue checking""] [ddl=/tidb/ddl/all_schema_versions/4e3becf5-9448-4cd6-9208-d845b0679638] [currentVer=1217026] [latestVer=1217027]
```

### 2. What did you expect to see? (Required)

DDL can update version after recovering from write failure.

### 3. What did you see instead (Required)

DDL execution is stuck, however, the workaround is simple, just execute another DDL.

### 4. What is your TiDB version? (Required)

v6.5.6
",open,2025-05-20T10:07:19Z,2025-07-03T10:04:24Z,,"['type/bug', 'severity/major', 'affects-6.1', 'affects-6.5', 'affects-7.1', 'component/ddl', 'affects-7.5', 'affects-8.1', 'report/customer', 'affects-8.5']",1,pcqz,[],,bug,"['replication', 'pd']",[],False,True,12
3016203945,60804,Rebase auto increment not executed after second restore,"## Bug Report
In the restore process, if the first restore fails but leaves partial table structures in the cluster, and the second restore uses OnExistIgnore, those pre-existing tables will be skipped.

As a result, row_id rebase is not executed for these tables, leading to incorrect auto-increment behavior.

The root cause is that batchCreateTables is not atomic.
https://github.com/pingcap/tidb/blob/287f27ea0e5b7be6d75bd4c6fc9982f9d80e4cf7/pkg/ddl/table.go#L231
Some table could become public while the whole `Create Tables` job still on going.

### 1. Minimal reproduce step (Required)
1. doing a restore with batch tables.
2. random kill restore process, try to make createTables partial succeed.

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
All tables in the createTables batch should either be created successfully together or fail entirely — there should be no partial success.
### 3. What did you see instead (Required)
After the restore process exited, some tables from the batch were still present, indicating a partial creation.
### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
v7.5.5
",open,2025-04-24T06:52:28Z,2025-07-03T08:57:49Z,,"['type/bug', 'severity/major', 'may-affects-6.1', 'may-affects-6.5', 'may-affects-7.1', 'component/ddl', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5']",1,3pointer,[],,bug,['backup'],[],False,True,11
3171836739,61971,"Support Pinning Owner Processes (analyze, ddl) to Specific TiDB Instances","## Feature Request

**Is your feature request related to a problem? Please describe:**
Currently, owner tasks (analyze, ddl, etc.) can be randomly assigned to any TiDB server. In a mixed environment where the same servers handle both OLTP traffic and owner tasks, this can cause load imbalances. The TiDB instance acting as the owner may consume significantly more memory and CPU resources, creating bottlenecks that affect overall cluster performance.

This is a example (Owners is on tidb-7): 
![Image](https://github.com/user-attachments/assets/d3c4c090-6b31-4328-92fa-df38e1535783)
![Image](https://github.com/user-attachments/assets/af3f4771-9b5f-4230-a270-3ac672c962b0)

**Describe the feature you'd like:**
Add a mechanism to pin owner roles (analyze, ddl, etc.) to a designated group of TiDB instances.
For example:
	•	Use a special label (e.g., owner=true) to mark TiDB instances intended for owner roles.
	•	Owner roles would then only be assigned to instances with this label, allowing OLTP instances to remain dedicated to transaction processing.

This feature would help isolate background tasks and optimize resource usage across the TiDB cluster.

**Describe alternatives you've considered:**
Restart the onwer tidb-server(but it is not a good idea).

**Teachability, Documentation, Adoption, Migration Strategy:**
N/A",open,2025-06-24T12:34:56Z,2025-07-03T08:33:31Z,,['type/feature-request'],1,dulao5,[],,other,"['docker', 'mysql', 'performance']",[],False,True,3
3178586318,62020,query information_schema.tables too slow,"## Bug Report

see https://asktug.com/t/topic/1043776

Please answer these questions before submitting your issue. Thanks!

before upgrade in v7.5.6

<img width=""1559"" alt=""Image"" src=""https://github.com/user-attachments/assets/8187a949-31d8-4511-95bd-15abe0e82f91"" />

after upgrade in v8.5.2

<img width=""1533"" alt=""Image"" src=""https://github.com/user-attachments/assets/8e918af8-0c08-4dbb-8d33-13c1e36f2073"" />



<img width=""2967"" alt=""Image"" src=""https://github.com/user-attachments/assets/7f78b34b-3381-481e-a222-2eb3cdd4e27f"" />

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

v8.5.2

",open,2025-06-26T10:09:40Z,2025-07-03T08:02:09Z,,"['type/enhancement', 'component/ddl', 'affects-8.5']",1,crazycs520,[],,enhancement,"['docker', 'performance']",[],False,True,5
3136873112,61680,The multi-schema change DDL gets stuck while MDL is disabled,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)


```
mysql> select @@tidb_enable_metadata_lock;
+-----------------------------+
| @@tidb_enable_metadata_lock |
+-----------------------------+
|                           1 |
+-----------------------------+
1 row in set (0.00 sec)

mysql> create table t(col1 int, col2 int, col3 int);
Query OK, 0 rows affected (0.11 sec)

mysql> set global tidb_enable_metadata_lock=off;
Query OK, 0 rows affected (0.02 sec)

mysql> alter table t drop column col1, drop column col2;
```


### 2. What did you expect to see? (Required)

The alter statement returns quickly.
### 3. What did you see instead (Required)

The statement is stuck.
### 4. What is your TiDB version? (Required)

v6.5.12

",open,2025-06-11T13:38:48Z,2025-07-03T07:27:33Z,,"['type/bug', 'severity/major', 'affects-6.5', 'affects-7.1', 'component/ddl', 'affects-7.5', 'affects-8.1', 'affects-8.5']",1,pcqz,['tangenta'],,bug,['mysql'],[],False,True,13
3144347849,61735,slice bounds out of range,"## Bug Report

### 1. Minimal reproduce step (Required)

```sql
select distinct avg(nullif(77.15, PI())); --runtime error: slice bounds out of range [:1] with capacity 0
```


### 2. What did you expect to see? (Required)
No error

### 3. What did you see instead (Required)


### 4. What is your TiDB version? (Required)

`tiup playground nightly --host 0.0.0.0 --kv 3 --tiflash 3`
```bash
8.0.11-TiDB-v9.0.0-beta.1.pre-554-gb1a5536a64-dirty
```


",closed,2025-06-13T18:08:36Z,2025-07-03T06:55:08Z,2025-07-03T06:55:08Z,"['type/bug', 'sig/execution', 'type/regression', 'severity/major', 'fuzz/sqlancer', 'affects-8.1', 'impact/panic', 'affects-8.5']",4,bajinsheng,['YangKeao'],,bug,['tiflash'],['error:'],True,True,19
2674229574,57530,runtime error: select * from  TIKV_REGION_STATUS where table_id = 81920,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

Start a tidb cluster, the following query:

```
mysql> select * from  TIKV_REGION_STATUS where table_id = 81920;
ERROR 1105 (HY000): runtime error: invalid memory address or nil pointer dereference
```

### 2. What did you expect to see? (Required)

no error

### 3. What did you see instead (Required)

```
mysql> select * from  TIKV_REGION_STATUS where table_id = 81920;
ERROR 1105 (HY000): runtime error: invalid memory address or nil pointer dereference
```

Here is the error stack:

```
[2024/11/20 11:32:02.391 +08:00] [INFO] [conn.go:1184] [""command dispatched failed""] [conn=1524629508] [session_alias=] [connInfo=""id:1524629508, addr:127.0.0.1:38948 status:10, collation:utf8mb4_0900_ai_ci, user:root""] [command=Query] [status=""inTxn:0, autocommit:1""] [sql=""select * from  TIKV_REGION_STATUS where table_id = 81920""] [txn_mode=PESSIMISTIC] [timestamp=0] [err=""runtime error: invalid memory address or nil pointer dereference
github.com/pingcap/errors.AddStack
	/home/genius/go/pkg/mod/github.com/pingcap/errors@v0.11.5-0.20240318064555-6bd07397691f/errors.go:178
github.com/pingcap/errors.Trace
	/home/genius/go/pkg/mod/github.com/pingcap/errors@v0.11.5-0.20240318064555-6bd07397691f/juju_adaptor.go:15
github.com/pingcap/tidb/pkg/util.GetRecoverError
	/home/genius/project/src/github.com/pingcap/tidb/pkg/util/util.go:288
github.com/pingcap/tidb/pkg/executor/internal/exec.Next.func1
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/internal/exec/executor.go:440
runtime.gopanic
	/home/genius/project/go/src/runtime/panic.go:785
runtime.panicmem
	/home/genius/project/go/src/runtime/panic.go:262
runtime.sigpanic
	/home/genius/project/go/src/runtime/signal_unix.go:900
github.com/pingcap/tidb/pkg/store/helper.(*Helper).GetRegionsTableInfo
	/home/genius/project/src/github.com/pingcap/tidb/pkg/store/helper/helper.go:684
github.com/pingcap/tidb/pkg/executor.(*memtableRetriever).setDataForTiKVRegionStatus
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/infoschema_reader.go:1975
github.com/pingcap/tidb/pkg/executor.(*memtableRetriever).retrieve
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/infoschema_reader.go:164
github.com/pingcap/tidb/pkg/executor.(*MemTableReaderExec).Next
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/memtable_reader.go:120
github.com/pingcap/tidb/pkg/executor/internal/exec.Next
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/internal/exec/executor.go:456
github.com/pingcap/tidb/pkg/executor.(*ExecStmt).next
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/adapter.go:1266
github.com/pingcap/tidb/pkg/executor.(*recordSet).Next
	/home/genius/project/src/github.com/pingcap/tidb/pkg/executor/adapter.go:172
github.com/pingcap/tidb/pkg/server/internal/resultset.(*tidbResultSet).Next
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/internal/resultset/resultset.go:72
github.com/pingcap/tidb/pkg/server.(*clientConn).writeChunks
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:2319
github.com/pingcap/tidb/pkg/server.(*clientConn).writeResultSet
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:2262
github.com/pingcap/tidb/pkg/server.(*clientConn).handleStmt
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:2065
github.com/pingcap/tidb/pkg/server.(*clientConn).handleQuery
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:1779
github.com/pingcap/tidb/pkg/server.(*clientConn).dispatch
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:1378
github.com/pingcap/tidb/pkg/server.(*clientConn).Run
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/conn.go:1147
github.com/pingcap/tidb/pkg/server.(*Server).onConn
	/home/genius/project/src/github.com/pingcap/tidb/pkg/server/server.go:741
runtime.goexit
	/home/genius/project/go/src/runtime/asm_amd64.s:
1700""]
```

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2024-11-20T03:38:14Z,2025-07-03T06:38:28Z,2024-11-20T13:41:40Z,"['type/bug', 'sig/sql-infra', 'severity/major', 'affects-6.5', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'impact/panic', 'affects-8.5']",0,tiancaiamao,['tiancaiamao'],,bug,"['mysql', 'backup', 'tikv']",['error:'],False,False,12
2057297443,49859,Performance jitter in 11D statements of Join Order Benchmark,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
1. deploy cluster with 1 tidb +3 tikv
2. run join order benchmark - 11D
```
SELECT
	MIN(cn.name) AS from_company,
	MIN(mc.note) AS production_note,
	MIN(t.title) AS movie_based_on_book
FROM
	company_name AS cn,
	company_type AS ct,
	keyword AS k,
	link_type AS lt,
	movie_companies AS mc,
	movie_keyword AS mk,
	movie_link AS ml,
	title AS t
WHERE
	cn.country_code != '[pl]'
	AND ct.kind != 'production companies'
	and ct.kind is not NULL
	AND k.keyword in ('sequel', 'revenge', 'based-on-novel')
	AND mc.note is not NULL
	AND t.production_year > 1950
	AND lt.id = ml.link_type_id
	AND ml.movie_id = t.id
	AND t.id = mk.movie_id
	AND mk.keyword_id = k.id
	AND t.id = mc.movie_id
	AND mc.company_type_id = ct.id
	AND mc.company_id = cn.id
	AND ml.movie_id = mk.movie_id
	AND ml.movie_id = mc.movie_id
	AND mk.movie_id = mc.movie_id;

```
### 2. What did you expect to see? (Required)

```
Baseline Execution Plans
Plan_Digest: 6df5d21ab577975303577b1283c20ef0 Elapsed_Time (s): 162.3 

+------------------------------------------+------------+------------+-----------+---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+
| ID                                       | ESTROWS    | ACTROWS    | TASK      | ACCESS OBJECT                               | EXECUTION INFO                                                                                                                                                                                                                                                                                                                                                                                                                                   | OPERATOR INFO                                                                                                                                                                               | MEMORY    | DISK    |
+------------------------------------------+------------+------------+-----------+---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+
| HashAgg_35                               | 1.00       | 1          | root      |                                             | time:2m42.3s, loops:2, RU:20581.276319, partial_worker:{wall_time:2m42.287510425s, concurrency:5, task_num:9009, tot_wait:13m30.05205941s, tot_exec:1.383332707s, tot_time:13m31.437332833s, max:2m42.287490326s, p95:2m42.287490326s}, final_worker:{wall_time:2m42.287533312s, concurrency:5, task_num:5, tot_wait:13m31.437519239s, tot_exec:41.425µs, tot_time:13m31.437563769s, max:2m42.287521969s, p95:2m42.287521969s}                   | funcs:min(imdb.company_name.name)->Column#39, funcs:min(imdb.movie_companies.note)->Column#40, funcs:min(imdb.title.title)->Column#41                                                       | 2.41 MB   | N/A     |
| └─Projection_37                          | 4911.99    | 9221275    | root      |                                             | time:2m42.3s, loops:9010, Concurrency:5                                                                                                                                                                                                                                                                                                                                                                                                          | imdb.company_name.name, imdb.movie_companies.note, imdb.title.title                                                                                                                         | 2.25 MB   | N/A     |
|   └─HashJoin_50                          | 4911.99    | 9221275    | root      |                                             | time:2m42.3s, loops:9010, build_hash_table:{total:4.4ms, fetch:4.39ms, build:12.2µs}, probe:{concurrency:5, total:13m31.4s, max:2m42.3s, probe:2m54.1s, fetch:10m37.4s}                                                                                                                                                                                                                                                                          | inner join, equal:[eq(imdb.movie_keyword.keyword_id, imdb.keyword.id)]                                                                                                                      | 25.7 KB   | 0 Bytes |
|     ├─IndexLookUp_233(Build)             | 137.38     | 3          | root      |                                             | time:4.36ms, loops:2, index_task: {total_time: 689.5µs, fetch_handle: 685.2µs, build: 1.34µs, wait: 2.92µs}, table_task: {total_time: 3.59ms, num: 1, concurrency: 5}, next: {wait_index: 751.3µs, wait_table_lookup_build: 174.3µs, wait_table_lookup_resp: 3.41ms}                                                                                                                                                                             |                                                                                                                                                                                             | 13.0 KB   | N/A     |
|     │ ├─IndexRangeScan_230(Build)        | 137.38     | 258        | cop[tikv] | table:k, index:keyword_idx_keyword(keyword) | time:665.2µs, loops:3, cop_task: {num: 1, max: 589.3µs, proc_keys: 258, tot_proc: 202.9µs, tot_wait: 27.5µs, rpc_num: 1, rpc_time: 571.2µs, copr_cache_hit_ratio: 0.00, build_task_duration: 14.7µs, max_distsql_concurrency: 1}, tikv_task:{time:0s, loops:4}, scan_detail: {total_process_keys: 258, total_process_keys_size: 11868, total_keys: 261, get_snapshot_time: 10µs, rocksdb: {key_skipped_count: 258, block: {cache_hit_count: 6}}} | range:[""based"",""based""], [""reven"",""reven""], [""seque"",""seque""], keep order:false                                                                                                             | N/A       | N/A     |
|     │ └─Selection_232(Probe)             | 137.38     | 3          | cop[tikv] |                                             | time:3.39ms, loops:2, cop_task: {num: 1, max: 3.28ms, proc_keys: 258, tot_proc: 2.39ms, tot_wait: 37.4µs, rpc_num: 1, rpc_time: 3.25ms, copr_cache_hit_ratio: 0.00, build_task_duration: 32.7µs, max_distsql_concurrency: 1}, tikv_task:{time:3ms, loops:4}, scan_detail: {total_process_keys: 258, total_process_keys_size: 16408, total_keys: 265, get_snapshot_time: 18µs, rocksdb: {key_skipped_count: 14, block: {cache_hit_count: 448}}}   | in(imdb.keyword.keyword, ""sequel"", ""revenge"", ""based-on-novel"")                                                                                                                             | N/A       | N/A     |
|     │   └─TableRowIDScan_231             | 137.38     | 258        | cop[tikv] | table:k                                     | tikv_task:{time:3ms, loops:4}                                                                                                                                                                                                                                                                                                                                                                                                                    | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|     └─HashJoin_64(Probe)                 | 8378871.38 | 2581940039 | root      |                                             | time:2m39.8s, loops:2521430, build_hash_table:{total:5s, fetch:1.89s, build:3.11s}, probe:{concurrency:5, total:13m18.8s, max:2m42.3s, probe:12m53.7s, fetch:25.1s}                                                                                                                                                                                                                                                                              | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.movie_keyword.movie_id) eq(imdb.movie_link.movie_id, imdb.movie_keyword.movie_id) eq(imdb.title.id, imdb.movie_keyword.movie_id)] | 2.34 GB   | 0 Bytes |
|       ├─HashJoin_75(Build)               | 2585150.00 | 17625104   | root      |                                             | time:2s, loops:17214, build_hash_table:{total:77.7µs, fetch:57.3µs, build:20.4µs}, probe:{concurrency:5, total:25s, max:5s, probe:15.9s, fetch:9.11s}                                                                                                                                                                                                                                                                                            | inner join, equal:[eq(imdb.movie_link.link_type_id, imdb.link_type.id)]                                                                                                                     | 9.46 KB   | 0 Bytes |
|       │ ├─TableReader_225(Build)         | 18.00      | 18         | root      |                                             | time:36.7µs, loops:2, cop_task: {num: 1, max: 298.8µs, proc_keys: 18, tot_proc: 47.5µs, tot_wait: 19.7µs, rpc_num: 1, rpc_time: 284µs, copr_cache_hit_ratio: 0.00, build_task_duration: 1.9µs, max_distsql_concurrency: 1}                                                                                                                                                                                                                       | data:TableFullScan_224                                                                                                                                                                      | 385 Bytes | N/A     |
|       │ │ └─TableFullScan_224            | 18.00      | 18         | cop[tikv] | table:lt                                    | tikv_task:{time:0s, loops:1}, scan_detail: {total_process_keys: 18, total_process_keys_size: 486, total_keys: 19, get_snapshot_time: 7.34µs, rocksdb: {key_skipped_count: 18, block: {cache_hit_count: 2}}}                                                                                                                                                                                                                                      | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │ └─HashJoin_88(Probe)             | 2585150.00 | 17625104   | root      |                                             | time:1.84s, loops:17215, build_hash_table:{total:1.03s, fetch:678.3ms, build:352.6ms}, probe:{concurrency:5, total:25s, max:5s, probe:16s, fetch:9.02s}                                                                                                                                                                                                                                                                                          | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.movie_link.movie_id) eq(imdb.title.id, imdb.movie_link.movie_id)]                                                                 | 96.6 MB   | 0 Bytes |
|       │   ├─TableReader_223(Build)       | 2585150.00 | 2585150    | root      |                                             | time:677ms, loops:2528, cop_task: {num: 3, max: 862.1ms, min: 365.6µs, avg: 449.6ms, p95: 862.1ms, max_proc_keys: 1280000, p95_proc_keys: 1280000, tot_proc: 1.3s, tot_wait: 58.3µs, rpc_num: 3, rpc_time: 1.35s, copr_cache_hit_ratio: 0.33, build_task_duration: 7.09µs, max_distsql_concurrency: 3}                                                                                                                                           | data:TableFullScan_222                                                                                                                                                                      | 32.9 MB   | N/A     |
|       │   │ └─TableFullScan_222          | 2585150.00 | 2585150    | cop[tikv] | table:ml                                    | tikv_task:{proc max:783ms, min:438ms, avg: 587.3ms, p80:783ms, p95:783ms, iters:2539, tasks:3}, scan_detail: {total_process_keys: 2156027, total_process_keys_size: 109946493, total_keys: 2156029, get_snapshot_time: 18.4µs, rocksdb: {key_skipped_count: 2156027, block: {cache_hit_count: 4198}}}                                                                                                                                            | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │   └─HashJoin_102(Probe)          | 2307846.25 | 1714499    | root      |                                             | time:1.81s, loops:1678, build_hash_table:{total:1.8s, fetch:356.6ms, build:1.44s}, probe:{concurrency:5, total:24.8s, max:4.97s, probe:15.8s, fetch:9.01s}                                                                                                                                                                                                                                                                                       | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.title.id)]                                                                                                                        | 402.8 MB  | 0 Bytes |
|       │     ├─TableReader_218(Build)     | 4247586.00 | 4247643    | root      |                                             | time:359.5ms, loops:4507, cop_task: {num: 6, max: 917.6ms, min: 344.9ms, avg: 603.2ms, p95: 917.6ms, max_proc_keys: 1107917, p95_proc_keys: 1107917, tot_proc: 3.37s, tot_wait: 120.8µs, rpc_num: 6, rpc_time: 3.62s, copr_cache_hit_ratio: 0.00, build_task_duration: 11.4µs, max_distsql_concurrency: 6}                                                                                                                                       | data:Selection_217                                                                                                                                                                          | 102.4 MB  | N/A     |
|       │     │ └─Selection_217            | 4247586.00 | 4247643    | cop[tikv] |                                             | tikv_task:{proc max:764ms, min:288ms, avg: 493.8ms, p80:700ms, p95:764ms, iters:4653, tasks:6}, scan_detail: {total_process_keys: 4736508, total_process_keys_size: 524795377, total_keys: 4736514, get_snapshot_time: 39.8µs, rocksdb: {key_skipped_count: 4736611, block: {cache_hit_count: 17914}}}                                                                                                                                           | gt(imdb.title.production_year, 1950)                                                                                                                                                        | N/A       | N/A     |
|       │     │   └─TableFullScan_216      | 4736508.00 | 4736508    | cop[tikv] | table:t                                     | tikv_task:{proc max:734ms, min:283ms, avg: 473ms, p80:664ms, p95:734ms, iters:4653, tasks:6}                                                                                                                                                                                                                                                                                                                                                     | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │     └─HashJoin_146(Probe)        | 2288639.00 | 1954290    | root      |                                             | time:582.4ms, loops:1911, build_hash_table:{total:515.5ms, fetch:433.2ms, build:82.3ms}, probe:{concurrency:5, total:24.6s, max:4.94s, probe:21.7s, fetch:2.9s}                                                                                                                                                                                                                                                                                  | inner join, equal:[eq(imdb.movie_companies.company_id, imdb.company_name.id)]                                                                                                               | 38.1 MB   | 0 Bytes |
|       │       ├─TableReader_215(Build)   | 337886.00  | 337601     | root      |                                             | time:433.1ms, loops:355, cop_task: {num: 1, max: 433.2ms, proc_keys: 362131, tot_proc: 414.1ms, tot_wait: 353µs, rpc_num: 1, rpc_time: 433.2ms, copr_cache_hit_ratio: 0.00, build_task_duration: 5.25µs, max_distsql_concurrency: 1}                                                                                                                                                                                                             | data:Selection_214                                                                                                                                                                          | 14.9 MB   | N/A     |
|       │       │ └─Selection_214          | 337886.00  | 337601     | cop[tikv] |                                             | tikv_task:{time:363ms, loops:358}, scan_detail: {total_process_keys: 362131, total_process_keys_size: 40171508, total_keys: 362132, get_snapshot_time: 336.5µs, rocksdb: {key_skipped_count: 362131, block: {cache_hit_count: 1373}}}                                                                                                                                                                                                            | ne(imdb.company_name.country_code, ""[pl]"")                                                                                                                                                  | N/A       | N/A     |
|       │       │   └─TableFullScan_213    | 362131.00  | 362131     | cop[tikv] | table:cn                                    | tikv_task:{time:323ms, loops:358}                                                                                                                                                                                                                                                                                                                                                                                                                | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │       └─HashJoin_194(Probe)      | 2288639.00 | 1980874    | root      |                                             | time:582.8ms, loops:1938, build_hash_table:{total:63.3µs, fetch:58µs, build:5.29µs}, probe:{concurrency:5, total:24.5s, max:4.91s, probe:21.6s, fetch:2.89s}                                                                                                                                                                                                                                                                                     | inner join, equal:[eq(imdb.company_type.id, imdb.movie_companies.company_type_id)]                                                                                                          | 25.7 KB   | 0 Bytes |
|       │         ├─TableReader_205(Build) | 3.20       | 3          | root      |                                             | time:27.1µs, loops:2, cop_task: {num: 1, max: 662.9µs, proc_keys: 4, tot_proc: 51.8µs, tot_wait: 356.1µs, rpc_num: 1, rpc_time: 649.2µs, copr_cache_hit_ratio: 0.00, build_task_duration: 4.85µs, max_distsql_concurrency: 1}                                                                                                                                                                                                                    | data:Selection_204                                                                                                                                                                          | 381 Bytes | N/A     |
|       │         │ └─Selection_204        | 3.20       | 3          | cop[tikv] |                                             | tikv_task:{time:0s, loops:1}, scan_detail: {total_process_keys: 4, total_process_keys_size: 224, total_keys: 5, get_snapshot_time: 340.6µs, rocksdb: {key_skipped_count: 4, block: {cache_hit_count: 2}}}                                                                                                                                                                                                                                        | ne(imdb.company_type.kind, ""production companies""), not(isnull(imdb.company_type.kind))                                                                                                     | N/A       | N/A     |
|       │         │   └─TableFullScan_203  | 4.00       | 4          | cop[tikv] | table:ct                                    | tikv_task:{time:0s, loops:1}                                                                                                                                                                                                                                                                                                                                                                                                                     | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │         └─TableReader_212(Probe) | 2288639.00 | 2288639    | root      |                                             | time:585.1ms, loops:2306, cop_task: {num: 5, max: 1.04s, min: 621.4µs, avg: 472.5ms, p95: 1.04s, max_proc_keys: 1185298, p95_proc_keys: 1185298, tot_proc: 2.19s, tot_wait: 1.76ms, rpc_num: 5, rpc_time: 2.36s, copr_cache_hit_ratio: 0.40, build_task_duration: 9.46µs, max_distsql_concurrency: 5}                                                                                                                                            | data:Selection_211                                                                                                                                                                          | 110.8 MB  | N/A     |
|       │           └─Selection_211        | 2288639.00 | 2288639    | cop[tikv] |                                             | tikv_task:{proc max:809ms, min:463ms, avg: 673.6ms, p80:809ms, p95:809ms, iters:4864, tasks:5}, scan_detail: {total_process_keys: 2969382, total_process_keys_size: 202617625, total_keys: 2969385, get_snapshot_time: 1.68ms, rocksdb: {key_skipped_count: 2969383, block: {cache_hit_count: 7347}}}                                                                                                                                            | not(isnull(imdb.movie_companies.note))                                                                                                                                                      | N/A       | N/A     |
|       │             └─TableFullScan_210  | 4958296.00 | 4958296    | cop[tikv] | table:mc                                    | tikv_task:{proc max:741ms, min:399ms, avg: 619.6ms, p80:741ms, p95:741ms, iters:4864, tasks:5}                                                                                                                                                                                                                                                                                                                                                   | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       └─TableReader_229(Probe)           | 7480087.00 | 7480087    | root      |                                             | time:44.2ms, loops:7311, cop_task: {num: 10, max: 669.9ms, min: 258.7µs, avg: 336.6ms, p95: 669.9ms, max_proc_keys: 960000, p95_proc_keys: 960000, tot_proc: 3.24s, tot_wait: 219µs, rpc_num: 10, rpc_time: 3.37s, copr_cache_hit_ratio: 0.40, build_task_duration: 17.8µs, max_distsql_concurrency: 10}                                                                                                                                         | data:TableFullScan_228                                                                                                                                                                      | 114.3 MB  | N/A     |
|         └─TableFullScan_228              | 7480087.00 | 7480087    | cop[tikv] | table:mk                                    | tikv_task:{proc max:604ms, min:343ms, avg: 486.2ms, p80:599ms, p95:604ms, iters:7350, tasks:10}, scan_detail: {total_process_keys: 5307746, total_process_keys_size: 240613872, total_keys: 5307752, get_snapshot_time: 73.9µs, rocksdb: {key_skipped_count: 5307746, block: {cache_hit_count: 9408}}}                                                                                                                                           | keep order:false                                                                                                                                                                            | N/A       | N/A     |
+------------------------------------------+------------+------------+-----------+---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+

```

### 3. What did you see instead (Required)
The elapsed time of 11D ranges from 162s to 195s
![image](https://github.com/pingcap/tidb/assets/84501897/e3681f03-4eaa-4d53-a965-b5bb5837c671)
```
Olap_Detail_Log_ID: 6295290   Plan_Digest: 6df5d21ab577975303577b1283c20ef0 Elapsed_Time (s): 195.5 

+------------------------------------------+------------+------------+-----------+---------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+
| ID                                       | ESTROWS    | ACTROWS    | TASK      | ACCESS OBJECT                               | EXECUTION INFO                                                                                                                                                                                                                                                                                                                                                                                                                                    | OPERATOR INFO                                                                                                                                                                               | MEMORY    | DISK    |
+------------------------------------------+------------+------------+-----------+---------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+
| HashAgg_35                               | 1.00       | 1          | root      |                                             | time:3m15.5s, loops:2, RU:21598.602762, partial_worker:{wall_time:3m15.526680121s, concurrency:5, task_num:9008, tot_wait:16m15.894038691s, tot_exec:1.736775085s, tot_time:16m17.632883533s, max:3m15.526652138s, p95:3m15.526652138s}, final_worker:{wall_time:3m15.526689401s, concurrency:5, task_num:20, tot_wait:16m17.633273823s, tot_exec:11.254µs, tot_time:16m17.633290392s, max:3m15.5266614s, p95:3m15.5266614s}                      | funcs:min(imdb.company_name.name)->Column#39, funcs:min(imdb.movie_companies.note)->Column#40, funcs:min(imdb.title.title)->Column#41                                                       | 2.40 MB   | N/A     |
| └─Projection_37                          | 4946.92    | 9221275    | root      |                                             | time:3m15.5s, loops:9009, Concurrency:5                                                                                                                                                                                                                                                                                                                                                                                                           | imdb.company_name.name, imdb.movie_companies.note, imdb.title.title                                                                                                                         | 2.25 MB   | N/A     |
|   └─HashJoin_50                          | 4946.92    | 9221275    | root      |                                             | time:3m15.5s, loops:9009, build_hash_table:{total:4.04ms, fetch:4.03ms, build:5.19µs}, probe:{concurrency:5, total:16m17.6s, max:3m15.5s, probe:3m18.9s, fetch:12m58.7s}                                                                                                                                                                                                                                                                          | inner join, equal:[eq(imdb.movie_keyword.keyword_id, imdb.keyword.id)]                                                                                                                      | 25.7 KB   | 0 Bytes |
|     ├─IndexLookUp_233(Build)             | 138.35     | 3          | root      |                                             | time:3.97ms, loops:2, index_task: {total_time: 857.2µs, fetch_handle: 853.4µs, build: 1.32µs, wait: 2.47µs}, table_task: {total_time: 3.01ms, num: 1, concurrency: 5}, next: {wait_index: 944.5µs, wait_table_lookup_build: 319.4µs, wait_table_lookup_resp: 2.67ms}                                                                                                                                                                              |                                                                                                                                                                                             | 13.0 KB   | N/A     |
|     │ ├─IndexRangeScan_230(Build)        | 138.35     | 258        | cop[tikv] | table:k, index:keyword_idx_keyword(keyword) | time:830.9µs, loops:3, cop_task: {num: 1, max: 742µs, proc_keys: 258, tot_proc: 325.6µs, tot_wait: 23.9µs, rpc_num: 1, rpc_time: 725.2µs, copr_cache_hit_ratio: 0.00, build_task_duration: 15.5µs, max_distsql_concurrency: 1}, tikv_task:{time:1ms, loops:4}, scan_detail: {total_process_keys: 258, total_process_keys_size: 11868, total_keys: 261, get_snapshot_time: 8.81µs, rocksdb: {key_skipped_count: 258, block: {cache_hit_count: 6}}} | range:[""based"",""based""], [""reven"",""reven""], [""seque"",""seque""], keep order:false                                                                                                             | N/A       | N/A     |
|     │ └─Selection_232(Probe)             | 138.35     | 3          | cop[tikv] |                                             | time:2.65ms, loops:2, cop_task: {num: 1, max: 2.56ms, proc_keys: 258, tot_proc: 1.67ms, tot_wait: 25µs, rpc_num: 1, rpc_time: 2.53ms, copr_cache_hit_ratio: 0.00, build_task_duration: 77.5µs, max_distsql_concurrency: 1}, tikv_task:{time:2ms, loops:4}, scan_detail: {total_process_keys: 258, total_process_keys_size: 16408, total_keys: 265, get_snapshot_time: 8.6µs, rocksdb: {key_skipped_count: 14, block: {cache_hit_count: 448}}}     | in(imdb.keyword.keyword, ""sequel"", ""revenge"", ""based-on-novel"")                                                                                                                             | N/A       | N/A     |
|     │   └─TableRowIDScan_231             | 138.35     | 258        | cop[tikv] | table:k                                     | tikv_task:{time:1ms, loops:4}                                                                                                                                                                                                                                                                                                                                                                                                                     | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|     └─HashJoin_64(Probe)                 | 8378871.38 | 2581940039 | root      |                                             | time:3m12.9s, loops:2521429, build_hash_table:{total:4.95s, fetch:1.96s, build:2.99s}, probe:{concurrency:5, total:16m6.3s, max:3m15.5s, probe:15m41.4s, fetch:24.8s}                                                                                                                                                                                                                                                                             | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.movie_keyword.movie_id) eq(imdb.movie_link.movie_id, imdb.movie_keyword.movie_id) eq(imdb.title.id, imdb.movie_keyword.movie_id)] | 2.34 GB   | 0 Bytes |
|       ├─HashJoin_75(Build)               | 2585150.00 | 17625104   | root      |                                             | time:2.09s, loops:17216, build_hash_table:{total:57.7µs, fetch:49µs, build:8.75µs}, probe:{concurrency:5, total:24.8s, max:4.95s, probe:15.3s, fetch:9.48s}                                                                                                                                                                                                                                                                                       | inner join, equal:[eq(imdb.movie_link.link_type_id, imdb.link_type.id)]                                                                                                                     | 9.46 KB   | 0 Bytes |
|       │ ├─TableReader_225(Build)         | 18.00      | 18         | root      |                                             | time:28.6µs, loops:2, cop_task: {num: 1, max: 312.5µs, proc_keys: 18, tot_proc: 42.3µs, tot_wait: 21.1µs, rpc_num: 1, rpc_time: 296.4µs, copr_cache_hit_ratio: 0.00, build_task_duration: 1.94µs, max_distsql_concurrency: 1}                                                                                                                                                                                                                     | data:TableFullScan_224                                                                                                                                                                      | 385 Bytes | N/A     |
|       │ │ └─TableFullScan_224            | 18.00      | 18         | cop[tikv] | table:lt                                    | tikv_task:{time:0s, loops:1}, scan_detail: {total_process_keys: 18, total_process_keys_size: 486, total_keys: 19, get_snapshot_time: 6.18µs, rocksdb: {key_skipped_count: 18, block: {cache_hit_count: 2}}}                                                                                                                                                                                                                                       | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │ └─HashJoin_88(Probe)             | 2585150.00 | 17625104   | root      |                                             | time:1.93s, loops:17216, build_hash_table:{total:1.07s, fetch:718.2ms, build:353.3ms}, probe:{concurrency:5, total:24.7s, max:4.95s, probe:15.3s, fetch:9.34s}                                                                                                                                                                                                                                                                                    | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.movie_link.movie_id) eq(imdb.title.id, imdb.movie_link.movie_id)]                                                                 | 96.6 MB   | 0 Bytes |
|       │   ├─TableReader_223(Build)       | 2585150.00 | 2585150    | root      |                                             | time:717.1ms, loops:2528, cop_task: {num: 3, max: 893.9ms, min: 302.5µs, avg: 534.2ms, p95: 893.9ms, max_proc_keys: 1280000, p95_proc_keys: 1280000, tot_proc: 1.55s, tot_wait: 63.7µs, rpc_num: 3, rpc_time: 1.6s, copr_cache_hit_ratio: 0.33, build_task_duration: 6.8µs, max_distsql_concurrency: 3}                                                                                                                                           | data:TableFullScan_222                                                                                                                                                                      | 32.9 MB   | N/A     |
|       │   │ └─TableFullScan_222          | 2585150.00 | 2585150    | cop[tikv] | table:ml                                    | tikv_task:{proc max:820ms, min:241ms, avg: 569.3ms, p80:820ms, p95:820ms, iters:2539, tasks:3}, scan_detail: {total_process_keys: 2156027, total_process_keys_size: 109946493, total_keys: 2156029, get_snapshot_time: 20.2µs, rocksdb: {key_skipped_count: 2156027, block: {cache_hit_count: 4198}}}                                                                                                                                             | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │   └─HashJoin_102(Probe)          | 2307846.25 | 1714499    | root      |                                             | time:1.87s, loops:1678, build_hash_table:{total:1.86s, fetch:440.9ms, build:1.42s}, probe:{concurrency:5, total:24.5s, max:4.91s, probe:15.1s, fetch:9.33s}                                                                                                                                                                                                                                                                                       | inner join, equal:[eq(imdb.movie_companies.movie_id, imdb.title.id)]                                                                                                                        | 402.8 MB  | 0 Bytes |
|       │     ├─TableReader_218(Build)     | 4196105.00 | 4247643    | root      |                                             | time:444ms, loops:4507, cop_task: {num: 6, max: 1.04s, min: 326.9ms, avg: 691.4ms, p95: 1.04s, max_proc_keys: 1107917, p95_proc_keys: 1107917, tot_proc: 3.88s, tot_wait: 132.5µs, rpc_num: 6, rpc_time: 4.15s, copr_cache_hit_ratio: 0.00, build_task_duration: 9.78µs, max_distsql_concurrency: 6}                                                                                                                                              | data:Selection_217                                                                                                                                                                          | 102.4 MB  | N/A     |
|       │     │ └─Selection_217            | 4196105.00 | 4247643    | cop[tikv] |                                             | tikv_task:{proc max:870ms, min:261ms, avg: 575.5ms, p80:808ms, p95:870ms, iters:4653, tasks:6}, scan_detail: {total_process_keys: 4736508, total_process_keys_size: 524795377, total_keys: 4736514, get_snapshot_time: 42.9µs, rocksdb: {key_skipped_count: 4736611, block: {cache_hit_count: 17914}}}                                                                                                                                            | gt(imdb.title.production_year, 1950)                                                                                                                                                        | N/A       | N/A     |
|       │     │   └─TableFullScan_216      | 4736508.00 | 4736508    | cop[tikv] | table:t                                     | tikv_task:{proc max:841ms, min:250ms, avg: 554.3ms, p80:771ms, p95:841ms, iters:4653, tasks:6}                                                                                                                                                                                                                                                                                                                                                    | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │     └─HashJoin_146(Probe)        | 2288639.00 | 1954290    | root      |                                             | time:700.2ms, loops:1912, build_hash_table:{total:457.8ms, fetch:362.7ms, build:95.1ms}, probe:{concurrency:5, total:24.2s, max:4.85s, probe:20.7s, fetch:3.48s}                                                                                                                                                                                                                                                                                  | inner join, equal:[eq(imdb.movie_companies.company_id, imdb.company_name.id)]                                                                                                               | 38.1 MB   | 0 Bytes |
|       │       ├─TableReader_215(Build)   | 337882.00  | 337601     | root      |                                             | time:362.4ms, loops:355, cop_task: {num: 1, max: 362.5ms, proc_keys: 362131, tot_proc: 332.9ms, tot_wait: 247.2µs, rpc_num: 1, rpc_time: 362.5ms, copr_cache_hit_ratio: 0.00, build_task_duration: 1.9µs, max_distsql_concurrency: 1}                                                                                                                                                                                                             | data:Selection_214                                                                                                                                                                          | 14.9 MB   | N/A     |
|       │       │ └─Selection_214          | 337882.00  | 337601     | cop[tikv] |                                             | tikv_task:{time:294ms, loops:358}, scan_detail: {total_process_keys: 362131, total_process_keys_size: 40171508, total_keys: 362132, get_snapshot_time: 229.2µs, rocksdb: {key_skipped_count: 362131, block: {cache_hit_count: 1373}}}                                                                                                                                                                                                             | ne(imdb.company_name.country_code, ""[pl]"")                                                                                                                                                  | N/A       | N/A     |
|       │       │   └─TableFullScan_213    | 362131.00  | 362131     | cop[tikv] | table:cn                                    | tikv_task:{time:266ms, loops:358}                                                                                                                                                                                                                                                                                                                                                                                                                 | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │       └─HashJoin_194(Probe)      | 2288639.00 | 1980874    | root      |                                             | time:699.5ms, loops:1937, build_hash_table:{total:121.9µs, fetch:114µs, build:7.88µs}, probe:{concurrency:5, total:24.1s, max:4.83s, probe:20.6s, fetch:3.47s}                                                                                                                                                                                                                                                                                    | inner join, equal:[eq(imdb.company_type.id, imdb.movie_companies.company_type_id)]                                                                                                          | 25.7 KB   | 0 Bytes |
|       │         ├─TableReader_205(Build) | 3.20       | 3          | root      |                                             | time:58.7µs, loops:2, cop_task: {num: 1, max: 694.1µs, proc_keys: 4, tot_proc: 53.2µs, tot_wait: 255.1µs, rpc_num: 1, rpc_time: 668.3µs, copr_cache_hit_ratio: 0.00, build_task_duration: 6.2µs, max_distsql_concurrency: 1}                                                                                                                                                                                                                      | data:Selection_204                                                                                                                                                                          | 381 Bytes | N/A     |
|       │         │ └─Selection_204        | 3.20       | 3          | cop[tikv] |                                             | tikv_task:{time:0s, loops:1}, scan_detail: {total_process_keys: 4, total_process_keys_size: 224, total_keys: 5, get_snapshot_time: 242.8µs, rocksdb: {key_skipped_count: 4, block: {cache_hit_count: 2}}}                                                                                                                                                                                                                                         | ne(imdb.company_type.kind, ""production companies""), not(isnull(imdb.company_type.kind))                                                                                                     | N/A       | N/A     |
|       │         │   └─TableFullScan_203  | 4.00       | 4          | cop[tikv] | table:ct                                    | tikv_task:{time:0s, loops:1}                                                                                                                                                                                                                                                                                                                                                                                                                      | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       │         └─TableReader_212(Probe) | 2288639.00 | 2288639    | root      |                                             | time:702.5ms, loops:2307, cop_task: {num: 5, max: 1.15s, min: 263.2µs, avg: 515.8ms, p95: 1.15s, max_proc_keys: 1185298, p95_proc_keys: 1185298, tot_proc: 2.41s, tot_wait: 584.9µs, rpc_num: 5, rpc_time: 2.58s, copr_cache_hit_ratio: 0.40, build_task_duration: 12.8µs, max_distsql_concurrency: 5}                                                                                                                                            | data:Selection_211                                                                                                                                                                          | 110.8 MB  | N/A     |
|       │           └─Selection_211        | 2288639.00 | 2288639    | cop[tikv] |                                             | tikv_task:{proc max:908ms, min:565ms, avg: 672.6ms, p80:908ms, p95:908ms, iters:4864, tasks:5}, scan_detail: {total_process_keys: 2969382, total_process_keys_size: 202617625, total_keys: 2969385, get_snapshot_time: 507.9µs, rocksdb: {key_skipped_count: 2969383, block: {cache_hit_count: 7347}}}                                                                                                                                            | not(isnull(imdb.movie_companies.note))                                                                                                                                                      | N/A       | N/A     |
|       │             └─TableFullScan_210  | 4958296.00 | 4958296    | cop[tikv] | table:mc                                    | tikv_task:{proc max:813ms, min:514ms, avg: 617ms, p80:813ms, p95:813ms, iters:4864, tasks:5}                                                                                                                                                                                                                                                                                                                                                      | keep order:false                                                                                                                                                                            | N/A       | N/A     |
|       └─TableReader_229(Probe)           | 7480087.00 | 7480087    | root      |                                             | time:51ms, loops:7311, cop_task: {num: 10, max: 867.7ms, min: 196.6µs, avg: 420.3ms, p95: 867.7ms, max_proc_keys: 960000, p95_proc_keys: 960000, tot_proc: 4.05s, tot_wait: 223.5µs, rpc_num: 10, rpc_time: 4.2s, copr_cache_hit_ratio: 0.30, build_task_duration: 22.7µs, max_distsql_concurrency: 10}                                                                                                                                           | data:TableFullScan_228                                                                                                                                                                      | 114.3 MB  | N/A     |
|         └─TableFullScan_228              | 7480087.00 | 7480087    | cop[tikv] | table:mk                                    | tikv_task:{proc max:796ms, min:313ms, avg: 482.9ms, p80:717ms, p95:796ms, iters:7350, tasks:10}, scan_detail: {total_process_keys: 5957358, total_process_keys_size: 270050336, total_keys: 5957365, get_snapshot_time: 64.9µs, rocksdb: {key_skipped_count: 5957358, block: {cache_hit_count: 10560}}}                                                                                                                                           | keep order:false                                                                                                                                                                            | N/A       | N/A     |
+------------------------------------------+------------+------------+-----------+---------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------+

```

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
Since https://github.com/pingcap/tidb/pull/48264

",open,2023-12-27T12:07:18Z,2025-07-03T05:52:09Z,,"['type/bug', 'type/performance', 'sig/execution', 'type/regression', 'severity/major', 'affects-7.6', 'affects-8.1', 'affects-8.5']",7,Yui-Song,['xzhangxian1008'],,bug,"['docker', 'performance', 'tikv']",[],False,False,25
1768590934,44893,Allow lightning to import base64 encoded csv dump files ,"## Feature Request
Allow lightning to decode base64 encoded csv dump files before ingesting in tidb 
**Is your feature request related to a problem? Please describe:**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->

**Describe the feature you'd like:**
<!-- A clear and concise description of what you want to happen. -->

**Describe alternatives you've considered:**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Teachability, Documentation, Adoption, Migration Strategy:**
<!-- If you can, explain some scenarios how users might use this, situations it would be helpful in. Any API designs, mockups, or diagrams are also helpful. -->
",open,2023-06-21T22:19:19Z,2025-07-03T05:44:29Z,,"['type/feature-request', 'component/lightning']",5,ankita25,[],,migration,['mysql'],[],False,False,12
3026956148,60925,Backfilling for adding index needs a metric to display the speed of writing kvs,"## Enhancement

After https://github.com/pingcap/tidb/pull/57145, users can set the speed limitation when writing to tikv. However, ddl lacks a metric like IMPORT INTO to display the speed. The metric in tikv panel can not reflect the speed in tidb side. So it is hard for users to decide the setting value.",closed,2025-04-29T03:52:48Z,2025-07-03T03:29:47Z,2025-05-06T03:44:34Z,"['type/enhancement', 'component/ddl', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,CbcWestwolf,[],,enhancement,['tikv'],[],False,True,5
599717510,16381,"Cannot get latest version: module contains a go.mod file, so module path should be github.com/pingcap/tidb/v3","## Background
The `github.com/pingcap/tidb` uses [Go modules](https://github.com/golang/go/wiki/Modules) and the current release version is `v3`. And it’s module path is `""github.com/pingcap/tidb""`, instead of `""github.com/pingcap/tidb/v3""`. It must comply with the specification of ""Releasing Modules for v2 or higher"" available in the Modules documentation. Quoting the specification:
> A package that has opted in to modules _must_ include the major version in the import path to import any v2+ modules
> To preserve import compatibility, the go command requires that modules with major version v2 or later use a module path with that major version as the final element. For example, version v2.0.0 of _example.com/m_ must instead use module path _example.com/m/v2_.
https://github.com/golang/go/wiki/Modules#releasing-modules-v2-or-higher

## Steps to Reproduce
GO111MODULE=on, run `go get` targeting any version >= v2.1.0 of the `pingcap/tidb`:
```
$ go get github.com/pingcap/tidb@v3.0.12
go: finding github.com/pingcap/tidb v3.0.12
go: finding github.com/pingcap/tidb v3.0.12
go get github.com/pingcap/tidb@v3.0.12: github.com/pingcap/tidb@v3.0.12: invalid version: module contains a go.mod file, so major version must be compatible: should be v0 or v1, not v3
```
run `go get github.com/pingcap/tidb`, the version will stuck in v2.0.11:
```
$go get github.com/pingcap/tidb
go: finding github.com/pingcap/tidb v2.0.11+incompatible
go: downloading github.com/pingcap/tidb v2.0.11+incompatible
go: extracting github.com/pingcap/tidb v2.0.11+incompatible
```
SO anyone using Go modules will not be able to easily use any newer version of `pingcap/tidb`.

## Solution
### 1. Kill the go.mod files, rolling back to GOPATH.
This would push them back to not being managed by Go modules (instead of incorrectly using Go modules).
Ensure compatibility for downstream module-aware projects and module-unaware projects projects

I see these dependencies in your go.mod file, which need modle awareness. So you'd better not use third-party tools(such as: Dep, glide, govendor…).
```
github.com/Jeffail/gabs/v2 v2.5.1 
github.com/pingcap/pd/v4 v4.0.0-rc.2.0.20200730093003-dc8c75cf7ca0 
```
You also need to update the import path to:
```
import github.com/Jeffail/gabs/…
import github.com/pingcap/pd/…
```


### 2. Fix module path to strictly follow SIV rules.
Patch the `go.mod` file to declare the module path as `github.com/pingcap/tidb/v3` as [per the specs](https://github.com/golang/go/wiki/Modules#semantic-import-versioning). And adjust all internal imports.
The downstream projects might be negatively affected in their building if they are module-unaware (Go versions older than 1.9.7 and 1.10.3; Or use third-party dependency management tools, such as: Dep, glide,govendor…).

**[*]** You can see who will be affected here: [85 module-unaware users, i.e., GayStudio/openbilibili, GDWGH/mu-li-xian-bei, smallnest/soar]
https://github.com/search?o=desc&q=%22github.com%2Fpingcap%2Ftidb%22+filename%3AGodeps.json+filename%3Avendor.conf+filename%3Avendor.json+filename%3Aglide.toml+filename%3AGodep.toml&s=indexed&type=Code

If you don't want to break the above repos. This method can provides better backwards-compatibility.
Release a v2 or higher module through the major subdirectory strategy: Create a new v3 `subdirectory` (github.com/pingcap/tidb/v3) and place a new go.mod file in that subdirectory. The `module path` must end with `/v3`. Copy or move the code into the v3 subdirectory. Update `import statements` within the module to also use `/v3` (import ""github.com/pingcap/tidb/v3/…""). Tag the release with `v3.x.y`.


### 3.  Suggest your downstream module users use hash instead of a version tag.
If the standard rule of go modules conflicts with your development mode. Or not intended to be used as a library and does not make any guarantees about the API. So you can’t comply with the specification of ""Releasing Modules for v2 or higher"" available in the Modules documentation. 
Regardless, since it's against one of the design choices of Go, it'll be a bit of a hack. Instead of `go get github.com/pingcap/tidb@version-tag`, module users need to use this following way to get the `pingcap/tidb`:
   (1) Search for the `tag` you want (in browser)
   (2) Get the `commit hash` for the `tag` you want
   (3) Run `go get github.com/pingcap/tidb@commit-hash`
   (4) Edit the go.mod file to put a comment about which version you actually used
This will make it difficult for module users to get and upgrade `pingcap/tidb`.

**[*]** You can see who will be affected here: [341 module users, e.g., ushell/yearning, chaos-mesh/go-sqlancer, chaos-mesh/horoscope]
https://github.com/search?q=pingcap%2Ftidb+filename%3Ago.mod&type=Code


## Summary
You can make a choice to fix DM issues by balancing your own development schedules/mode against the affects on the downstream projects.

For this issue, `Solution 2` can maximize your benefits and with minimal impacts to your downstream projects the ecosystem. 

## References
* https://github.com/golang/go/wiki/Modules#semantic-import-versioning
* https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning
* https://github.com/golang/go/wiki/Modules#releasing-modules-v2-or-higher
",open,2020-04-14T16:56:05Z,2025-07-03T02:34:27Z,,"['type/enhancement', 'wontfix']",14,KateGo520,[],,enhancement,"['mysql', 'backup', 'pd']",[],False,False,22
3124470168,61565,internal SQL wrongly use get plan cost v1,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

When you enable the flame graph, you will find that some of the internal SQL stacks have stacks that call ```get_plan_cost_v1```, which is clearly incorrect.

![Image](https://github.com/user-attachments/assets/0f53b1e0-fb89-453b-9250-b835fcf8360b)

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-06-06T11:12:24Z,2025-07-02T23:36:49Z,2025-06-10T05:22:29Z,"['type/bug', 'sig/planner', 'severity/major', 'affects-6.5', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'report/customer', 'affects-8.5']",0,hawkingrei,[],,bug,['docker'],[],False,True,9
3178571136,62019,unexpected query result using aggregation,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
``` SQL
use test;
CREATE TABLE `t910beff5` (
  `col_40` tinyint unsigned DEFAULT '95',
  `col_41` tinytext COLLATE gbk_bin NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=gbk COLLATE=gbk_bin;
INSERT INTO `t910beff5` VALUES(7,'CWHObI8-!amnYA'),(1,'g+!OHa@OTdsA2#JN'),(249,'cwx!P4xaX)U'),(118,'mlDJX^n+'),(0,'EOZ9*QUsH%qi)%'),(183,'9*Lzmwg%pxy'),(139,'!ME5dBDrOG5'),(127,'BNb8SajqZ'),(209,'IWS^j'),(68,'U9v99'),(187,'dE*Zzjz#0&'),(10,'iC'),(87,'jIgUfpWzE9#oQhn&#&'),(4,'BLmM2'),(153,'(BG(8nIFNyE$%i'),(51,'EDhm)%Fie~qReM');

SELECT AVG(DISTINCT `t910beff5`.`col_40`) AS `r0` FROM `t910beff5` WHERE `t910beff5`.`col_41`>='D1$9+VTpEe)' OR `t910beff5`.`col_41` BETWEEN 'znRD*2pkmtm4' AND 'PBueg(&tWY%dzsT(_' GROUP BY `t910beff5`.`col_40`,`t910beff5`.`col_41` HAVING `t910beff5`.`col_41`='cwx!P4xaX)U';

```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
One row
### 3. What did you see instead (Required)
```  SQL
mysql> SELECT AVG(DISTINCT `t910beff5`.`col_40`) AS `r0` FROM `t910beff5` WHERE `t910beff5`.`col_41`>='D1$9+VTpEe)' OR `t910beff5`.`col_41` BETWEEN 'znRD*2pkmtm4' AND 'PBueg(&tWY%dzsT(_' GROUP BY `t910beff5`.`col_40`,`t910beff5`.`col_41` HAVING `t910beff5`.`col_41`='cwx!P4xaX)U';
Empty set (0.02 sec)

```
### 4. What is your TiDB version? (Required)
e87b8a9566b9dc61be69ded626254dc48c736006
<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-06-26T10:04:02Z,2025-07-02T21:37:52Z,2025-07-02T21:37:52Z,"['type/bug', 'sig/planner', 'severity/major', 'fuzz/randomtest', 'affects-8.5', 'affects-9.0']",6,wjhuang2016,['hawkingrei'],,bug,['mysql'],[],True,True,21
3194713301,62134,short-circuit in SELECT OR/AND clause,"## Bug Report

Hi, TiDB developers, please consider such queries:
```sql
SELECT TRUE OR (SELECT COUNT(*) FROM t1)>1;
SELECT FALSE AND (SELECT COUNT(*) FROM t1)>1;
```
For the first query, there are two conditions in the `WHERE` clause, connected by `OR`, which means that if any one of the conditions is met, it is `TRUE`. Therefore, when we calculate two conditions, if we calculate one of the conditions to be `TRUE`, we can short-circuit the `OR` expressions, which can avoid unnecessary calculations. For the second query, similarly, if we calculate one of the conditions to be `FALSE`, we can short-circuit the `AND` expressions. However, TiDB does not short-circuit to optimize such queries. Especially, short-circuiting is necessary when the computation of the condition is expensive.

### 1. Minimal reproduce step

(1) Create table and insert data
```sql
CREATE TABLE t1(c1 INT8);

CREATE TEMPORARY TABLE digits (d INT);
INSERT INTO digits VALUES (0),(1),(2),(3),(4),(5),(6),(7),(8),(9);

-- insert into t1 with 10 million rows
INSERT INTO t1
SELECT 
  d1.d + d2.d*10 + d3.d*100 + d4.d*1000 + d5.d*10000 + d6.d*100000 + d7.d*1000000 AS num
FROM 
  digits d1, digits d2, digits d3, digits d4, digits d5, digits d6, digits d7
WHERE 
  d1.d + d2.d*10 + d3.d*100 + d4.d*1000 + d5.d*10000 + d6.d*100000 + d7.d*1000000 <= 10000000;
```
(2) Execute query
```sql
SELECT TRUE OR (SELECT COUNT(c1) FROM t1)>1;
+------------------------------------+
| TRUE OR (SELECT COUNT(c1) FROM t1)>1 |
+------------------------------------+
|                                  1 |
+------------------------------------+
1 row in set (1.43 sec)

SELECT TRUE;
+------+
| TRUE |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

SELECT FALSE AND (SELECT COUNT(c1) FROM t1)>1;
+--------------------------------------+
| FALSE AND (SELECT COUNT(c1) FROM t1)>1 |
+--------------------------------------+
|                                    0 |
+--------------------------------------+
1 row in set (1.43 sec)

SELECT FALSE;
+-------+
| FALSE |
+-------+
|     0 |
+-------+
1 row in set (0.00 sec)
```
The following case is more obvious. All of the four queries trigger `ERROR 8175 (HY000)`. Especially, their `EXPLAIN` statements perform actual execution.
```sql
SELECT TRUE OR (SELECT COUNT(*) FROM t1 a, t1 b)>1;
SELECT FALSE AND (SELECT COUNT(*) FROM t1 a, t1 b)>1;
EXPLAIN SELECT TRUE OR (SELECT COUNT(*) FROM t1 a, t1 b)>1;
EXPLAIN SELECT TRUE OR (SELECT COUNT(*) FROM t1 a, t1 b)>1;
ERROR 8175 (HY000): Your query has been cancelled due to exceeding the allowed memory limit for a single SQL query. Please try narrowing your query scope or increase the tidb_mem_quota_query limit and try again.[conn=2378170378]
```
### 2. What did you expect to see? 
`SELECT OR/AND` clause could short-circuit, and `EXPLAIN` statements do not perform actual execution.
```sql
SELECT TRUE OR (SELECT COUNT(c1) FROM t1)>1;
+------------------------------------+
| TRUE OR (SELECT COUNT(c1) FROM t1)>1 |
+------------------------------------+
|                                  1 |
+------------------------------------+
1 row in set (0.00 sec)

SELECT FALSE AND (SELECT COUNT(c1) FROM t1)>1;
+--------------------------------------+
| FALSE AND (SELECT COUNT(c1) FROM t1)>1 |
+--------------------------------------+
|                                    0 |
+--------------------------------------+
1 row in set (0.00 sec)
```

### 3. What is your TiDB version? (Required)
| Release Version: v8.5.2
Edition: Community
Git Commit Hash: f43a13324440f92209e2a9f04c1bbe9cf763978d
Git Branch: HEAD
UTC Build Time: 2025-05-29 03:30:55
GoVersion: go1.23.8
Race Enabled: false
Check Table Before Drop: false
Store: tikv |

",open,2025-07-02T06:14:33Z,2025-07-02T19:41:38Z,,"['type/enhancement', 'sig/planner', 'severity/moderate']",0,jinhui-lai,['hawkingrei'],,enhancement,"['backup', 'tikv']",[],False,True,6
3003203159,60640,the y-axis format of Kv Request Duration in Resource Control grafana is wrong,"## Bug Report

<img width=""720"" alt=""Image"" src=""https://github.com/user-attachments/assets/ec502cb8-3c25-4285-b033-37c1ff0d0537"" />

“Successful KV Request Wait Duration” is type of ""duration"".

",closed,2025-04-17T18:41:00Z,2025-07-02T17:40:54Z,2025-04-28T06:49:36Z,"['type/bug', 'severity/moderate', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,glorv,[],,bug,"['docker', 'monitoring']",[],False,True,5
3003203159,60640,the y-axis format of Kv Request Duration in Resource Control grafana is wrong,"## Bug Report

<img width=""720"" alt=""Image"" src=""https://github.com/user-attachments/assets/ec502cb8-3c25-4285-b033-37c1ff0d0537"" />

“Successful KV Request Wait Duration” is type of ""duration"".

",closed,2025-04-17T18:41:00Z,2025-07-02T17:40:54Z,2025-04-28T06:49:36Z,"['type/bug', 'severity/moderate', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,glorv,[],,bug,"['docker', 'monitoring']",[],False,True,5
3191293223,62116,Predicate simplification cannot be performed in CTEs.,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```
set @@session.tidb_stats_load_sync_wait=2000;
create table t1 (a int, b  varchar(32));
insert into t1 values
(4,'aaaa' ), (7,'bb'), (1,'ccc'), (4,'dd');
insert into t1 values
(3,'eee'), (7,'bb'), (1,'fff'), (4,'ggg');
create table t2 (c int);
insert into t2 values
(2), (4), (5), (3);

explain format = 'brief'
with t as (select distinct a from t1 where b >= 'c')
select * from t as r1, t as r2 where r1.a=r2.a;
id	estRows	task	access object	operator info
HashJoin	2131.20	root		inner join, equal:[eq(mariadb_cte_nonrecursive.t1.a, mariadb_cte_nonrecursive.t1.a)]
├─Selection(Build)	2131.20	root		not(isnull(mariadb_cte_nonrecursive.t1.a))
│ └─CTEFullScan	2664.00	root	CTE:t AS r2	data:CTE_0
└─Selection(Probe)	2131.20	root		not(isnull(mariadb_cte_nonrecursive.t1.a))
  └─CTEFullScan	2664.00	root	CTE:t AS r1	data:CTE_0
CTE_0	2664.00	root		Non-Recursive CTE
└─HashAgg(Seed Part)	2664.00	root		group by:mariadb_cte_nonrecursive.t1.a, funcs:firstrow(mariadb_cte_nonrecursive.t1.a)->mariadb_cte_nonrecursive.t1.a
  └─TableReader	2664.00	root		data:HashAgg
    └─HashAgg	2664.00	cop[tikv]		group by:mariadb_cte_nonrecursive.t1.a, 
      └─Selection	3330.00	cop[tikv]		ge(mariadb_cte_nonrecursive.t1.b, ""c""), or(not(isnull(mariadb_cte_nonrecursive.t1.a)), not(isnull(mariadb_cte_nonrecursive.t1.a)))
        └─TableFullScan	10000.00	cop[tikv]	table:t1	keep order:false, stats:pseudo
```
<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

```or(not(isnull(mariadb_cte_nonrecursive.t1.a)), not(isnull(mariadb_cte_nonrecursive.t1.a)))```

should be simplified.
### 3. What did you see instead (Required)


cannot be simplified.
### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-07-01T08:14:38Z,2025-07-02T16:13:08Z,2025-07-01T13:05:42Z,"['type/bug', 'sig/planner', 'severity/major', 'affects-7.5', 'affects-8.1', 'affects-8.5']",1,hawkingrei,['hawkingrei'],,bug,"['mysql', 'backup', 'replication', 'tikv']",[],True,True,11
3162284578,61884,`initGlobalVariableIfNotExists` function forget close `rs`,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

https://github.com/pingcap/tidb/blob/c597cb5e0a290153916d52a5600c7ee4b30c634a/pkg/session/bootstrap.go#L1043-L1058

### 2. What did you expect to see? (Required)

call `rs.Close` before return

### 3. What did you see instead (Required)

forget call it and caused some states of `s` to not be cleaned up.

If `mysql.GLOBAL_VARIABLES` has a clustered index, it will report an error log like 

```
[2025/06/20 16:07:36.838 +08:00] [FATAL] [bootstrap.go:3591] [""mustExecute error""] [error=""try to commit with invalid txnStartTS: 18446744073709551615""] [stack=""github.com/pingcap/tidb/pkg/session.mustExecute\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3591\ngithub.com/pingcap/tidb/pkg/session.initGlobalVariableIfNotExists\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3327\ngithub.com/pingcap/tidb/pkg/session.upgradeToVer209\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3181\ngithub.com/pingcap/tidb/pkg/session.upgrade\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:1556\ngithub.com/pingcap/tidb/pkg/session.runInBootstrapSession\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3732\ngithub.com/pingcap/tidb/pkg/session.bootstrapSessionImpl\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3458\ngithub.com/pingcap/tidb/pkg/session.BootstrapSession\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3404\nmain.createStoreDDLOwnerMgrAndDomain\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/cmd/tidb-server/main.go:416\nmain.main\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/cmd/tidb-server/main.go:320\nruntime.main\n\t/Users/pingcap/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.6.darwin-arm64/src/runtime/proc.go:272""] [stack=""github.com/pingcap/tidb/pkg/session.mustExecute\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3591\ngithub.com/pingcap/tidb/pkg/session.initGlobalVariableIfNotExists\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3327\ngithub.com/pingcap/tidb/pkg/session.upgradeToVer209\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:3181\ngithub.com/pingcap/tidb/pkg/session.upgrade\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/bootstrap.go:1556\ngithub.com/pingcap/tidb/pkg/session.runInBootstrapSession\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3732\ngithub.com/pingcap/tidb/pkg/session.bootstrapSessionImpl\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3458\ngithub.com/pingcap/tidb/pkg/session.BootstrapSession\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/pkg/session/session.go:3404\nmain.createStoreDDLOwnerMgrAndDomain\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/cmd/tidb-server/main.go:416\nmain.main\n\t/Users/pingcap/workspace/bp-tidb-release-darwin-arm64-w2tsl-build-binaries/source/tidb/cmd/tidb-server/main.go:320\nruntime.main\n\t/Users/pingcap/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.6.darwin-arm64/src/runtime/proc.go:272""]
```

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
v8.5.2, master
",closed,2025-06-20T07:54:36Z,2025-07-02T16:00:02Z,2025-06-21T01:35:49Z,"['type/bug', 'type/regression', 'sig/sql-infra', 'severity/major', 'report/customer', 'affects-8.5', 'impact/upgrade']",8,Defined2014,[],,bug,['mysql'],[],True,True,23
3196239568,62159,Privilege check is mistakenly skipped for the plan cache point get special path,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

conn1
`mysql -h 127.0.0.1 -P 4000 -u root`
```sql
use test;
CREATE USER 'testuser'@'%';
CREATE TABLE test.t1 (a INT, b INT, PRIMARY KEY(a));
GRANT SELECT ON test.t1 TO 'testuser'@'%';
```

conn2
`mysql -h 127.0.0.1 -P 4000 -u testuser`
```sql
use test;
PREPARE stmt1 FROM 'SELECT * FROM test.t1 WHERE a = 0';
EXECUTE stmt1;
```

conn1
```
REVOKE SELECT ON test.t1 FROM 'testuser'@'%';
```

conn2
```
EXECUTE stmt1;
```

### 2. What did you expect to see? (Required)

`ERROR 1142 (42000): SELECT command denied to user 'testuser'@'127.0.0.1' for table 't1'`

### 3. What did you see instead (Required)

Successfully executed.

### 4. What is your TiDB version? (Required)

From v4.0 until the latest nightly (pre v9.0)

",open,2025-07-02T15:04:02Z,2025-07-02T15:17:59Z,,"['type/bug', 'sig/planner', 'severity/major', 'affects-6.1', 'affects-6.5', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'affects-8.5']",0,time-and-fate,['time-and-fate'],,bug,['mysql'],[],False,True,12
3195105557,62142,lightning: service safe point is not cleared on exit,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

with master, we can see the service safe point still exist after lightning exist, it will block GC for awhile, and it will expire after 10m, so it's not a serious issue
```
➜  lightning /Users/me/code/pingcap/tidb/bin/tidb-lightning-master --config test.toml
Verbose debug logs will be written to lightning.log

tidb lightning exit successfully

➜  lightning etcdctl --endpoints localhost:2379 get --prefix """"|grep -a lightning
/pd/7522392937985088901/gc/safe_point/service/lightning-c8a20fff-07bd-4744-bfa5-a12e529847c5
{""service_id"":""lightning-c8a20fff-07bd-4744-bfa5-a12e529847c5"",""expired_at"":1751444458,""safe_point"":459130498717057084}
```

### 2. What did you expect to see? (Required)
clear on exit
### 3. What did you see instead (Required)
not
### 4. What is your TiDB version? (Required)
master
<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-07-02T08:43:26Z,2025-07-02T13:45:43Z,2025-07-02T13:45:43Z,"['type/bug', 'severity/minor', 'component/lightning']",0,D3Hunter,[],,bug,"['pd', 'cdc']",[],False,True,3
2746663389,58364,"go tool trace is broken, ""failed to parse any useful part of the trace: misuse of region in goroutine""","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

start tidb, run some workload

then use the trace tool

```
curl 'http://127.0.0.1:10080/debug/pprof/trace?seconds=3' > trace.out
go tool trace -http=:6062 trace.out 
2024/12/18 11:29:22 Preparing trace for viewer...
failed to parse any useful part of the trace: misuse of region in goroutine 387: region end {228 pdclient.tsoReqSend} when the inner-most active region start event is {0 pdclient.tsoReqSend}
```

### 2. What did you expect to see? (Required)

go tool trace works.

### 3. What did you see instead (Required)

It's broken.

> failed to parse any useful part of the trace: misuse of region in goroutine 387: region end {228 pdclient.tsoReqSend} when the inner-most active region start event is {0 pdclient.tsoReqSend}


### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

",closed,2024-12-18T03:31:24Z,2025-07-02T13:30:29Z,2024-12-25T10:53:38Z,"['type/bug', 'sig/sql-infra']",3,tiancaiamao,['tiancaiamao'],,bug,"['backup', 'pd']",[],True,False,11
3194716060,62135,optimize performance of query with limit,"## Enhancement


### 1. Minimal reproduce step (Required)


1. prepare data.

```sql
create table orders (user_name varchar(10) not null, item_id int not null, index (user_name));
create table items  (id int auto_increment key, name varchar(100));
insert into orders values (""user1"", rand()*10000);
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user1"", rand()*10000 from orders;
insert into orders select ""user2"", rand()*10000 from orders;
insert into orders select ""user2"", rand()*10000 from orders limit 1024;
insert into orders select ""user2"", rand()*10000 from orders limit 2048;
insert into items (name) select uuid() from orders limit 2000;
insert into items (name) select uuid() from orders limit 2000;
insert into items (name) select uuid() from orders limit 2000;
insert into items (name) select uuid() from items  limit 4000;
analyze table orders,items;

-- For the convenience of analysis, disable paging.
set @@tidb_enable_paging=0;
```

2. Execute the following querys.

```sql
test> explain analyze select /*+ INL_JOIN(orders, items) */ * from orders join items on orders.item_id = items.id where orders.user_name='user1' order by items.name desc limit 20;
+---------------------------+---------+---------+-----------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+
| id                        | estRows | actRows | task      | access object | execution info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | operator info                                                                                                                               | memory   | disk    |
+---------------------------+---------+---------+-----------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+
| TopN_14                   | 20.00   | 20      | root      |               | time:14.6ms, open:40.1µs, close:2.96µs, loops:2, RU:15.69                                                                                                                                                                                                                                                                                                                                                                                                                                             | test.items.name:desc, offset:0, count:20                                                                                                    | 5.88 KB  | 0 Bytes |
| └─IndexJoin_19            | 1024.00 | 1024    | root      |               | time:14.4ms, open:19.9µs, close:2.38µs, loops:3, inner:{total:25.6ms, concurrency:5, task:5, construct:739.8µs, fetch:24.6ms, build:281.8µs}, probe:349µs                                                                                                                                                                                                                                                                                                                                             | inner join, inner:TableReader_40, outer key:test.orders.item_id, inner key:test.items.id, equal cond:eq(test.orders.item_id, test.items.id) | 134.8 KB | N/A     |
|   ├─TableReader_35(Build) | 1024.00 | 1024    | root      |               | time:5.01ms, open:18.6µs, close:1.25µs, loops:8, cop_task: {num: 1, max: 4.94ms, proc_keys: 5120, tot_proc: 4.54ms, tot_wait: 32.2µs, copr_cache_hit_ratio: 0.00, build_task_duration: 4.54µs, max_distsql_concurrency: 1}, fetch_resp_duration: 4.96ms, rpc_info:{Cop:{num_rpc:1, total_time:4.93ms}}                                                                                                                                                                                                | data:Selection_34                                                                                                                           | 21.5 KB  | N/A     |
|   │ └─Selection_34        | 1024.00 | 1024    | cop[tikv] |               | tikv_task:{time:4ms, loops:10}, scan_detail: {total_process_keys: 5120, total_process_keys_size: 235458, total_keys: 5121, get_snapshot_time: 17.4µs, rocksdb: {delete_skipped_count: 4864, key_skipped_count: 9984, block: {}}}, time_detail: {total_process_time: 4.54ms, total_suspend_time: 14.9µs, total_wait_time: 32.2µs, total_kv_read_wall_time: 4ms, tikv_grpc_process_time: 17.7µs, tikv_grpc_wait_time: 36.2µs, tikv_wall_time: 4.69ms}                                                   | eq(test.orders.user_name, ""user1"")                                                                                                          | N/A      | N/A     |
|   │   └─TableFullScan_33  | 5120.00 | 5120    | cop[tikv] | table:orders  | tikv_task:{time:4ms, loops:10}                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | keep order:false                                                                                                                            | N/A      | N/A     |
|   └─TableReader_40(Probe) | 1024.00 | 1003    | root      |               | total_time:23.7ms, total_open:0s, total_close:25.7µs, loops:10, cop_task: {num: 5, max: 8.08ms, min: 1.52ms, avg: 4.66ms, p95: 8.08ms, max_proc_keys: 495, p95_proc_keys: 495, tot_proc: 19.9ms, tot_wait: 348.1µs, copr_cache_hit_ratio: 0.00, build_task_duration: 170µs, max_distsql_concurrency: 1, max_extra_concurrency: 1}, fetch_resp_duration: 23.5ms, rpc_info:{Cop:{num_rpc:5, total_time:23.2ms}}                                                                                         | data:TableRangeScan_39                                                                                                                      | N/A      | N/A     |
|     └─TableRangeScan_39   | 1024.00 | 1003    | cop[tikv] | table:items   | tikv_task:{proc max:7ms, min:1ms, avg: 4ms, p80:7ms, p95:7ms, iters:17, tasks:5}, scan_detail: {total_process_keys: 1003, total_process_keys_size: 72216, total_keys: 1034, get_snapshot_time: 249µs, rocksdb: {delete_skipped_count: 64, key_skipped_count: 128, block: {}}}, time_detail: {total_process_time: 19.9ms, total_suspend_time: 263.7µs, total_wait_time: 348.1µs, total_kv_read_wall_time: 20ms, tikv_grpc_process_time: 404.6µs, tikv_grpc_wait_time: 167.5µs, tikv_wall_time: 21.8ms} | range: decided by [test.orders.item_id], keep order:false                                                                                   | N/A      | N/A     |
+---------------------------+---------+---------+-----------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+

test> explain analyze select /*+ INL_JOIN(orders, items) */ * from orders join items on orders.item_id = items.id where orders.user_name='user1' order by items.name desc;
+---------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+
| id                        | estRows | actRows | task      | access object | execution info                                                                                                                                                                                                                                                                                                                                                                                                                                 | operator info                                                                                                                               | memory   | disk    |
+---------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+
| Sort_9                    | 1024.00 | 1024    | root      |               | time:13.4ms, open:46.4µs, close:4.75µs, loops:2, RU:5.06                                                                                                                                                                                                                                                                                                                                                                                       | test.items.name:desc                                                                                                                        | 103.2 KB | 0 Bytes |
| └─IndexJoin_12            | 1024.00 | 1024    | root      |               | time:12.5ms, open:35.7µs, close:3.79µs, loops:2, inner:{total:11.5ms, concurrency:5, task:1, construct:403.7µs, fetch:10.9ms, build:172.6µs}, probe:225µs                                                                                                                                                                                                                                                                                      | inner join, inner:TableReader_33, outer key:test.orders.item_id, inner key:test.items.id, equal cond:eq(test.orders.item_id, test.items.id) | 175.1 KB | N/A     |
|   ├─TableReader_28(Build) | 1024.00 | 1024    | root      |               | time:639.5µs, open:34.1µs, close:1.79µs, loops:3, cop_task: {num: 1, max: 514.5µs, proc_keys: 0, tot_proc: 1.46µs, tot_wait: 64.9µs, copr_cache_hit_ratio: 1.00, build_task_duration: 6.71µs, max_distsql_concurrency: 1}, fetch_resp_duration: 552.3µs, rpc_info:{Cop:{num_rpc:1, total_time:499µs}}                                                                                                                                          | data:Selection_27                                                                                                                           | 21.4 KB  | N/A     |
|   │ └─Selection_27        | 1024.00 | 1024    | cop[tikv] |               | tikv_task:{time:6ms, loops:10}, scan_detail: {get_snapshot_time: 32µs, rocksdb: {block: {}}}, time_detail: {total_process_time: 1.46µs, total_wait_time: 64.9µs, tikv_grpc_process_time: 40µs, tikv_grpc_wait_time: 26.5µs, tikv_wall_time: 170.5µs}                                                                                                                                                                                           | eq(test.orders.user_name, ""user1"")                                                                                                          | N/A      | N/A     |
|   │   └─TableFullScan_26  | 5120.00 | 5120    | cop[tikv] | table:orders  | tikv_task:{time:5ms, loops:10}                                                                                                                                                                                                                                                                                                                                                                                                                 | keep order:false                                                                                                                            | N/A      | N/A     |
|   └─TableReader_33(Probe) | 1024.00 | 973     | root      |               | time:10.6ms, open:0s, close:5.08µs, loops:2, cop_task: {num: 1, max: 10.6ms, proc_keys: 973, tot_proc: 9.11ms, tot_wait: 49.8µs, copr_cache_hit_ratio: 0.00, build_task_duration: 63.2µs, max_distsql_concurrency: 1}, fetch_resp_duration: 10.6ms, rpc_info:{Cop:{num_rpc:1, total_time:10.6ms}}                                                                                                                                              | data:TableRangeScan_32                                                                                                                      | N/A      | N/A     |
|     └─TableRangeScan_32   | 1024.00 | 973     | cop[tikv] | table:items   | tikv_task:{time:9ms, loops:5}, scan_detail: {total_process_keys: 973, total_process_keys_size: 70056, total_keys: 1062, get_snapshot_time: 29.9µs, rocksdb: {delete_skipped_count: 187, key_skipped_count: 374, block: {}}}, time_detail: {total_process_time: 9.11ms, total_suspend_time: 336.9µs, total_wait_time: 49.8µs, total_kv_read_wall_time: 9ms, tikv_grpc_process_time: 269.6µs, tikv_grpc_wait_time: 62.2µs, tikv_wall_time: 10ms} | range: decided by [test.orders.item_id], keep order:false                                                                                   | N/A      | N/A     |
+---------------------------+---------+---------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+----------+---------+
```

Comparing the execution plans of these two queries, the query with `limit 20` sends many more RPCs from the `TableReader_xx(Probe)` than the query without `limit`.

The query with `limit 20`:

```sql
...
|   └─TableReader_40(Probe) ... | 1003    | root | ... total_time:23.7ms, loops:10, cop_task: {num: 5, ...
...
```

The query without `limit 20`:

```sql
...
|   └─TableReader_33(Probe) ... | 973     | root | ... time:10.6ms, loops:2, cop_task: {num: 1, ...
...
```


### Version

nightly.

```sql
test> select tidb_version();
+-----------------------------------------------------------+
| tidb_version()                                            |
+-----------------------------------------------------------+
| Release Version: v9.0.0-beta.2.pre-34-g1c612763c8         |
| Edition: Community                                        |
| Git Commit Hash: 1c612763c8d3cbaa042e37a244a9e02301542f45 |
| Git Branch: HEAD                                          |
| UTC Build Time: 2025-07-02 03:22:53                       |
| GoVersion: go1.23.10                                      |
| Race Enabled: false                                       |
| Check Table Before Drop: false                            |
| Store: tikv                                               |
| Kernel Type: Classic                                      |
+-----------------------------------------------------------+
1 row in set
test> select * from information_schema.cluster_info;
+------+-----------------+-----------------+---------------------------------+------------------------------------------+---------------------+---------------+-----------+
| TYPE | INSTANCE        | STATUS_ADDRESS  | VERSION                         | GIT_HASH                                 | START_TIME          | UPTIME        | SERVER_ID |
+------+-----------------+-----------------+---------------------------------+------------------------------------------+---------------------+---------------+-----------+
| tidb | 127.0.0.1:4000  | 127.0.0.1:10080 | 9.0.0-beta.2.pre-34-g1c612763c8 | 1c612763c8d3cbaa042e37a244a9e02301542f45 | 2025-07-02 13:42:35 | 32m54.628324s | 1338      |
| pd   | 127.0.0.1:2379  | 127.0.0.1:2379  | 9.0.0-beta.2.pre-3-g4f5e6c0f8   | 4f5e6c0f8a0cab198603bcbb86a44923565f0fdc | 2025-07-02 13:42:20 | 33m9.628331s  | 0         |
| tikv | 127.0.0.1:20160 | 127.0.0.1:20180 | 9.0.0-beta.2                    | 2029ff019ce689acc113f3bd886b08f861da0fbf | 2025-07-02 13:42:25 | 33m4.628335s  | 0         |
+------+-----------------+-----------------+---------------------------------+------------------------------------------+---------------------+---------------+-----------+
```

",open,2025-07-02T06:15:51Z,2025-07-02T12:21:48Z,,['type/enhancement'],1,crazycs520,[],,enhancement,"['backup', 'performance', 'tikv', 'pd']",[],False,True,3
3019367803,60842,panic in the ddl/notifier.(*DDLNotifier).OnBecomeOwner,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)


https://do.pingcap.net/jenkins/blue/organizations/jenkins/pingcap%2Ftidb%2Fghpr_unit_test/detail/ghpr_unit_test/31460/pipeline#step-69-log-1516

```
panic: assert failed, error processing events: [tikv:9006]GC life time is shorter than transaction duration, transaction starts at 2025-04-25 08:27:30.532 +0000 UTC, GC safe point is 2025-04-25 08:27:30.534 +0000 UTC [recovered]

	panic: assert failed, error processing events: [tikv:9006]GC life time is shorter than transaction duration, transaction starts at 2025-04-25 08:27:30.532 +0000 UTC, GC safe point is 2025-04-25 08:27:30.534 +0000 UTC


goroutine 27868 [running]:

github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).OnBecomeOwner.func1({0x8e03ca0, 0xc00b044310})

	pkg/ddl/notifier/subscribe.go:340 +0x314

github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1.1()

	pkg/util/wait_group_wrapper.go:195 +0xa2

panic({0x8e03ca0?, 0xc00b044310?})

	GOROOT/src/runtime/panic.go:791 +0x132

github.com/pingcap/tidb/pkg/util/intest.doPanic({0x0, 0x0}, {0xc007dade78, 0x1, 0x1})

	pkg/util/intest/assert_common.go:58 +0x79

github.com/pingcap/tidb/pkg/util/intest.doAssert(0x0, {0xc007dade78, 0x1, 0x1})

	pkg/util/intest/assert_common.go:30 +0x6e

github.com/pingcap/tidb/pkg/util/intest.Assert(0x0, {0xc007dade78, 0x1, 0x1})

	pkg/util/intest/assert.go:25 +0x9e

github.com/pingcap/tidb/pkg/ddl/notifier.(*DDLNotifier).start(0xc007c73020)

	pkg/ddl/notifier/subscribe.go:164 +0x553

github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1()

	pkg/util/wait_group_wrapper.go:202 +0xcf

created by github.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover in goroutine 28005

	pkg/util/wait_group_wrapper.go:191 +0x13d

panic: runtime error: invalid memory address or nil pointer dereference

[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x256df39]


goroutine 1 [running]:

github.com/bazelbuild/rules_go/go/tools/bzltestutil.toXML({0x98922a8, 0x1c}, 0xc001dbd970)

	external/io_bazel_rules_go/go/tools/bzltestutil/xml.go:191 +0x719

github.com/bazelbuild/rules_go/go/tools/bzltestutil.json2xml({0xa469a20, 0xc002000810}, {0x98922a8, 0x1c})

	external/io_bazel_rules_go/go/tools/bzltestutil/xml.go:165 +0x1657

github.com/bazelbuild/rules_go/go/tools/bzltestutil.writeReport({{0xc002180000, 0x74533, 0x80000}, 0x0, 0x0}, {0x98922a8, 0x1c}, {0xc000086010, 0xbb})

	external/io_bazel_rules_go/go/tools/bzltestutil/wrap.go:167 +0xeb

github.com/bazelbuild/rules_go/go/tools/bzltestutil.Wrap({0x98922a8, 0x1c})

	external/io_bazel_rules_go/go/tools/bzltestutil/wrap.go:155 +0xf65

main.main()

	bazel-out/k8-fastbuild/bin/pkg/ddl/tests/fail/fail_test_/testmain.go:103 +0x48

--

Coverage runner: Not collecting coverage for failed test.

```
<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)

https://github.com/pingcap/tidb/commit/5faa7496ef58bcee2b56ea9fd176d44363117815
<!-- Paste the output of SELECT tidb_version() -->

",open,2025-04-25T08:30:26Z,2025-07-02T10:28:32Z,,"['type/bug', 'component/test', 'severity/major', 'component/ddl']",1,hawkingrei,[],,bug,['tikv'],"['error:', 'panic:']",False,True,6
3093237518,61350,incompatible with mysql in column-type-info when use cast(),"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

create table testfield (f0 int,f1 decimal(10,2),f2 bigint,f3 datetime,f4 float,f5 double,primary key (f0));
insert into testfield values (1,1.1,1,'20250527',1.1,1.1);
insert into testfield values (2,2.2,2,'20250527',2.2,2.2);

TiDB nightly:
mysql> select cast(f0 as char),cast(f1 as char),cast(f2 as char),cast(f3 as char),cast(f4 as char),cast(f5 as char) from testfield;
Field   1:  `cast(f0 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
Length:     44
Max_length: 1
Decimals:   31
Flags:      

Field   2:  `cast(f1 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
**Length:     5**
Max_length: 4
Decimals:   31
Flags:      

Field   3:  `cast(f2 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
Length:     80
Max_length: 1
Decimals:   31
Flags:      

Field   4:  `cast(f3 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
**Length:     5**
Max_length: 19
Decimals:   31
Flags:      

Field   5:  `cast(f4 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
**Length:     5**
Max_length: 3
Decimals:   31
Flags:      

Field   6:  `cast(f5 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_bin (46)
**Length:     5**
Max_length: 3
Decimals:   31
Flags:      


+------------------+------------------+------------------+---------------------+------------------+------------------+
| cast(f0 as char) | cast(f1 as char) | cast(f2 as char) | cast(f3 as char)    | cast(f4 as char) | cast(f5 as char) |
+------------------+------------------+------------------+---------------------+------------------+------------------+
| 1                | 1.10             | 1                | 2025-05-27 00:00:00 | 1.1              | 1.1              |
| 2                | 2.20             | 2                | 2025-05-27 00:00:00 | 2.2              | 2.2              |
+------------------+------------------+------------------+---------------------+------------------+------------------+
2 rows in set (0.00 sec)

MySQL 8.4.4:
[tidb@k8s-master ~]$ mysql --column-type-info  -u root -p123123 -D test
mysql: [Warning] Using a password on the command line interface can be insecure.
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 10
Server version: 8.4.4 MySQL Community Server - GPL

Copyright (c) 2000, 2025, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> select cast(f0 as char),cast(f1 as char),cast(f2 as char),cast(f3 as char),cast(f4 as char),cast(f5 as char) from testfield;
Field   1:  `cast(f0 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
Length:     44
Max_length: 1
Decimals:   31
Flags:      

Field   2:  `cast(f1 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
**Length:     48**
Max_length: 4
Decimals:   31
Flags:      

Field   3:  `cast(f2 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
Length:     80
Max_length: 1
Decimals:   31
Flags:      

Field   4:  `cast(f3 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
**Length:     76**
Max_length: 19
Decimals:   31
Flags:      

Field   5:  `cast(f4 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
**Length:     48**
Max_length: 3
Decimals:   31
Flags:      

Field   6:  `cast(f5 as char)`
Catalog:    `def`
Database:   ``
Table:      ``
Org_table:  ``
Type:       VAR_STRING
Collation:  utf8mb4_0900_ai_ci (255)
**Length:     88**
Max_length: 3
Decimals:   31
Flags:      


+------------------+------------------+------------------+---------------------+------------------+------------------+
| cast(f0 as char) | cast(f1 as char) | cast(f2 as char) | cast(f3 as char)    | cast(f4 as char) | cast(f5 as char) |
+------------------+------------------+------------------+---------------------+------------------+------------------+
| 1                | 1.10             | 1                | 2025-05-27 00:00:00 | 1.1              | 1.1              |
| 2                | 2.20             | 2                | 2025-05-27 00:00:00 | 2.2              | 2.2              |
+------------------+------------------+------------------+---------------------+------------------+------------------+
2 rows in set (0.00 sec)

mysql> 

### 2. What did you expect to see? (Required)

Compatible with MySQL when use cast(XXX as varchar), include datetime\float\double\decimal

### 3. What did you see instead (Required)
the values of length in column-type-info incompatible with MySQL when use cast(xxx as varchar)

### 4. What is your TiDB version? (Required)
+--------------------------------------------+
| version()                                  |
+--------------------------------------------+
| 8.0.11-TiDB-v9.0.0-beta.1.pre-803-g7702f73 |
+--------------------------------------------+
1 row in set (0.01 sec)

",open,2025-05-27T09:15:46Z,2025-07-02T10:04:44Z,,"['type/bug', 'type/compatibility', 'sig/sql-infra', 'severity/moderate', 'may-affects-6.1', 'may-affects-7.1', 'may-affects-7.5', 'may-affects-8.1', 'affects-8.5']",5,lc17123,['YangKeao'],,bug,"['kubernetes', 'mysql']",[],False,True,22
3048311725,61026,DDL reorg workers send read requests that contain suffix `0x01`,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```sql
set global tidb_ddl_enable_fast_reorg = off;
set global tidb_enable_dist_task = off;
create table t (a int);
insert into t values (1);
alter table t add index idx(a);
```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

https://github.com/pingcap/tidb/blob/c1576410ac18755b2abb4faed51015199a82e671/pkg/ddl/backfilling.go#L1140

The `upperbound` should be `t\x80\x00\x00\x00\x00\x00\x00t_r\x80\x00\x00\x00\x00\x00\x00\x01\x00` (the suffix is `0x00`).

### 3. What did you see instead (Required)

`t\x80\x00\x00\x00\x00\x00\x00t_r\x80\x00\x00\x00\x00\x00\x00\x01\x01` (the suffix is `0x01`).

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
c1576410ac",open,2025-05-08T09:02:24Z,2025-07-02T09:24:15Z,,['component/ddl'],2,tangenta,[],,other,[],[],False,True,5
3195138220,62144,Reserve a range of table ID for enterprise edition,"## Enhancement

https://github.com/pingcap/tidb/blob/a900a31a9d1e4b277b42b77e9fac2a6d8b83ffc4/pkg/infoschema/tables.go#L346-L353

we found git conflict with cherry-pick codes from open-source TiDB. It's better to reserve a range to avoid more confilct in future",open,2025-07-02T08:54:19Z,2025-07-02T09:06:45Z,,['type/enhancement'],1,lance6716,[],,enhancement,[],[],False,True,3
3062856224,61116,next-gen: ddl function is not available after native br restore was executed several times,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
1. restore sysbench_32_7000w to keyspace_a with 8.5.1 br
2. cse backup cluster data
3. cse restore --keyspace-name keyspace_a --target-keyspace-name keyspace_b
4. drop sysbench_32_7000w of keyspace_a and keyspace_b
cse restore --keyspace-name keyspace_a --target-keyspace-name keyspace_b or cse restore --keyspace-name keyspace_a --target-keyspace-name keyspace_a
6. restore error
2025-05-13T14:33:21+00:00] Restore keyspace keyspace_a->keyspace_b error:  PdError(Other(""[components/pd_client/src/[util.rs:615](http://util.rs:615/)]: request retry exceeds limit""))
7. after a period of time, minio could not access normally, and tikv repeatedly panicked (2025/05/13 22:45:00 +08:00)
8. restart minio and minio recovery to normal，tikv also recovery to normal
9. The cluster cannot be used normally and ddl is stuck 

### 2. What did you expect to see? (Required)
ddl function is available

### 3. What did you see instead (Required)
ddl function is not available after native br restore was executed several times with some tidb error
`[2025/05/14 03:18:11.666 +00:00] [ERROR] [misc.go:117] [""panic in the recoverable goroutine""] [keyspaceName=keyspace_a] [label=domain] [funcInfo=handleTasksLoop] [r=""runtime error: invalid memory address or nil pointer dereference""] [stack=""[github.com/pingcap/tidb/pkg/util.Recover\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/misc.go:121\nruntime.gopanic\n\t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:791\ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).Exec.func1\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:496\nruntime.gopanic\n\t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:791\nruntime.panicmem\n\t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:262\nruntime.sigpanic\n\t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/signal_unix.go:917\ngithub.com/pingcap/tidb/pkg/executor.buildNoRangeIndexLookUpReader\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:4206\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildIndexLookUpReader\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:4222\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:297\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildHashAgg\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:1927\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:275\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildProjection\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:2099\ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:279\ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).buildExecutor\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:1230\ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).Exec\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:571\ngithub.com/pingcap/tidb/pkg/session.runStmt\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:2305\ngithub.com/pingcap/tidb/pkg/session.(*session).ExecuteStmt\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:2167\ngithub.com/pingcap/tidb/pkg/session.(*session).ExecuteInternal\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:1540\ngithub.com/pingcap/tidb/pkg/util/sqlexec.ExecSQL\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/sqlexec/restricted_sql_executor.go:256\ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).GetTaskExecInfoByExecID.func1\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:321\ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).WithNewSession\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:172\ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).GetTaskExecInfoByExecID\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:317\ngithub.com/pingcap/tidb/pkg/disttask/framework/taskexecutor.(*Manager).handleTasks\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/taskexecutor/manager.go:172\ngithub.com/pingcap/tidb/pkg/disttask/framework/taskexecutor.(*Manager).handleTasksLoop\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/taskexecutor/manager.go:151\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).Run.func1\n\t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/wait_group_wrapper.go:167](http://github.com/pingcap/tidb/pkg/util.Recover/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/misc.go:121/nruntime.gopanic/n/t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:791/ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).Exec.func1/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:496/nruntime.gopanic/n/t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:791/nruntime.panicmem/n/t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/panic.go:262/nruntime.sigpanic/n/t/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.8.linux-amd64/src/runtime/signal_unix.go:917/ngithub.com/pingcap/tidb/pkg/executor.buildNoRangeIndexLookUpReader/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:4206/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildIndexLookUpReader/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:4222/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:297/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildHashAgg/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:1927/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:275/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).buildProjection/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:2099/ngithub.com/pingcap/tidb/pkg/executor.(*executorBuilder).build/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/builder.go:279/ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).buildExecutor/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:1230/ngithub.com/pingcap/tidb/pkg/executor.(*ExecStmt).Exec/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/executor/adapter.go:571/ngithub.com/pingcap/tidb/pkg/session.runStmt/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:2305/ngithub.com/pingcap/tidb/pkg/session.(*session).ExecuteStmt/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:2167/ngithub.com/pingcap/tidb/pkg/session.(*session).ExecuteInternal/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/session/session.go:1540/ngithub.com/pingcap/tidb/pkg/util/sqlexec.ExecSQL/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/sqlexec/restricted_sql_executor.go:256/ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).GetTaskExecInfoByExecID.func1/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:321/ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).WithNewSession/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:172/ngithub.com/pingcap/tidb/pkg/disttask/framework/storage.(*TaskManager).GetTaskExecInfoByExecID/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/storage/task_table.go:317/ngithub.com/pingcap/tidb/pkg/disttask/framework/taskexecutor.(*Manager).handleTasks/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/taskexecutor/manager.go:172/ngithub.com/pingcap/tidb/pkg/disttask/framework/taskexecutor.(*Manager).handleTasksLoop/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/disttask/framework/taskexecutor/manager.go:151/ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).Run.func1/n/t/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tidb/pkg/util/wait_group_wrapper.go:167)""]`

### 4. What is your TiDB version? (Required)
./tidb-server -V
 Release Version: v9.0.0-next-gen
Edition: Community
Git Commit Hash: ad7da11f3f1c0e773cca0c7231a00be060ed6edc
Git Branch: heads/refs/tags/v9.0.0-next-gen
UTC Build Time: 2025-05-07 08:49:36
GoVersion: go1.23.8
Race Enabled: false
Check Table Before Drop: false
Store: unistore
Kernel Type: Next Generation

",closed,2025-05-14T11:54:43Z,2025-07-02T08:11:08Z,2025-07-02T08:11:08Z,"['type/bug', 'severity/major', 'feature/developing', 'may-affects-6.1', 'may-affects-6.5', 'may-affects-7.1', 'component/ddl', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5']",2,Lily2025,['Benjamin2037'],,bug,"['backup', 'tikv', 'pd']",['error:'],True,True,17
3119940372,61510,br: add more metrics to trace the memory usage during restoring,"## Enhancement
As title, we may encounter OOM when doing `restore point` and there are too many metadata files.",closed,2025-06-05T05:50:49Z,2025-07-02T07:54:15Z,2025-07-02T07:54:15Z,['type/enhancement'],0,YuJuncen,[],,enhancement,"['monitoring', 'backup']",[],False,True,1
2883559848,59810,Cancel the DDL cause incorrect column name,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

Run the following DDL, and cancel it before execution finished.
```
ALTER TABLE test.a CHANGE column1 column1 VARCHAR(255)
```

TiCDC receive column name like `_Col$_xxx`, this is unexpected. TiCDC only handle DDL job which state is `Done`


<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

The column name should be correct, such as column1

### 3. What did you see instead (Required)

TiCDC receive column name like `_Col$_xxx`, this is unexpected.

### 4. What is your TiDB version? (Required)

v7.5.1

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-02-27T06:24:35Z,2025-07-02T07:50:56Z,2025-07-02T07:50:56Z,"['type/bug', 'severity/critical', 'may-affects-6.1', 'may-affects-6.5', 'may-affects-7.1', 'component/ddl', 'may-affects-7.5', 'may-affects-8.1', 'impact/inconsistency', 'may-affects-8.5', 'affects-9.0']",2,3AceShowHand,[],,bug,['cdc'],[],True,False,15
3120460105,61525,"inject tikv failure, pitr has inconsistent results","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
1. start pitr with table filter
2. inject tikv pod failure 10min. duiring this failure, pitr would fail
3. restart pitr
4. pitr could success but data was inconsistent.

backup log has these operations：

1. create table `index_Data2_v2`
2. drop table `index_Data2`
3. rename table `index_Data2_v2` to `index_Data2`

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)
no table `index_Data2_v2` 

### 3. What did you see instead (Required)
table `index_Data2_v2`  in restore mode

![Image](https://github.com/user-attachments/assets/fdb06389-eec1-48eb-b5d1-971cb8a057be)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

Release Version: v9.0.0-beta.1.pre-869-g2bd1417
Edition: Community
Git Commit Hash: 2bd14176d4aa185f2b6f88cb506b4b8cc754a18d
Git Branch: HEAD
UTC Build Time: 2025-06-04 07:10:25
GoVersion: go1.23.9
Race Enabled: false
Check Table Before Drop: false
Store: tikv
Kernel Type: Classic",closed,2025-06-05T09:16:40Z,2025-07-02T07:50:24Z,2025-07-02T07:48:47Z,"['type/bug', 'severity/major', 'component/br', 'feature/developing', 'affects-8.5']",9,apollodafoni,['Leavrth'],,bug,"['kubernetes', 'docker', 'backup', 'tikv']",[],True,True,26
3159575095,61841,"After the table is repaired, it still remains in the repair list.","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
1. create a cluster with 3 tidb, 3 tikv
2. use br do 'pitr table filter'
3. kill br process, and let the table in restore mode
4. use `admin repair table ` recover rable

### 2. What did you expect to see? (Required)
1. After the table is repaired, it removed from repair list.

### 3. What did you see instead (Required)
1. After the table is repaired, it still remains in the repair list.

![Image](https://github.com/user-attachments/assets/0775b7df-85c9-4e9c-97cb-8eeaf2cbea0e)

2. One of the tidb repairs also had an error

![Image](https://github.com/user-attachments/assets/49660073-1bbe-4e3b-ab1d-a24e596922ae)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
Release Version: v8.5.0-20250618-76bdb5d
Edition: Community
Git Commit Hash: 76bdb5d24ca4d4526940dff398994c6728ba70e5
Git Branch: heads/refs/tags/v8.5.0-20250618-76bdb5d
UTC Build Time: 2025-06-18 07:07:08
GoVersion: go1.23.3
Race Enabled: false
Check Table Before Drop: false
Store: tikv
",closed,2025-06-19T09:10:03Z,2025-07-02T07:47:38Z,2025-07-02T07:47:38Z,"['type/bug', 'severity/major', 'may-affects-6.5', 'may-affects-7.1', 'component/ddl', 'may-affects-7.5', 'may-affects-8.1', 'may-affects-8.5']",8,apollodafoni,[],,bug,"['docker', 'backup', 'tikv']",[],True,True,24
3112282550,61454,Pessimistic locks are left after the session gets killed,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->

- start a transaction and lock a key
  ```sql
  create table t (id int primary key, c int);
  insert into t values (1, 1), (2, 2), (3, 3);
  begin;
  select * from t where id = 1 for update;
  ```
- kill the above session by `kill <id>`
- query the mvcc info of the key
  ```sh
  curl 127.0.0.1:10080/mvcc/key/test/t/1
  ```

### 2. What did you expect to see? (Required)

the pessimistic lock should be rollbacked.

### 3. What did you see instead (Required)

the pessimistic lock was left because `rollbackPessimisticLocks` failed due to the [kill flag](https://github.com/tikv/client-go/blob/e84f1a780fa63c25b76b8813eee4d587904b8221/txnkv/transaction/2pc.go#L1074).
```
$ curl 127.0.0.1:10080/mvcc/key/test/t/1
{
 ""key"": ""7480000000000000705F728000000000000001"",
 ""region_id"": 22,
 ""value"": {
  ""info"": {
   ""lock"": {
    ""type"": 5,
    ""start_ts"": 458469322054434817,
    ""primary"": ""dIAAAAAAAABwX3KAAAAAAAAAAQ=="",
    ""last_change_ts"": 458469321360015362,
    ""versions_to_last_change"": 1
   },
   ""writes"": [
    {
     ""start_ts"": 458469321360015361,
     ""commit_ts"": 458469321360015362,
     ""short_value"": ""gAABAAAAAgEACg==""
    }
   ]
  }
 }
}
```

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

master",open,2025-06-03T03:46:28Z,2025-07-02T07:15:47Z,,"['type/bug', 'sig/transaction', 'severity/moderate', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'affects-8.5', 'affects-9.0']",2,zyguan,[],,bug,"['tikv', 'pd']",[],False,True,12
2995457313,60574,release: v7.5.7,"**Disclaimer**
The dates published in this issue are for planning purposes only. It is intended solely to help you plan your projects. A date that exists in the future should not be considered a firm release date as the release and timing of releases are subject to change at any time and are at PingCAP's sole discretion.

**Candidate SHA:**
TBD

Working Tags: TBD

**Check the diff in the current version:**
See the difference from the commit perspective:
TBD


**Release process checklist**

- [x] 0. Announce the release plan.
 
- [ ] 1. Code freeze and RC build: Jul. 24, 2025(PDT, GMT-7)

- [ ] 2. Qualifying the release.

- [ ] 3. Docs preparing for release.

- [ ] 4. The release qualified.

- [ ] 5. Docs are ready for release.

**Release date: Aug. 7, 2025(CST & PDT)**

Do not proceed below until the release date.

- [ ] 6. Publish TiDB Release

> - [ ] fill in Candidate SHA above
> 
> - [ ] fill in the release tag

- [ ] 7. Update docs

- [ ] 8. Update the official website",open,2025-04-15T07:33:26Z,2025-07-02T06:46:08Z,,[],0,EmmaDuDu,[],,other,['pd'],[],False,True,0
3152156792,61769,release: v8.5.3,"**Disclaimer**
The dates published in this issue are for planning purposes only. It is intended solely to help you plan your projects. A date that exists in the future should not be considered a firm release date as the release and timing of releases are subject to change at any time and are at PingCAP's sole discretion.

**Working Tags:**
TBD

**Check the diff in the current version:**
See the difference from the commit perspective:
TBD


**Release process checklist**

- [x] 0. Announce the release plan.
 
- [ ] 1. Code freeze and RC build:Jul. 14, 2025(PDT, GMT-7) 

- [ ] 2. Qualifying the release.

- [ ] 3. Docs preparing for release.

- [ ] 4. The release qualified.

- [ ] 5. Docs are ready for release.

**Release date: Jul. 24, 2025(CST & PDT)**

Do not proceed below until the release date.

- [ ] 6. Publish TiDB Release
 
> - [ ] fill in the release tag

- [ ] 7. Update docs

- [ ] 8. Update the official website",open,2025-06-17T05:53:30Z,2025-07-02T06:46:03Z,,[],0,EmmaDuDu,[],,other,['pd'],[],False,True,0
2984596147,60472,Tracking Issue for Upgrade,"## Tasks:
- [x] 8.5.3

- [x] 8.5.2
    - [x] https://github.com/pingcap/tidb/issues/61884
    - [x] https://github.com/tikv/tikv/issues/18503
- [x] 8.5.1
    - [x] https://github.com/pingcap/tidb/issues/59926
    - [x] https://github.com/pingcap/tidb/issues/59827
    - [x] https://github.com/tikv/tikv/issues/18196
    - [x] https://github.com/pingcap/tidb/issues/58368
    - [x] https://github.com/tikv/tikv/issues/18233
    - [x] https://github.com/pingcap/tidb/issues/59947
    - [x] https://github.com/tikv/tikv/issues/18384
    - [x] https://github.com/pingcap/tidb/issues/60627
- [x] 8.5.0
    - [x] https://github.com/pingcap/tidb/issues/58843
- [x] 7.5.6
    - [x] https://github.com/pingcap/tidb/issues/51464

",open,2025-04-10T06:25:39Z,2025-07-02T06:43:32Z,,[],0,seiya-annie,[],,other,['tikv'],[],False,True,0
2778376752,58843,"modify column keeps writing temp column to tableinfo during upgrade from 8.1 -> 8.5, when there are multiple owners","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
- during upgrade, trigger this issue https://github.com/pingcap/tidb/issues/54689 on the older node `A`
- during the upgrade there is a `ALTER TABLE mysql.tidb_runaway_queries MODIFY COLUMN `plan_digest` varchar(64) DEFAULT '';` submitted by the 8.5 node which will force to be owner, and the job is using v1 args, but it contains 8 args, below is the code of 8.5.0
https://github.com/pingcap/tidb/blob/244062f826f75494525e3ac319d0e8ad794b0a43/pkg/meta/model/job_args.go#L1690-L1694
- if the job is run on `A`, it will append args, but A only uses the first 8, the appended args is useless.
  - if the job is created by older version, the job will only have 5 args initially, will append args will work, below is the code of 8.1.0
https://github.com/pingcap/tidb/blob/945d07c5d5c7a1ae212f6013adfb187f2de24b23/pkg/ddl/ddl_api.go#L6027
- so `modifyInfo.changingCol` is nil all the time, and it's initialized and inserted into the tableinfo every time(code of 8.1.0):
https://github.com/pingcap/tidb/blob/945d07c5d5c7a1ae212f6013adfb187f2de24b23/pkg/ddl/column.go#L570-L571
- as node `A` keeps running the job, we got a tableinfo like this:
```json
{
  ""id"": 432102,
  ""name"": {
   ""O"": ""tidb_runaway_queries"",
   ""L"": ""tidb_runaway_queries""
  },
  ""charset"": ""utf8mb4"",
  ""collate"": ""utf8mb4_bin"",
  ""cols"": [
..... other columns
  {
    ""id"": 3546,
    ""name"": {
     ""O"": ""_Col$_plan_digest_3536"",
     ""L"": ""_col$_plan_digest_3536""
    },
    ""offset"": 3545,
.....
}
```
### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)
see title
<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-01-09T17:24:21Z,2025-07-02T06:42:44Z,2025-01-10T06:43:51Z,"['type/bug', 'severity/major', 'component/ddl', 'report/customer', 'affects-8.5', 'impact/upgrade']",3,D3Hunter,[],,bug,['mysql'],[],True,False,12
3194360328,62130,"replace __MACOSX/s/._issue_61093.json? [y]es, [n]o, [A]ll, [N]one, [r]ename:","## Enhancement

```
TIDB_TEST_STORE_NAME=tikv TIKV_PATH=127.0.0.1:2379 ./run-tests.sh -s ../../bin/tidb-server -r all
extracting statistics: s
replace __MACOSX/s/._issue_61093.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: 
```

what's going on with this __MACOSX trash file???

",closed,2025-07-02T03:05:09Z,2025-07-02T06:30:34Z,2025-07-02T06:30:34Z,['type/enhancement'],1,tiancaiamao,[],,enhancement,['tikv'],[],True,True,3
3044563901,60986,TiDB panicked when quering the region status with a non-existed table ID,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```
MySQL [information_schema]>    SELECT
    ->      tikv.address,
    ->      peer.region_id,
    ->      peer.store_id,
    ->      peer.is_leader
    ->    FROM
    ->      TIKV_STORE_STATUS tikv,
    ->      TIKV_REGION_PEERS peer,
    ->      (SELECT region_id FROM TIKV_REGION_STATUS WHERE table_id = 111) region
    ->    WHERE
    ->      region.region_id = peer.region_id
    ->      AND peer.store_id = tikv.store_id;
ERROR 1105 (HY000): runtime error: invalid memory address or nil pointer dereference
MySQL [information_schema]> SELECT TABLE_NAME 
    -> FROM information_schema.TABLES 
    -> WHERE TIDB_TABLE_ID = 111;
Empty set (0.001 sec)
```

```
[2025/05/05 13:25:11.927 +00:00] [INFO] [conn.go:1184] [""command dispatched failed""] [conn=104857614] [session_alias=] [connInfo=""id:104857614, addr:10.148.0.5:40686 status:10, collation:utf8_general_ci, user:root""] [command=Query] [status=""inTxn:0, autocommit:1""] [sql=""SELECT      tikv.address,      peer.region_id,      peer.store_id,      peer.is_leader    FROM      TIKV_STORE_STATUS tikv,      TIKV_REGION_PEERS peer,      (SELECT region_id FROM TIKV_REGION_STATUS WHERE table_id = 113) region    WHERE      region.region_id = peer.region_id      AND peer.store_id = tikv.store_id""] [txn_mode=PESSIMISTIC] [timestamp=0] [err=""runtime error: invalid memory address or nil pointer dereference\ngithub.com/pingcap/errors.AddStack\n\t/root/go/pkg/mod/github.com/pingcap/errors@v0.11.5-0.20240318064555-6bd07397691f/errors.go:178\ngithub.com/pingcap/errors.Trace\n\t/root/go/pkg/mod/github.com/pingcap/errors@v0.11.5-0.20240318064555-6bd07397691f/juju_adaptor.go:15\ngithub.com/pingcap/tidb/pkg/util.GetRecoverError\n\t/workspace/source/tidb/pkg/util/util.go:288\ngithub.com/pingcap/tidb/pkg/executor/internal/exec.Next.func1\n\t/workspace/source/tidb/pkg/executor/internal/exec/executor.go:440\nruntime.gopanic\n\t/usr/local/go/src/runtime/panic.go:785\nruntime.panicmem\n\t/usr/local/go/src/runtime/panic.go:262\nruntime.sigpanic\n\t/usr/local/go/src/runtime/signal_unix.go:917\ngithub.com/pingcap/tidb/pkg/store/helper.(*Helper).GetRegionsTableInfo\n\t/workspace/source/tidb/pkg/store/helper/helper.go:684\ngithub.com/pingcap/tidb/pkg/executor.(*memtableRetriever).setDataForTiKVRegionStatus\n\t/workspace/source/tidb/pkg/executor/infoschema_reader.go:2017\ngithub.com/pingcap/tidb/pkg/executor.(*memtableRetriever).retrieve\n\t/workspace/source/tidb/pkg/executor/infoschema_reader.go:183\ngithub.com/pingcap/tidb/pkg/executor.(*MemTableReaderExec).Next\n\t/workspace/source/tidb/pkg/executor/memtable_reader.go:136\ngithub.com/pingcap/tidb/pkg/executor/internal/exec.Next\n\t/workspace/source/tidb/pkg/executor/internal/exec/executor.go:456\ngithub.com/pingcap/tidb/pkg/executor.(*SelectionExec).Next\n\t/workspace/source/tidb/pkg/executor/select.go:721\ngithub.com/pingcap/tidb/pkg/executor/internal/exec.Next\n\t/workspace/source/tidb/pkg/executor/internal/exec/executor.go:456\ngithub.com/pingcap/tidb/pkg/executor/join.(*probeSideTupleFetcherBase).fetchProbeSideChunks\n\t/workspace/source/tidb/pkg/executor/join/hash_join_base.go:172\ngithub.com/pingcap/tidb/pkg/executor/join.(*HashJoinV1Exec).fetchAndProbeHashTable.func1\n\t/workspace/source/tidb/pkg/executor/join/hash_join_v1.go:217\ngithub.com/pingcap/tidb/pkg/util.(*WaitGroupWrapper).RunWithRecover.func1\n\t/workspace/source/tidb/pkg/util/wait_group_wrapper.go:189\nruntime.goexit\n\t/usr/local/go/src/runtime/asm_amd64.s:1700""]
```

<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

No error, empty result.

### 3. What did you see instead (Required)

ERROR 1105 (HY000): runtime error: invalid memory address or nil pointer dereference

### 4. What is your TiDB version? (Required)

v8.5.1

<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-05-07T03:27:26Z,2025-07-02T06:14:46Z,2025-05-07T06:23:32Z,"['type/bug', 'sig/sql-infra', 'report/customer', 'affects-8.5']",1,jackysp,[],,bug,"['mysql', 'tikv']",['error:'],True,True,6
3047682238,61007,Using the same log file for different log types can cause some problems,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

use same log files

### 2. What did you expect to see? (Required)

The logs are normal.

### 3. What did you see instead (Required)

![Image](https://github.com/user-attachments/assets/0f2df709-e9e1-4994-9bca-fc254a15c4ea)

Out of order, rotate may also cause problems

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
master
",closed,2025-05-08T03:16:08Z,2025-07-02T06:14:18Z,2025-05-08T07:51:33Z,"['type/bug', 'sig/sql-infra', 'severity/major', 'affects-8.1', 'affects-8.5']",0,Defined2014,['Defined2014'],,bug,['docker'],[],False,True,8
3075357824,61191,remove foreign key table from tableInfoResident after new foreign key index on infoschema v2,"## Enhancement
",closed,2025-05-20T01:25:51Z,2025-07-02T06:14:09Z,2025-05-22T08:16:56Z,"['type/enhancement', 'component/ddl', 'affects-8.5']",0,River2000i,[],,enhancement,[],[],False,True,3
3159373093,61835,bug: vector type parser string maybe wrong,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

```cli
create table t(a vector(4));
-- parser as [1,2,3,4.4]
insert into t values(""[1,2,3,4.4]ddddddddddddfasfa"");
````

### 2. What did you expect to see? (Required)


ERROR 1105 (HY000): Invalid vector text: [1,2,3,4.4]ddddddddddddfasfa

### 3. What did you see instead (Required)

succeed insert as [1,2,3,4.4]

### 4. What is your TiDB version? (Required)

https://github.com/pingcap/tidb/commit/56ba961c7076da1677e1f471356e4651dca3051e
<!-- Paste the output of SELECT tidb_version() -->

",closed,2025-06-19T08:00:53Z,2025-07-02T06:13:40Z,2025-06-19T16:47:37Z,"['type/bug', 'severity/minor', 'sig/vector', 'affects-8.5', 'affects-9.0']",0,yihong0618,[],,bug,[],[],False,True,5
2639779226,57191,routine leak in TestRejectUnsupportedTables,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)
just run it, it happens every time. this sleep is introduced in https://github.com/tikv/client-go/pull/1458/files#diff-8600ed94f5c2740e41ca557dd1d00840f7fd0e3fcd2743d4dbbf5f1e9cc0376eR511, and has been updated in tidb in https://github.com/pingcap/tidb/pull/56305 for more than a month, I am not sure why CI cannot find it for such a long time, and suddenly it appears in this pr https://github.com/pingcap/tidb/pull/57179
```
--- PASS: TestRejectUnsupportedTables (4.40s)
PASS
goleak: Errors on successful test run: found unexpected goroutines:
[Goroutine 1156 in state sleep, with time.Sleep on top of the stack:
time.Sleep(0x12a05f200)
	/usr/local/go/src/runtime/time.go:315 +0xc8
github.com/tikv/client-go/v2/txnkv/transaction.(*twoPhaseCommitter).resolveFlushedLocks.func1()
	/Users/jujiajia/go/pkg/mod/github.com/tikv/client-go/v2@v2.0.8-0.20240925070302-58f3322fc39a/txnkv/transaction/pipelined_flush.go:511 +0xdf8
created by github.com/tikv/client-go/v2/txnkv/transaction.(*twoPhaseCommitter).resolveFlushedLocks in goroutine 63
	/Users/jujiajia/go/pkg/mod/github.com/tikv/client-go/v2@v2.0.8-0.20240925070302-58f3322fc39a/txnkv/transaction/pipelined_flush.go:489 +0xcf4
 Goroutine 1110 in state sleep, with time.Sleep on top of the stack:
time.Sleep(0x12a05f200)
	/usr/local/go/src/runtime/time.go:315 +0xc8
github.com/tikv/client-go/v2/txnkv/transaction.(*twoPhaseCommitter).resolveFlushedLocks.func1()
	/Users/jujiajia/go/pkg/mod/github.com/tikv/client-go/v2@v2.0.8-0.20240925070302-58f3322fc39a/txnkv/transaction/pipelined_flush.go:511 +0xdf8
created by github.com/tikv/client-go/v2/txnkv/transaction.(*twoPhaseCommitter).resolveFlushedLocks in goroutine 63
	/Users/jujiajia/go/pkg/mod/github.com/tikv/client-go/v2@v2.0.8-0.20240925070302-58f3322fc39a/txnkv/transaction/pipelined_flush.go:489 +0xcf4
]
```
<!-- a step by step guide for reproducing the bug. -->

### 2. What did you expect to see? (Required)

### 3. What did you see instead (Required)

### 4. What is your TiDB version? (Required)
master
<!-- Paste the output of SELECT tidb_version() -->

",closed,2024-11-07T03:42:51Z,2025-07-02T06:12:10Z,2024-11-07T09:51:27Z,"['type/bug', 'sig/transaction', 'severity/major', 'may-affects-5.4', 'may-affects-6.1', 'may-affects-6.5', 'may-affects-7.1', 'may-affects-7.5', 'may-affects-8.1', 'impact/leak', 'affects-8.5']",1,D3Hunter,[],,bug,"['tikv', 'pd']",[],True,False,13
2965838018,60375,import into merge stage is extremely slow for large datasets due to suboptimal resource usage,"## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

1. datesize 8T with about 48 billion rows
2. DXF is enabled
3. import into xxx from s3:xxx

### 2. What did you expect to see? (Required)
The merge phase should be optimized to make full use of all available TiDB resources
### 3. What did you see instead (Required)
Only 2 subtasks were allocated, and while one finishes the merge step quickly, the other takes nearly 2 hours.
[next-step=merge-sort] [subtask-count=2]
![Image](https://github.com/user-attachments/assets/002f8b55-075f-4cea-9e48-420521ada1ff)
![Image](https://github.com/user-attachments/assets/9f237b57-0af0-468a-a3e5-a273b581267a)

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->

v8.5.1",closed,2025-04-02T09:46:16Z,2025-07-02T06:11:32Z,2025-05-24T04:21:08Z,"['type/bug', 'severity/major', 'component/import', 'component/ddl', 'affects-8.5']",0,shaoxiqian,['tangenta'],,bug,"['docker', 'cloud', 'performance']",[],False,False,8
2948815569,60271,"In the batchPointGet operation, the internal backoff information is not correctly displayed in the execution Info","## Bug Report

Please answer these questions before submitting your issue. Thanks!

### 1. Minimal reproduce step (Required)

<!-- a step by step guide for reproducing the bug. -->
Mock backoff info to all BatchPointGet operations. Update client-go code like 
```go
func (s *KVSnapshot) BatchGet(ctx context.Context, keys [][]byte) (map[string][]byte, error) {
...
	bo.Backoff(retry.BoPDRPC, errors.New(""1111""))
	err := s.batchGetKeysByRegions(bo, keys, func(k, v []byte) {
...
}

func (s *KVSnapshot) batchGetKeysByRegions(bo *retry.Backoffer, keys [][]byte, collectF func(k, v []byte)) error {
...
	for i, batch1 := range batches {
		batch := batch1
		errInfo := ""xxx""
		boInfo := retry.BoRegionMiss
		if i == 1 {
			errInfo = ""yyy""
			boInfo = retry.BoTxnLockFast
		}
		go func() {
			backoffer, cancel := bo.Fork()
			defer cancel()
			err := backoffer.Backoff(boInfo, errors.New(errInfo))
			logutil.BgLogger().Warn(""backoff errors -------------------------------------------------"" + errInfo)
			if err != nil {
				return
			}
			ch <- s.batchGetSingleRegion(backoffer, batch, collectF)
		}()
	}
...
}
```
Original code:
https://github.com/tikv/client-go/blob/d4383a9a681116b265290818569ae3a7b59db5dd/txnkv/txnsnapshot/snapshot.go#L240-L241
```go
func (s *KVSnapshot) BatchGet(ctx context.Context, keys [][]byte) (map[string][]byte, error) {
...
	err := s.batchGetKeysByRegions(bo, keys, func(k, v []byte) {
...
}
```
https://github.com/tikv/client-go/blob/d4383a9a681116b265290818569ae3a7b59db5dd/txnkv/txnsnapshot/snapshot.go#L357-L364
```go
	for _, batch1 := range batches {
		batch := batch1
		go func() {
			backoffer, cancel := bo.Fork()
			defer cancel()
			ch <- s.batchGetSingleRegion(backoffer, batch, collectF)
		}()
	}
```

```sql
create table t(id int, user int, primary key(id));
SPLIT TABLE t BETWEEN (0) AND (1000000000) REGIONS 16;
insert into t values(312500000,312500000),(562500000,562500000),(1,1),(100000000,100000000);
explain analyze select * from t where id in(1, 100000000, 562500000);
```


### 2. What did you expect to see? (Required)
```sql
+-------------------+---------+---------+------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+--------+------+
| id                | estRows | actRows | task | access object | execution info                                                                                                                                                                                                                                                                    | operator info                                                | memory | disk |
+-------------------+---------+---------+------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+--------+------+
| Batch_Point_Get_1 | 3.00    | 3       | root | table:t       | time:371.2ms, loops:2, RU:1.426785, BatchGet:{num_rpc:3, total_time:3.23ms},pdRPC_backoff:{num:1, total_time:364ms}, tikv_wall_time: 1.22ms, scan_detail: {total_process_keys: 3, total_process_keys_size: 117, total_keys: 3, get_snapshot_time: 268.4µs, rocksdb: {block: {}}}  | handle:[1 100000000 562500000], keep order:false, desc:false | N/A    | N/A  |
+-------------------+---------+---------+------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+--------+------+
1 row in set (0.37 sec)
```

### 3. What did you see instead (Required)
There should be multiple backoff messages instead of being overridden by the outermost backoff message.

### 4. What is your TiDB version? (Required)

<!-- Paste the output of SELECT tidb_version() -->
v7.5.5
",closed,2025-03-26T08:49:40Z,2025-07-02T06:08:50Z,2025-04-23T02:34:32Z,"['type/bug', 'component/metrics', 'sig/execution', 'severity/major', 'component/tikv-client', 'affects-6.1', 'affects-6.5', 'affects-7.1', 'affects-7.5', 'affects-8.1', 'report/customer', 'affects-8.5']",5,zimulala,['yibin87'],,bug,"['tikv', 'pd']",[],True,False,25
